{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bffb67a",
      "metadata": {
        "id": "2bffb67a"
      },
      "outputs": [],
      "source": [
        "# Colab setup: clone repo and cd to script directory (run this first)\n",
        "import os\n",
        "REPO_DIR = \"/content/GNN-Sandia\"\n",
        "REPO_URL = \"https://github.com/alitasavori/GNN-Sandia.git\"\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !git clone {REPO_URL} {REPO_DIR}\n",
        "else:\n",
        "    !cd {REPO_DIR} && git pull origin main\n",
        "os.chdir(REPO_DIR)\n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90bd9812",
      "metadata": {
        "id": "90bd9812"
      },
      "outputs": [],
      "source": [
        "# Install dependencies (run once; Colab may already have torch)\n",
        "!pip install -q torch torch_geometric pandas opendssdirect matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ftcq1M4F8ZMg",
      "metadata": {
        "id": "Ftcq1M4F8ZMg"
      },
      "source": [
        "# GNN3: Exploration Execution\n",
        "\n",
        "This notebook runs seven standalone Python scripts:\n",
        "1. **gnn_final_exploration.py** — 20 nominees × 3 datasets (30% data)\n",
        "2. **gnn_further_exploration.py** — 60 new nominees × 3 datasets (30% data)\n",
        "3. **gnn_narrow_exploration.py** — 10 promising configs × 3 datasets (30% data)\n",
        "4. **gnn_boost_exploration.py** — 10 configs to beat Block 3 best (30% data)\n",
        "5. **gnn_refine_exploration.py** — 8 configs from Block 4 insights (30% data)\n",
        "6. **gnn_deltav_exploration.py** — 9 best Load-type configs on fourth dataset (delta-V, 30% data)\n",
        "7. **gnn_deltav_5x_exploration.py** — 9 configs on fifth dataset (delta-V 5× PV); reports target mean and compares RMSE to mean/std\n",
        "\n",
        "Ensure you are in the directory containing the scripts and data folders (`gnn_samples_out`, `gnn_samples_inj_full`, `gnn_samples_loadtype_full`, `gnn_samples_deltav_full`, `gnn_samples_deltav_5x_full` for Blocks 6–7)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2-FAh8BM8ZMh",
      "metadata": {
        "id": "2-FAh8BM8ZMh"
      },
      "source": [
        "## 1. Final exploration (20 nominees × 3 datasets)\n",
        "\n",
        "Runs `gnn_final_exploration.py` — the original 20 configs from GNN2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QdR3gnKD8ZMh",
      "metadata": {
        "id": "QdR3gnKD8ZMh"
      },
      "outputs": [],
      "source": [
        "%run gnn_final_exploration.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ZCKcQ7Q8ZMh",
      "metadata": {
        "id": "9ZCKcQ7Q8ZMh"
      },
      "source": [
        "### Results (from previous run — no need to re-run)\n",
        "\n",
        "**Best: light_xwide + Load-type | MAE=0.015253 | RMSE=0.015253**\n",
        "\n",
        "| # | Config | Dataset | MAE | RMSE | Best_epoch |\n",
        "|---|--------|---------|-----|------|----------|\n",
        "| 0 | light_xwide | Load-type | 0.015253 | 0.015253 | 16 |\n",
        "| 1 | light_wide | Load-type | 0.015392 | 0.015392 | 34 |\n",
        "| 2 | wide_shallow | Load-type | 0.015478 | 0.015478 | 16 |\n",
        "| 3 | light_emb | Load-type | 0.015668 | 0.015668 | 19 |\n",
        "| 4 | max_cap | Load-type | 0.015687 | 0.015687 | 22 |\n",
        "| 5 | light | Load-type | 0.015753 | 0.015753 | 25 |\n",
        "| 6 | deep_wide | Load-type | 0.015916 | 0.015916 | 16 |\n",
        "| 7 | light_wide_emb | Load-type | 0.016070 | 0.016070 | 21 |\n",
        "| 8 | medium_wide | Load-type | 0.016409 | 0.016409 | 24 |\n",
        "| 9 | light_deep | Load-type | 0.016458 | 0.016458 | 22 |\n",
        "| 10 | deep | Load-type | 0.016701 | 0.016701 | 17 |\n",
        "| 11 | heavy | Load-type | 0.016745 | 0.016745 | 16 |\n",
        "| 12 | heavy_wide | Load-type | 0.016901 | 0.016901 | 21 |\n",
        "| 13 | medium | Load-type | 0.017928 | 0.017928 | 27 |\n",
        "| 14 | emb_heavy | Load-type | 0.018131 | 0.018131 | 30 |\n",
        "| 15 | compact_deep | Load-type | 0.018999 | 0.018999 | 11 |\n",
        "| 16 | deep | Derived | 0.023686 | 0.023686 | 38 |\n",
        "| 17 | medium | Derived | 0.024115 | 0.024115 | 38 |\n",
        "| 18 | heavy_wide | Derived | 0.024337 | 0.024337 | 31 |\n",
        "| 19 | deep_wide | Derived | 0.024600 | 0.024600 | 24 |\n",
        "| 20 | deep | Original | 0.025552 | 0.025552 | 22 |\n",
        "| 21 | emb_heavy | Original | 0.025876 | 0.025876 | 40 |\n",
        "| 22 | medium_wide | Original | 0.025889 | 0.025889 | 30 |\n",
        "| 23 | heavy | Original | 0.025945 | 0.025945 | 30 |\n",
        "| 24 | deep_wide | Original | 0.026434 | 0.026434 | 15 |\n",
        "| 25 | medium | Original | 0.026445 | 0.026445 | 21 |\n",
        "| 26 | heavy_wide | Original | 0.026840 | 0.026840 | 26 |\n",
        "| 27 | medium_wide | Derived | 0.027652 | 0.027652 | 19 |\n",
        "| 28 | heavy | Derived | 0.027656 | 0.027656 | 19 |\n",
        "| 29 | light_emb | Original | 0.028368 | 0.028368 | 40 |\n",
        "| 30 | max_cap | Derived | 0.028736 | 0.028736 | 20 |\n",
        "| 31 | wide_shallow | Original | 0.028743 | 0.028743 | 24 |\n",
        "| 32 | light_wide | Original | 0.028872 | 0.028872 | 31 |\n",
        "| 33 | light | Original | 0.028915 | 0.028915 | 31 |\n",
        "| 34 | light_wide_emb | Original | 0.029121 | 0.029121 | 17 |\n",
        "| 35 | light_xwide | Original | 0.030242 | 0.030242 | 11 |\n",
        "| 36 | light_xwide | Derived | 0.030483 | 0.030483 | 29 |\n",
        "| 37 | light | Derived | 0.030562 | 0.030562 | 38 |\n",
        "| 38 | light_wide | Derived | 0.030610 | 0.030610 | 25 |\n",
        "| 39 | light_wide_emb | Derived | 0.030769 | 0.030769 | 18 |\n",
        "| 40 | light_emb | Derived | 0.030799 | 0.030799 | 38 |\n",
        "| 41 | emb_heavy | Derived | 0.031089 | 0.031089 | 11 |\n",
        "| 42 | wide_shallow | Derived | 0.031866 | 0.031866 | 11 |\n",
        "| 43 | deep_xplus | Derived | 0.063484 | 0.063484 | 26 |\n",
        "| 44 | light_deep | Derived | 0.063514 | 0.063514 | 21 |\n",
        "| 45 | xdeep | Load-type | 0.063565 | 0.063565 | 6 |\n",
        "| 46 | ultra_deep | Derived | 0.063587 | 0.063587 | 16 |\n",
        "| 47 | ultra_deep | Load-type | 0.063596 | 0.063596 | 8 |\n",
        "| 48 | deep_xplus | Load-type | 0.063600 | 0.063600 | 12 |\n",
        "| 49 | compact_deep | Derived | 0.063619 | 0.063619 | 15 |\n",
        "| 50 | xdeep | Derived | 0.063637 | 0.063637 | 19 |\n",
        "| 51 | deep_plus | Load-type | 0.063691 | 0.063691 | 4 |\n",
        "| 52 | deep_plus | Derived | 0.063856 | 0.063856 | 9 |\n",
        "| 53 | xdeep | Original | 0.064010 | 0.064010 | 8 |\n",
        "| 54 | max_cap | Original | 0.064017 | 0.064017 | 3 |\n",
        "| 55 | deep_xplus | Original | 0.064022 | 0.064022 | 4 |\n",
        "| 56 | ultra_deep | Original | 0.064043 | 0.064043 | 20 |\n",
        "| 57 | compact_deep | Original | 0.064068 | 0.064068 | 11 |\n",
        "| 58 | deep_plus | Original | 0.064086 | 0.064086 | 20 |\n",
        "| 59 | light_deep | Original | 0.064095 | 0.064095 | 12 |\n",
        "\n",
        "*(No config reached MAE < 0.001; best MAE = 0.015253)*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4SeoOlja8ZMi",
      "metadata": {
        "id": "4SeoOlja8ZMi"
      },
      "source": [
        "## 2. Further exploration (60 nominees × 3 datasets)\n",
        "\n",
        "Runs `gnn_further_exploration.py` — 60 new evidence-based configs:\n",
        "- Load-type extrapolation: wider h (160, 192), h=96/80/112, emb 16/8\n",
        "- 3-layer sweet spot: medium_3, heavy_3, deep_3, etc.\n",
        "- Emb 12/6 interpolation\n",
        "- Original/Derived refinements\n",
        "\n",
        "**Run the cell below to execute.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ASfYEBbV8ZMi",
      "metadata": {
        "id": "ASfYEBbV8ZMi"
      },
      "outputs": [],
      "source": [
        "%run gnn_further_exploration.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SHDBcUcU8eD6",
      "metadata": {
        "id": "SHDBcUcU8eD6"
      },
      "source": [
        "### Results Summary (sorted by MAE)\n",
        "\n",
        "**Best: light_emb_h96 + Load-type | MAE=0.015133 | RMSE=0.015133**\n",
        "\n",
        "| # | Config | Dataset | MAE | RMSE | Best_epoch |\n",
        "|---|--------|---------|-----|------|----------|\n",
        "| 0 | light_emb_h96 | Load-type | 0.015133 | 0.015133 | 18 |\n",
        "| 1 | light_xwide_emb | Load-type | 0.015236 | 0.015236 | 20 |\n",
        "| 2 | light_wide_emb12 | Load-type | 0.015297 | 0.015297 | 19 |\n",
        "| 3 | wide_shallow_h160 | Load-type | 0.015417 | 0.015417 | 18 |\n",
        "| 4 | light_xxxwide_emb | Load-type | 0.015473 | 0.015473 | 11 |\n",
        "| 5 | light_xxwide | Load-type | 0.015516 | 0.015516 | 18 |\n",
        "| 6 | light_xwide_emb12 | Load-type | 0.015543 | 0.015543 | 12 |\n",
        "| 7 | light_wide_h112 | Load-type | 0.015601 | 0.015601 | 13 |\n",
        "| 8 | heavy_3 | Load-type | 0.015608 | 0.015608 | 24 |\n",
        "| 9 | light_xxwide_emb | Load-type | 0.015610 | 0.015610 | 13 |\n",
        "| 10 | light_h112 | Load-type | 0.015612 | 0.015612 | 13 |\n",
        "| 11 | light_wide_3 | Load-type | 0.015623 | 0.015623 | 22 |\n",
        "| 12 | max_cap_3 | Load-type | 0.015638 | 0.015638 | 22 |\n",
        "| 13 | light_xxxwide | Load-type | 0.015641 | 0.015641 | 11 |\n",
        "| 14 | light_h144 | Load-type | 0.015695 | 0.015695 | 16 |\n",
        "| 15 | light_xwide_h96 | Load-type | 0.015707 | 0.015707 | 17 |\n",
        "| 16 | light_xwide_3 | Load-type | 0.015724 | 0.015724 | 40 |\n",
        "| 17 | wide_shallow_h112 | Load-type | 0.015735 | 0.015735 | 13 |\n",
        "| 18 | emb_heavy_3 | Load-type | 0.015842 | 0.015842 | 37 |\n",
        "| 19 | light_emb_h80 | Load-type | 0.015868 | 0.015868 | 16 |\n",
        "| 20 | medium_wide_3 | Load-type | 0.015956 | 0.015956 | 22 |\n",
        "| 21 | light_wide_h80 | Load-type | 0.016018 | 0.016018 | 19 |\n",
        "| 22 | wide_shallow_h96 | Load-type | 0.016039 | 0.016039 | 10 |\n",
        "| 23 | deep_wide_3 | Load-type | 0.016050 | 0.016050 | 14 |\n",
        "| 24 | light_wide_h96 | Load-type | 0.016079 | 0.016079 | 10 |\n",
        "| 25 | deep_3 | Load-type | 0.016268 | 0.016268 | 12 |\n",
        "| 26 | light_h80 | Load-type | 0.016278 | 0.016278 | 12 |\n",
        "| 27 | light_emb12 | Load-type | 0.016318 | 0.016318 | 22 |\n",
        "| 28 | light_h176 | Load-type | 0.016472 | 0.016472 | 9 |\n",
        "| 29 | medium_emb12 | Load-type | 0.016495 | 0.016495 | 21 |\n",
        "| 30 | heavy_wide_3 | Load-type | 0.016726 | 0.016726 | 12 |\n",
        "| 31 | deep_emb12 | Load-type | 0.016848 | 0.016848 | 14 |\n",
        "| 32 | heavy_emb12 | Load-type | 0.016942 | 0.016942 | 14 |\n",
        "| 33 | medium_3 | Load-type | 0.020678 | 0.020678 | 12 |\n",
        "| 34 | heavy_emb12 | Original | 0.023660 | 0.023660 | 30 |\n",
        "| 35 | deep_emb12 | Original | 0.023892 | 0.023892 | 28 |\n",
        "| 36 | light_xwide_3 | Original | 0.025757 | 0.025757 | 27 |\n",
        "| 37 | medium_wide_3 | Original | 0.025859 | 0.025859 | 38 |\n",
        "| 38 | heavy_3 | Original | 0.025878 | 0.025878 | 28 |\n",
        "| 39 | light_wide_3 | Original | 0.025880 | 0.025880 | 38 |\n",
        "| 40 | heavy_wide_3 | Original | 0.025893 | 0.025893 | 27 |\n",
        "| 41 | deep_wide_3 | Original | 0.026574 | 0.026574 | 23 |\n",
        "| 42 | medium_emb12 | Original | 0.026793 | 0.026793 | 21 |\n",
        "| 43 | medium_emb12 | Derived | 0.026833 | 0.026833 | 29 |\n",
        "| 44 | deep_3 | Original | 0.026896 | 0.026896 | 33 |\n",
        "| 45 | emb_heavy_3 | Derived | 0.026953 | 0.026953 | 27 |\n",
        "| 46 | medium_3 | Derived | 0.026972 | 0.026972 | 39 |\n",
        "| 47 | max_cap_3 | Original | 0.027236 | 0.027236 | 17 |\n",
        "| 48 | emb_heavy_3 | Original | 0.027292 | 0.027292 | 26 |\n",
        "| 49 | heavy_wide_3 | Derived | 0.027310 | 0.027310 | 23 |\n",
        "| 50 | deep_3 | Derived | 0.027319 | 0.027319 | 18 |\n",
        "| 51 | light_wide_3 | Derived | 0.027447 | 0.027447 | 18 |\n",
        "| 52 | heavy_3 | Derived | 0.027461 | 0.027461 | 18 |\n",
        "| 53 | medium_wide_3 | Derived | 0.027504 | 0.027504 | 18 |\n",
        "| 54 | max_cap_3 | Derived | 0.027976 | 0.027976 | 9 |\n",
        "| 55 | deep_emb12 | Derived | 0.028090 | 0.028090 | 10 |\n",
        "| 56 | heavy_emb12 | Derived | 0.028318 | 0.028318 | 10 |\n",
        "| 57 | medium_3 | Original | 0.028460 | 0.028460 | 27 |\n",
        "| 58 | light_wide_emb12 | Original | 0.028721 | 0.028721 | 33 |\n",
        "| 59 | light_xwide_3 | Derived | 0.028773 | 0.028773 | 13 |\n",
        "| 60 | light_emb12 | Original | 0.028795 | 0.028795 | 26 |\n",
        "| 61 | light_xxwide | Original | 0.028844 | 0.028844 | 19 |\n",
        "| 62 | light_h80 | Original | 0.028912 | 0.028912 | 16 |\n",
        "| 63 | wide_shallow_h160 | Original | 0.028930 | 0.028930 | 19 |\n",
        "| 64 | light_wide_h80 | Original | 0.028982 | 0.028982 | 16 |\n",
        "| 65 | light_h144 | Original | 0.029013 | 0.029013 | 13 |\n",
        "| 66 | light_emb_h96 | Original | 0.029059 | 0.029059 | 23 |\n",
        "| 67 | light_wide_h112 | Original | 0.029250 | 0.029250 | 28 |\n",
        "| 68 | wide_shallow_h112 | Original | 0.029294 | 0.029294 | 28 |\n",
        "| 69 | light_emb_h80 | Original | 0.029385 | 0.029385 | 14 |\n",
        "| 70 | light_wide_h96 | Original | 0.029396 | 0.029396 | 16 |\n",
        "| 71 | light_xxwide_emb | Original | 0.029457 | 0.029457 | 15 |\n",
        "| 72 | light_xwide_emb | Original | 0.029474 | 0.029474 | 24 |\n",
        "| 73 | light_xwide_h96 | Original | 0.029499 | 0.029499 | 16 |\n",
        "| 74 | deep_wide_3 | Derived | 0.029622 | 0.029622 | 11 |\n",
        "| 75 | light_xxxwide | Original | 0.029805 | 0.029805 | 16 |\n",
        "| 76 | light_emb_h96 | Derived | 0.030051 | 0.030051 | 39 |\n",
        "| 77 | wide_shallow_h96 | Original | 0.030169 | 0.030169 | 15 |\n",
        "| 78 | wide_shallow_h112 | Derived | 0.030228 | 0.030228 | 30 |\n",
        "| 79 | light_h112 | Original | 0.030233 | 0.030233 | 20 |\n",
        "| 80 | light_h176 | Original | 0.030284 | 0.030284 | 15 |\n",
        "| 81 | light_h112 | Derived | 0.030303 | 0.030303 | 30 |\n",
        "| 82 | light_wide_h112 | Derived | 0.030304 | 0.030304 | 30 |\n",
        "| 83 | light_wide_emb12 | Derived | 0.030437 | 0.030437 | 28 |\n",
        "| 84 | light_wide_h96 | Derived | 0.030463 | 0.030463 | 22 |\n",
        "| 85 | light_h144 | Derived | 0.030463 | 0.030463 | 23 |\n",
        "| 86 | wide_shallow_h96 | Derived | 0.030476 | 0.030476 | 22 |\n",
        "| 87 | light_xxwide_emb | Derived | 0.030487 | 0.030487 | 27 |\n",
        "| 88 | wide_shallow_emb12 | Derived | 0.030492 | 0.030492 | 22 |\n",
        "| 89 | light_xwide_h96 | Derived | 0.030525 | 0.030525 | 18 |\n",
        "| 90 | light_xxxwide_emb | Derived | 0.030576 | 0.030576 | 23 |\n",
        "| 91 | light_xwide_emb12 | Derived | 0.030605 | 0.030605 | 22 |\n",
        "| 92 | light_xxxwide_emb | Original | 0.030626 | 0.030626 | 11 |\n",
        "| 93 | light_h80 | Derived | 0.030639 | 0.030639 | 18 |\n",
        "| 94 | light_xwide_emb | Derived | 0.030672 | 0.030672 | 29 |\n",
        "| 95 | light_xxxwide | Derived | 0.030732 | 0.030732 | 10 |\n",
        "| 96 | light_emb_h80 | Derived | 0.030892 | 0.030892 | 40 |\n",
        "| 97 | light_h176 | Derived | 0.030944 | 0.030944 | 21 |\n",
        "| 98 | light_emb12 | Derived | 0.030958 | 0.030958 | 36 |\n",
        "| 99 | light_xxwide | Derived | 0.031020 | 0.031020 | 14 |\n",
        "| 100 | light_wide_h80 | Derived | 0.031032 | 0.031032 | 18 |\n",
        "| 101 | light_xwide_emb12 | Original | 0.031277 | 0.031277 | 9 |\n",
        "| 102 | wide_shallow_h160 | Derived | 0.031335 | 0.031335 | 16 |\n",
        "| 103 | wide_shallow_emb12 | Original | 0.031643 | 0.031643 | 9 |\n",
        "\n",
        "*(No config reached MAE < 0.001; best MAE = 0.015133)*\n",
        "\n",
        "---\n",
        "\n",
        "**Detailed output (epoch-by-epoch):**\n",
        "\n",
        "======================================================================\n",
        "FURTHER EXPLORATION: 30% data, 60 nominees × 3 datasets, target MAE < 0.001\n",
        "======================================================================\n",
        "\n",
        ">>> light_xxwide + Original (n=2 h=160 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.022743 | RMSE=0.04635 | best=0.04635 | patience=8\n",
        "    Epoch 05 | train_loss=0.000448 | RMSE=0.03309 | best=0.03309 | patience=8\n",
        "    Epoch 10 | train_loss=0.000394 | RMSE=0.03976 | best=0.03115 | patience=7\n",
        "    Epoch 15 | train_loss=0.000396 | RMSE=0.03195 | best=0.03000 | patience=5\n",
        "    Epoch 20 | train_loss=0.000399 | RMSE=0.02954 | best=0.02884 | patience=7\n",
        "    Epoch 25 | train_loss=0.000347 | RMSE=0.04140 | best=0.02884 | patience=2\n",
        "  FINAL: MAE=0.028844 RMSE=0.028844 best_epoch=19\n",
        "\n",
        ">>> light_xxwide + Derived (n=2 h=160 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.026295 | RMSE=0.04757 | best=0.04757 | patience=8\n",
        "    Epoch 05 | train_loss=0.000507 | RMSE=0.03647 | best=0.03647 | patience=8\n",
        "    Epoch 10 | train_loss=0.000416 | RMSE=0.03323 | best=0.03234 | patience=7\n",
        "    Epoch 15 | train_loss=0.000463 | RMSE=0.03375 | best=0.03102 | patience=7\n",
        "    Epoch 20 | train_loss=0.000381 | RMSE=0.03851 | best=0.03102 | patience=2\n",
        "  FINAL: MAE=0.031020 RMSE=0.031020 best_epoch=14\n",
        "\n",
        ">>> light_xxwide + Load-type (n=2 h=160 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.053346 | RMSE=0.04430 | best=0.04430 | patience=8\n",
        "    Epoch 05 | train_loss=0.000143 | RMSE=0.01724 | best=0.01724 | patience=8\n",
        "    Epoch 10 | train_loss=0.000102 | RMSE=0.01797 | best=0.01666 | patience=7\n",
        "    Epoch 15 | train_loss=0.000131 | RMSE=0.05038 | best=0.01653 | patience=6\n",
        "    Epoch 20 | train_loss=0.000124 | RMSE=0.01574 | best=0.01552 | patience=6\n",
        "    Epoch 25 | train_loss=0.000131 | RMSE=0.01711 | best=0.01552 | patience=1\n",
        "  FINAL: MAE=0.015516 RMSE=0.015516 best_epoch=18\n",
        "\n",
        ">>> light_xxxwide + Original (n=2 h=192 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.034420 | RMSE=0.04959 | best=0.04959 | patience=8\n",
        "    Epoch 05 | train_loss=0.000459 | RMSE=0.06113 | best=0.03501 | patience=8\n",
        "    Epoch 10 | train_loss=0.000383 | RMSE=0.03041 | best=0.03041 | patience=8\n",
        "    Epoch 15 | train_loss=0.000409 | RMSE=0.03746 | best=0.02983 | patience=4\n",
        "    Epoch 20 | train_loss=0.000386 | RMSE=0.03350 | best=0.02980 | patience=4\n",
        "  FINAL: MAE=0.029805 RMSE=0.029805 best_epoch=16\n",
        "\n",
        ">>> light_xxxwide + Derived (n=2 h=192 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.022646 | RMSE=0.04488 | best=0.04488 | patience=8\n",
        "    Epoch 05 | train_loss=0.000522 | RMSE=0.04747 | best=0.03740 | patience=8\n",
        "    Epoch 10 | train_loss=0.000426 | RMSE=0.03073 | best=0.03073 | patience=8\n",
        "    Epoch 15 | train_loss=0.000422 | RMSE=0.03311 | best=0.03073 | patience=3\n",
        "  FINAL: MAE=0.030732 RMSE=0.030732 best_epoch=10\n",
        "\n",
        ">>> light_xxxwide + Load-type (n=2 h=192 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.065208 | RMSE=0.04523 | best=0.04523 | patience=8\n",
        "    Epoch 05 | train_loss=0.000142 | RMSE=0.01857 | best=0.01857 | patience=8\n",
        "    Epoch 10 | train_loss=0.000131 | RMSE=0.02012 | best=0.01857 | patience=7\n",
        "    Epoch 15 | train_loss=0.000122 | RMSE=0.01677 | best=0.01564 | patience=4\n",
        "  FINAL: MAE=0.015641 RMSE=0.015641 best_epoch=11\n",
        "\n",
        ">>> light_xwide_emb + Original (n=2 h=128 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.033506 | RMSE=0.05679 | best=0.05679 | patience=8\n",
        "    Epoch 05 | train_loss=0.000462 | RMSE=0.03557 | best=0.03433 | patience=8\n",
        "    Epoch 10 | train_loss=0.000453 | RMSE=0.03757 | best=0.03325 | patience=7\n",
        "    Epoch 15 | train_loss=0.000396 | RMSE=0.03330 | best=0.03104 | patience=6\n",
        "    Epoch 20 | train_loss=0.000370 | RMSE=0.03658 | best=0.02999 | patience=6\n",
        "    Epoch 25 | train_loss=0.000386 | RMSE=0.02987 | best=0.02947 | patience=7\n",
        "    Epoch 30 | train_loss=0.000369 | RMSE=0.03050 | best=0.02947 | patience=2\n",
        "  FINAL: MAE=0.029474 RMSE=0.029474 best_epoch=24\n",
        "\n",
        ">>> light_xwide_emb + Derived (n=2 h=128 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.034125 | RMSE=0.06415 | best=0.06415 | patience=8\n",
        "    Epoch 05 | train_loss=0.000484 | RMSE=0.03829 | best=0.03616 | patience=8\n",
        "    Epoch 10 | train_loss=0.000487 | RMSE=0.04640 | best=0.03420 | patience=7\n",
        "    Epoch 15 | train_loss=0.000400 | RMSE=0.03228 | best=0.03227 | patience=7\n",
        "    Epoch 20 | train_loss=0.000415 | RMSE=0.03235 | best=0.03206 | patience=6\n",
        "    Epoch 25 | train_loss=0.000383 | RMSE=0.03151 | best=0.03134 | patience=6\n",
        "    Epoch 30 | train_loss=0.000362 | RMSE=0.03374 | best=0.03067 | patience=7\n",
        "    Epoch 35 | train_loss=0.000370 | RMSE=0.03614 | best=0.03067 | patience=2\n",
        "  FINAL: MAE=0.030672 RMSE=0.030672 best_epoch=29\n",
        "\n",
        ">>> light_xwide_emb + Load-type (n=2 h=128 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.039430 | RMSE=0.02792 | best=0.02792 | patience=8\n",
        "    Epoch 05 | train_loss=0.000146 | RMSE=0.01751 | best=0.01751 | patience=8\n",
        "    Epoch 10 | train_loss=0.000127 | RMSE=0.02443 | best=0.01606 | patience=7\n",
        "    Epoch 15 | train_loss=0.000188 | RMSE=0.01598 | best=0.01598 | patience=8\n",
        "    Epoch 20 | train_loss=0.000135 | RMSE=0.01524 | best=0.01524 | patience=8\n",
        "    Epoch 25 | train_loss=0.000139 | RMSE=0.02004 | best=0.01524 | patience=3\n",
        "  FINAL: MAE=0.015236 RMSE=0.015236 best_epoch=20\n",
        "\n",
        ">>> light_wide_h96 + Original (n=2 h=96 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.048396 | RMSE=0.05514 | best=0.05514 | patience=8\n",
        "    Epoch 05 | train_loss=0.000491 | RMSE=0.03305 | best=0.03305 | patience=8\n",
        "    Epoch 10 | train_loss=0.000389 | RMSE=0.03955 | best=0.03068 | patience=7\n",
        "    Epoch 15 | train_loss=0.000425 | RMSE=0.03096 | best=0.03068 | patience=2\n",
        "    Epoch 20 | train_loss=0.000402 | RMSE=0.03033 | best=0.02940 | patience=4\n",
        "  FINAL: MAE=0.029396 RMSE=0.029396 best_epoch=16\n",
        "\n",
        ">>> light_wide_h96 + Derived (n=2 h=96 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.027096 | RMSE=0.05828 | best=0.05828 | patience=8\n",
        "    Epoch 05 | train_loss=0.000493 | RMSE=0.03500 | best=0.03500 | patience=8\n",
        "    Epoch 10 | train_loss=0.000390 | RMSE=0.03120 | best=0.03120 | patience=8\n",
        "    Epoch 15 | train_loss=0.000383 | RMSE=0.03240 | best=0.03120 | patience=3\n",
        "    Epoch 20 | train_loss=0.000393 | RMSE=0.03962 | best=0.03057 | patience=6\n",
        "    Epoch 25 | train_loss=0.000388 | RMSE=0.03915 | best=0.03046 | patience=5\n",
        "    Epoch 30 | train_loss=0.000359 | RMSE=0.03098 | best=0.03046 | patience=0\n",
        "  FINAL: MAE=0.030463 RMSE=0.030463 best_epoch=22\n",
        "\n",
        ">>> light_wide_h96 + Load-type (n=2 h=96 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.037758 | RMSE=0.05632 | best=0.05632 | patience=8\n",
        "    Epoch 05 | train_loss=0.000185 | RMSE=0.02020 | best=0.02020 | patience=8\n",
        "    Epoch 10 | train_loss=0.000140 | RMSE=0.01608 | best=0.01608 | patience=8\n",
        "    Epoch 15 | train_loss=0.000114 | RMSE=0.01816 | best=0.01608 | patience=3\n",
        "  FINAL: MAE=0.016079 RMSE=0.016079 best_epoch=10\n",
        "\n",
        ">>> light_h80 + Original (n=2 h=80 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.031186 | RMSE=0.05377 | best=0.05377 | patience=8\n",
        "    Epoch 05 | train_loss=0.000461 | RMSE=0.03387 | best=0.03387 | patience=8\n",
        "    Epoch 10 | train_loss=0.000432 | RMSE=0.04077 | best=0.03235 | patience=7\n",
        "    Epoch 15 | train_loss=0.000359 | RMSE=0.03013 | best=0.03013 | patience=8\n",
        "    Epoch 20 | train_loss=0.000378 | RMSE=0.02919 | best=0.02891 | patience=4\n",
        "  FINAL: MAE=0.028912 RMSE=0.028912 best_epoch=16\n",
        "\n",
        ">>> light_h80 + Derived (n=2 h=80 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.037007 | RMSE=0.05522 | best=0.05522 | patience=8\n",
        "    Epoch 05 | train_loss=0.000543 | RMSE=0.04235 | best=0.04001 | patience=8\n",
        "    Epoch 10 | train_loss=0.000443 | RMSE=0.04089 | best=0.03375 | patience=7\n",
        "    Epoch 15 | train_loss=0.000413 | RMSE=0.04640 | best=0.03271 | patience=6\n",
        "    Epoch 20 | train_loss=0.000392 | RMSE=0.03067 | best=0.03064 | patience=6\n",
        "    Epoch 25 | train_loss=0.000359 | RMSE=0.03093 | best=0.03064 | patience=1\n",
        "  FINAL: MAE=0.030639 RMSE=0.030639 best_epoch=18\n",
        "\n",
        ">>> light_h80 + Load-type (n=2 h=80 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.060571 | RMSE=0.06049 | best=0.06049 | patience=8\n",
        "    Epoch 05 | train_loss=0.000179 | RMSE=0.02294 | best=0.01991 | patience=8\n",
        "    Epoch 10 | train_loss=0.000140 | RMSE=0.02594 | best=0.01878 | patience=7\n",
        "    Epoch 15 | train_loss=0.000116 | RMSE=0.01650 | best=0.01628 | patience=5\n",
        "    Epoch 20 | train_loss=0.000112 | RMSE=0.01767 | best=0.01628 | patience=0\n",
        "  FINAL: MAE=0.016278 RMSE=0.016278 best_epoch=12\n",
        "\n",
        ">>> light_h112 + Original (n=2 h=112 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.043935 | RMSE=0.06174 | best=0.06174 | patience=8\n",
        "    Epoch 05 | train_loss=0.000505 | RMSE=0.03758 | best=0.03398 | patience=8\n",
        "    Epoch 10 | train_loss=0.000406 | RMSE=0.03489 | best=0.03199 | patience=7\n",
        "    Epoch 15 | train_loss=0.000459 | RMSE=0.05266 | best=0.03047 | patience=7\n",
        "    Epoch 20 | train_loss=0.000436 | RMSE=0.03023 | best=0.03023 | patience=8\n",
        "    Epoch 25 | train_loss=0.000382 | RMSE=0.03207 | best=0.03023 | patience=3\n",
        "  FINAL: MAE=0.030233 RMSE=0.030233 best_epoch=20\n",
        "\n",
        ">>> light_h112 + Derived (n=2 h=112 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.036475 | RMSE=0.05191 | best=0.05191 | patience=8\n",
        "    Epoch 05 | train_loss=0.000516 | RMSE=0.03698 | best=0.03643 | patience=8\n",
        "    Epoch 10 | train_loss=0.000492 | RMSE=0.03411 | best=0.03255 | patience=7\n",
        "    Epoch 15 | train_loss=0.000428 | RMSE=0.04972 | best=0.03237 | patience=7\n",
        "    Epoch 20 | train_loss=0.000421 | RMSE=0.03270 | best=0.03155 | patience=6\n",
        "    Epoch 25 | train_loss=0.000379 | RMSE=0.03196 | best=0.03155 | patience=1\n",
        "    Epoch 30 | train_loss=0.000365 | RMSE=0.03030 | best=0.03030 | patience=8\n",
        "    Epoch 35 | train_loss=0.000370 | RMSE=0.03052 | best=0.03030 | patience=3\n",
        "  FINAL: MAE=0.030303 RMSE=0.030303 best_epoch=30\n",
        "\n",
        ">>> light_h112 + Load-type (n=2 h=112 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.031547 | RMSE=0.04289 | best=0.04289 | patience=8\n",
        "    Epoch 05 | train_loss=0.000173 | RMSE=0.02131 | best=0.02131 | patience=8\n",
        "    Epoch 10 | train_loss=0.000159 | RMSE=0.01989 | best=0.01771 | patience=7\n",
        "    Epoch 15 | train_loss=0.000118 | RMSE=0.01708 | best=0.01561 | patience=6\n",
        "    Epoch 20 | train_loss=0.000109 | RMSE=0.01841 | best=0.01561 | patience=1\n",
        "  FINAL: MAE=0.015612 RMSE=0.015612 best_epoch=13\n",
        "\n",
        ">>> wide_shallow_h96 + Original (n=2 h=96 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.048384 | RMSE=0.05271 | best=0.05271 | patience=8\n",
        "    Epoch 05 | train_loss=0.000516 | RMSE=0.03475 | best=0.03475 | patience=8\n",
        "    Epoch 10 | train_loss=0.000409 | RMSE=0.04082 | best=0.03171 | patience=7\n",
        "    Epoch 15 | train_loss=0.000445 | RMSE=0.03017 | best=0.03017 | patience=8\n",
        "    Epoch 20 | train_loss=0.000413 | RMSE=0.03029 | best=0.03017 | patience=3\n",
        "  FINAL: MAE=0.030169 RMSE=0.030169 best_epoch=15\n",
        "\n",
        ">>> wide_shallow_h96 + Derived (n=2 h=96 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.027097 | RMSE=0.05823 | best=0.05823 | patience=8\n",
        "    Epoch 05 | train_loss=0.000491 | RMSE=0.03489 | best=0.03489 | patience=8\n",
        "    Epoch 10 | train_loss=0.000390 | RMSE=0.03146 | best=0.03146 | patience=8\n",
        "    Epoch 15 | train_loss=0.000381 | RMSE=0.03226 | best=0.03146 | patience=3\n",
        "    Epoch 20 | train_loss=0.000393 | RMSE=0.03943 | best=0.03053 | patience=6\n",
        "    Epoch 25 | train_loss=0.000390 | RMSE=0.03866 | best=0.03048 | patience=5\n",
        "    Epoch 30 | train_loss=0.000359 | RMSE=0.03097 | best=0.03048 | patience=0\n",
        "  FINAL: MAE=0.030476 RMSE=0.030476 best_epoch=22\n",
        "\n",
        ">>> wide_shallow_h96 + Load-type (n=2 h=96 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.037812 | RMSE=0.05380 | best=0.05380 | patience=8\n",
        "    Epoch 05 | train_loss=0.000188 | RMSE=0.02048 | best=0.02048 | patience=8\n",
        "    Epoch 10 | train_loss=0.000131 | RMSE=0.01604 | best=0.01604 | patience=8\n",
        "    Epoch 15 | train_loss=0.000116 | RMSE=0.01712 | best=0.01604 | patience=3\n",
        "  FINAL: MAE=0.016039 RMSE=0.016039 best_epoch=10\n",
        "\n",
        ">>> wide_shallow_h160 + Original (n=2 h=160 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.022750 | RMSE=0.04757 | best=0.04757 | patience=8\n",
        "    Epoch 05 | train_loss=0.000457 | RMSE=0.03385 | best=0.03385 | patience=8\n",
        "    Epoch 10 | train_loss=0.000389 | RMSE=0.03765 | best=0.03189 | patience=7\n",
        "    Epoch 15 | train_loss=0.000393 | RMSE=0.03356 | best=0.03022 | patience=5\n",
        "    Epoch 20 | train_loss=0.000398 | RMSE=0.02924 | best=0.02893 | patience=7\n",
        "    Epoch 25 | train_loss=0.000346 | RMSE=0.04242 | best=0.02893 | patience=2\n",
        "  FINAL: MAE=0.028930 RMSE=0.028930 best_epoch=19\n",
        "\n",
        ">>> wide_shallow_h160 + Derived (n=2 h=160 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.026290 | RMSE=0.04843 | best=0.04843 | patience=8\n",
        "    Epoch 05 | train_loss=0.000503 | RMSE=0.03744 | best=0.03744 | patience=8\n",
        "    Epoch 10 | train_loss=0.000418 | RMSE=0.03342 | best=0.03207 | patience=7\n",
        "    Epoch 15 | train_loss=0.000470 | RMSE=0.03403 | best=0.03152 | patience=7\n",
        "    Epoch 20 | train_loss=0.000382 | RMSE=0.03844 | best=0.03133 | patience=4\n",
        "  FINAL: MAE=0.031335 RMSE=0.031335 best_epoch=16\n",
        "\n",
        ">>> wide_shallow_h160 + Load-type (n=2 h=160 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.053327 | RMSE=0.03925 | best=0.03925 | patience=8\n",
        "    Epoch 05 | train_loss=0.000139 | RMSE=0.01898 | best=0.01898 | patience=8\n",
        "    Epoch 10 | train_loss=0.000104 | RMSE=0.01802 | best=0.01802 | patience=8\n",
        "    Epoch 15 | train_loss=0.000135 | RMSE=0.02519 | best=0.01604 | patience=7\n",
        "    Epoch 20 | train_loss=0.000127 | RMSE=0.01577 | best=0.01542 | patience=6\n",
        "    Epoch 25 | train_loss=0.000161 | RMSE=0.01646 | best=0.01542 | patience=1\n",
        "  FINAL: MAE=0.015417 RMSE=0.015417 best_epoch=18\n",
        "\n",
        ">>> light_emb_h96 + Original (n=2 h=96 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.046058 | RMSE=0.05339 | best=0.05339 | patience=8\n",
        "    Epoch 05 | train_loss=0.000462 | RMSE=0.03363 | best=0.03363 | patience=8\n",
        "    Epoch 10 | train_loss=0.000447 | RMSE=0.03508 | best=0.03235 | patience=7\n",
        "    Epoch 15 | train_loss=0.000401 | RMSE=0.02956 | best=0.02956 | patience=8\n",
        "    Epoch 20 | train_loss=0.000387 | RMSE=0.03001 | best=0.02956 | patience=3\n",
        "    Epoch 25 | train_loss=0.000369 | RMSE=0.03384 | best=0.02906 | patience=6\n",
        "    Epoch 30 | train_loss=0.000327 | RMSE=0.03006 | best=0.02906 | patience=1\n",
        "  FINAL: MAE=0.029059 RMSE=0.029059 best_epoch=23\n",
        "\n",
        ">>> light_emb_h96 + Derived (n=2 h=96 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.027515 | RMSE=0.05206 | best=0.05206 | patience=8\n",
        "    Epoch 05 | train_loss=0.000481 | RMSE=0.06040 | best=0.03846 | patience=8\n",
        "    Epoch 10 | train_loss=0.000522 | RMSE=0.03675 | best=0.03529 | patience=7\n",
        "    Epoch 15 | train_loss=0.000391 | RMSE=0.03386 | best=0.03226 | patience=6\n",
        "    Epoch 20 | train_loss=0.000383 | RMSE=0.03816 | best=0.03203 | patience=4\n",
        "    Epoch 25 | train_loss=0.000367 | RMSE=0.03705 | best=0.03097 | patience=5\n",
        "    Epoch 30 | train_loss=0.000388 | RMSE=0.03068 | best=0.03034 | patience=7\n",
        "    Epoch 35 | train_loss=0.000371 | RMSE=0.04908 | best=0.03034 | patience=2\n",
        "    Epoch 40 | train_loss=0.000359 | RMSE=0.03012 | best=0.03005 | patience=7\n",
        "  FINAL: MAE=0.030051 RMSE=0.030051 best_epoch=39\n",
        "\n",
        ">>> light_emb_h96 + Load-type (n=2 h=96 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.046952 | RMSE=0.03832 | best=0.03832 | patience=8\n",
        "    Epoch 05 | train_loss=0.000168 | RMSE=0.02560 | best=0.02130 | patience=8\n",
        "    Epoch 10 | train_loss=0.000136 | RMSE=0.01717 | best=0.01717 | patience=8\n",
        "    Epoch 15 | train_loss=0.000108 | RMSE=0.01549 | best=0.01549 | patience=8\n",
        "    Epoch 20 | train_loss=0.000126 | RMSE=0.01586 | best=0.01513 | patience=6\n",
        "    Epoch 25 | train_loss=0.000103 | RMSE=0.01634 | best=0.01513 | patience=1\n",
        "  FINAL: MAE=0.015133 RMSE=0.015133 best_epoch=18\n",
        "\n",
        ">>> light_xxwide_emb + Original (n=2 h=160 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.033243 | RMSE=0.05565 | best=0.05565 | patience=8\n",
        "    Epoch 05 | train_loss=0.000472 | RMSE=0.03303 | best=0.03303 | patience=8\n",
        "    Epoch 10 | train_loss=0.000383 | RMSE=0.03140 | best=0.03140 | patience=8\n",
        "    Epoch 15 | train_loss=0.000362 | RMSE=0.02946 | best=0.02946 | patience=8\n",
        "    Epoch 20 | train_loss=0.000409 | RMSE=0.03348 | best=0.02946 | patience=3\n",
        "  FINAL: MAE=0.029457 RMSE=0.029457 best_epoch=15\n",
        "\n",
        ">>> light_xxwide_emb + Derived (n=2 h=160 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.027448 | RMSE=0.05259 | best=0.05259 | patience=8\n",
        "    Epoch 05 | train_loss=0.000488 | RMSE=0.03889 | best=0.03768 | patience=8\n",
        "    Epoch 10 | train_loss=0.000466 | RMSE=0.03241 | best=0.03241 | patience=8\n",
        "    Epoch 15 | train_loss=0.000428 | RMSE=0.03909 | best=0.03106 | patience=4\n",
        "    Epoch 20 | train_loss=0.000389 | RMSE=0.03967 | best=0.03070 | patience=6\n",
        "    Epoch 25 | train_loss=0.000445 | RMSE=0.03155 | best=0.03069 | patience=7\n",
        "    Epoch 30 | train_loss=0.000381 | RMSE=0.03239 | best=0.03049 | patience=5\n",
        "    Epoch 35 | train_loss=0.000374 | RMSE=0.03150 | best=0.03049 | patience=0\n",
        "  FINAL: MAE=0.030487 RMSE=0.030487 best_epoch=27\n",
        "\n",
        ">>> light_xxwide_emb + Load-type (n=2 h=160 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.041701 | RMSE=0.03725 | best=0.03725 | patience=8\n",
        "    Epoch 05 | train_loss=0.000152 | RMSE=0.03447 | best=0.01850 | patience=8\n",
        "    Epoch 10 | train_loss=0.000112 | RMSE=0.01611 | best=0.01611 | patience=8\n",
        "    Epoch 15 | train_loss=0.000118 | RMSE=0.01979 | best=0.01561 | patience=6\n",
        "    Epoch 20 | train_loss=0.000121 | RMSE=0.01909 | best=0.01561 | patience=1\n",
        "  FINAL: MAE=0.015610 RMSE=0.015610 best_epoch=13\n",
        "\n",
        ">>> light_xxxwide_emb + Original (n=2 h=192 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.029738 | RMSE=0.05453 | best=0.05453 | patience=8\n",
        "    Epoch 05 | train_loss=0.000456 | RMSE=0.03310 | best=0.03310 | patience=8\n",
        "    Epoch 10 | train_loss=0.000474 | RMSE=0.03484 | best=0.03286 | patience=7\n",
        "    Epoch 15 | train_loss=0.000423 | RMSE=0.05812 | best=0.03063 | patience=4\n",
        "  FINAL: MAE=0.030626 RMSE=0.030626 best_epoch=11\n",
        "\n",
        ">>> light_xxxwide_emb + Derived (n=2 h=192 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.025082 | RMSE=0.04507 | best=0.04507 | patience=8\n",
        "    Epoch 05 | train_loss=0.000512 | RMSE=0.03478 | best=0.03478 | patience=8\n",
        "    Epoch 10 | train_loss=0.000467 | RMSE=0.03349 | best=0.03349 | patience=8\n",
        "    Epoch 15 | train_loss=0.000454 | RMSE=0.03441 | best=0.03313 | patience=7\n",
        "    Epoch 20 | train_loss=0.000400 | RMSE=0.03090 | best=0.03090 | patience=8\n",
        "    Epoch 25 | train_loss=0.000396 | RMSE=0.03552 | best=0.03058 | patience=6\n",
        "    Epoch 30 | train_loss=0.000352 | RMSE=0.03084 | best=0.03058 | patience=1\n",
        "  FINAL: MAE=0.030576 RMSE=0.030576 best_epoch=23\n",
        "\n",
        ">>> light_xxxwide_emb + Load-type (n=2 h=192 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.023646 | RMSE=0.03105 | best=0.03105 | patience=8\n",
        "    Epoch 05 | train_loss=0.000188 | RMSE=0.01961 | best=0.01809 | patience=8\n",
        "    Epoch 10 | train_loss=0.000146 | RMSE=0.01792 | best=0.01594 | patience=7\n",
        "    Epoch 15 | train_loss=0.000146 | RMSE=0.02031 | best=0.01547 | patience=4\n",
        "  FINAL: MAE=0.015473 RMSE=0.015473 best_epoch=11\n",
        "\n",
        ">>> light_h144 + Original (n=2 h=144 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.028215 | RMSE=0.05069 | best=0.05069 | patience=8\n",
        "    Epoch 05 | train_loss=0.000473 | RMSE=0.03742 | best=0.03742 | patience=8\n",
        "    Epoch 10 | train_loss=0.000397 | RMSE=0.03201 | best=0.03159 | patience=7\n",
        "    Epoch 15 | train_loss=0.000375 | RMSE=0.02920 | best=0.02901 | patience=6\n",
        "    Epoch 20 | train_loss=0.000391 | RMSE=0.05412 | best=0.02901 | patience=1\n",
        "  FINAL: MAE=0.029013 RMSE=0.029013 best_epoch=13\n",
        "\n",
        ">>> light_h144 + Derived (n=2 h=144 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.035849 | RMSE=0.04343 | best=0.04343 | patience=8\n",
        "    Epoch 05 | train_loss=0.000493 | RMSE=0.03618 | best=0.03604 | patience=8\n",
        "    Epoch 10 | train_loss=0.000422 | RMSE=0.04924 | best=0.03269 | patience=7\n",
        "    Epoch 15 | train_loss=0.000456 | RMSE=0.03176 | best=0.03176 | patience=8\n",
        "    Epoch 20 | train_loss=0.000406 | RMSE=0.04028 | best=0.03150 | patience=5\n",
        "    Epoch 25 | train_loss=0.000361 | RMSE=0.03486 | best=0.03046 | patience=6\n",
        "    Epoch 30 | train_loss=0.000386 | RMSE=0.03611 | best=0.03046 | patience=1\n",
        "  FINAL: MAE=0.030463 RMSE=0.030463 best_epoch=23\n",
        "\n",
        ">>> light_h144 + Load-type (n=2 h=144 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.028496 | RMSE=0.04000 | best=0.04000 | patience=8\n",
        "    Epoch 05 | train_loss=0.000121 | RMSE=0.01831 | best=0.01752 | patience=8\n",
        "    Epoch 10 | train_loss=0.000131 | RMSE=0.02010 | best=0.01632 | patience=7\n",
        "    Epoch 15 | train_loss=0.000137 | RMSE=0.02679 | best=0.01632 | patience=2\n",
        "    Epoch 20 | train_loss=0.000133 | RMSE=0.02202 | best=0.01569 | patience=4\n",
        "  FINAL: MAE=0.015695 RMSE=0.015695 best_epoch=16\n",
        "\n",
        ">>> light_h176 + Original (n=2 h=176 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.037669 | RMSE=0.04697 | best=0.04697 | patience=8\n",
        "    Epoch 05 | train_loss=0.000547 | RMSE=0.03848 | best=0.03502 | patience=8\n",
        "    Epoch 10 | train_loss=0.000404 | RMSE=0.03508 | best=0.03422 | patience=7\n",
        "    Epoch 15 | train_loss=0.000402 | RMSE=0.03028 | best=0.03028 | patience=8\n",
        "    Epoch 20 | train_loss=0.000408 | RMSE=0.03205 | best=0.03028 | patience=3\n",
        "  FINAL: MAE=0.030284 RMSE=0.030284 best_epoch=15\n",
        "\n",
        ">>> light_h176 + Derived (n=2 h=176 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.031436 | RMSE=0.05254 | best=0.05254 | patience=8\n",
        "    Epoch 05 | train_loss=0.000471 | RMSE=0.03665 | best=0.03651 | patience=8\n",
        "    Epoch 10 | train_loss=0.000424 | RMSE=0.03269 | best=0.03269 | patience=8\n",
        "    Epoch 15 | train_loss=0.000415 | RMSE=0.03130 | best=0.03130 | patience=8\n",
        "    Epoch 20 | train_loss=0.000460 | RMSE=0.03219 | best=0.03130 | patience=3\n",
        "    Epoch 25 | train_loss=0.000421 | RMSE=0.03622 | best=0.03094 | patience=4\n",
        "  FINAL: MAE=0.030944 RMSE=0.030944 best_epoch=21\n",
        "\n",
        ">>> light_h176 + Load-type (n=2 h=176 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.060436 | RMSE=0.05813 | best=0.05813 | patience=8\n",
        "    Epoch 05 | train_loss=0.000193 | RMSE=0.01966 | best=0.01966 | patience=8\n",
        "    Epoch 10 | train_loss=0.000123 | RMSE=0.01705 | best=0.01647 | patience=7\n",
        "    Epoch 15 | train_loss=0.000135 | RMSE=0.02208 | best=0.01647 | patience=2\n",
        "  FINAL: MAE=0.016472 RMSE=0.016472 best_epoch=9\n",
        "\n",
        ">>> light_wide_h80 + Original (n=2 h=80 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.031186 | RMSE=0.05375 | best=0.05375 | patience=8\n",
        "    Epoch 05 | train_loss=0.000461 | RMSE=0.03463 | best=0.03463 | patience=8\n",
        "    Epoch 10 | train_loss=0.000434 | RMSE=0.04087 | best=0.03238 | patience=7\n",
        "    Epoch 15 | train_loss=0.000361 | RMSE=0.02985 | best=0.02985 | patience=8\n",
        "    Epoch 20 | train_loss=0.000377 | RMSE=0.02917 | best=0.02898 | patience=4\n",
        "  FINAL: MAE=0.028982 RMSE=0.028982 best_epoch=16\n",
        "\n",
        ">>> light_wide_h80 + Derived (n=2 h=80 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.037007 | RMSE=0.05465 | best=0.05465 | patience=8\n",
        "    Epoch 05 | train_loss=0.000536 | RMSE=0.04498 | best=0.04073 | patience=8\n",
        "    Epoch 10 | train_loss=0.000445 | RMSE=0.03912 | best=0.03363 | patience=7\n",
        "    Epoch 15 | train_loss=0.000416 | RMSE=0.04858 | best=0.03270 | patience=6\n",
        "    Epoch 20 | train_loss=0.000406 | RMSE=0.03106 | best=0.03103 | patience=6\n",
        "    Epoch 25 | train_loss=0.000367 | RMSE=0.03183 | best=0.03103 | patience=1\n",
        "  FINAL: MAE=0.031032 RMSE=0.031032 best_epoch=18\n",
        "\n",
        ">>> light_wide_h80 + Load-type (n=2 h=80 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.060569 | RMSE=0.06101 | best=0.06101 | patience=8\n",
        "    Epoch 05 | train_loss=0.000173 | RMSE=0.02279 | best=0.02113 | patience=8\n",
        "    Epoch 10 | train_loss=0.000137 | RMSE=0.03013 | best=0.02034 | patience=7\n",
        "    Epoch 15 | train_loss=0.000127 | RMSE=0.02842 | best=0.01648 | patience=7\n",
        "    Epoch 20 | train_loss=0.000118 | RMSE=0.01968 | best=0.01602 | patience=7\n",
        "    Epoch 25 | train_loss=0.000123 | RMSE=0.03186 | best=0.01602 | patience=2\n",
        "  FINAL: MAE=0.016018 RMSE=0.016018 best_epoch=19\n",
        "\n",
        ">>> light_wide_h112 + Original (n=2 h=112 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.043935 | RMSE=0.06147 | best=0.06147 | patience=8\n",
        "    Epoch 05 | train_loss=0.000505 | RMSE=0.03695 | best=0.03434 | patience=8\n",
        "    Epoch 10 | train_loss=0.000413 | RMSE=0.03643 | best=0.03171 | patience=7\n",
        "    Epoch 15 | train_loss=0.000458 | RMSE=0.05226 | best=0.03067 | patience=7\n",
        "    Epoch 20 | train_loss=0.000437 | RMSE=0.03032 | best=0.03032 | patience=8\n",
        "    Epoch 25 | train_loss=0.000388 | RMSE=0.03363 | best=0.03032 | patience=3\n",
        "    Epoch 30 | train_loss=0.000359 | RMSE=0.05098 | best=0.02925 | patience=6\n",
        "    Epoch 35 | train_loss=0.000356 | RMSE=0.04158 | best=0.02925 | patience=1\n",
        "  FINAL: MAE=0.029250 RMSE=0.029250 best_epoch=28\n",
        "\n",
        ">>> light_wide_h112 + Derived (n=2 h=112 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.036480 | RMSE=0.05301 | best=0.05301 | patience=8\n",
        "    Epoch 05 | train_loss=0.000513 | RMSE=0.03758 | best=0.03640 | patience=8\n",
        "    Epoch 10 | train_loss=0.000491 | RMSE=0.03422 | best=0.03282 | patience=7\n",
        "    Epoch 15 | train_loss=0.000431 | RMSE=0.04943 | best=0.03267 | patience=7\n",
        "    Epoch 20 | train_loss=0.000421 | RMSE=0.03346 | best=0.03179 | patience=6\n",
        "    Epoch 25 | train_loss=0.000376 | RMSE=0.03229 | best=0.03142 | patience=4\n",
        "    Epoch 30 | train_loss=0.000364 | RMSE=0.03030 | best=0.03030 | patience=8\n",
        "    Epoch 35 | train_loss=0.000367 | RMSE=0.03049 | best=0.03030 | patience=3\n",
        "  FINAL: MAE=0.030304 RMSE=0.030304 best_epoch=30\n",
        "\n",
        ">>> light_wide_h112 + Load-type (n=2 h=112 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.031437 | RMSE=0.04141 | best=0.04141 | patience=8\n",
        "    Epoch 05 | train_loss=0.000178 | RMSE=0.02465 | best=0.02026 | patience=8\n",
        "    Epoch 10 | train_loss=0.000167 | RMSE=0.02284 | best=0.01783 | patience=7\n",
        "    Epoch 15 | train_loss=0.000119 | RMSE=0.02216 | best=0.01560 | patience=6\n",
        "    Epoch 20 | train_loss=0.000110 | RMSE=0.01882 | best=0.01560 | patience=1\n",
        "  FINAL: MAE=0.015601 RMSE=0.015601 best_epoch=13\n",
        "\n",
        ">>> light_xwide_h96 + Original (n=2 h=96 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.048387 | RMSE=0.05502 | best=0.05502 | patience=8\n",
        "    Epoch 05 | train_loss=0.000496 | RMSE=0.03383 | best=0.03383 | patience=8\n",
        "    Epoch 10 | train_loss=0.000407 | RMSE=0.04074 | best=0.03159 | patience=7\n",
        "    Epoch 15 | train_loss=0.000435 | RMSE=0.03108 | best=0.03108 | patience=8\n",
        "    Epoch 20 | train_loss=0.000402 | RMSE=0.02985 | best=0.02950 | patience=4\n",
        "  FINAL: MAE=0.029499 RMSE=0.029499 best_epoch=16\n",
        "\n",
        ">>> light_xwide_h96 + Derived (n=2 h=96 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.027094 | RMSE=0.05934 | best=0.05934 | patience=8\n",
        "    Epoch 05 | train_loss=0.000492 | RMSE=0.03487 | best=0.03487 | patience=8\n",
        "    Epoch 10 | train_loss=0.000388 | RMSE=0.03115 | best=0.03115 | patience=8\n",
        "    Epoch 15 | train_loss=0.000382 | RMSE=0.03237 | best=0.03115 | patience=3\n",
        "    Epoch 20 | train_loss=0.000392 | RMSE=0.03959 | best=0.03052 | patience=6\n",
        "    Epoch 25 | train_loss=0.000389 | RMSE=0.03839 | best=0.03052 | patience=1\n",
        "  FINAL: MAE=0.030525 RMSE=0.030525 best_epoch=18\n",
        "\n",
        ">>> light_xwide_h96 + Load-type (n=2 h=96 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.037798 | RMSE=0.05497 | best=0.05497 | patience=8\n",
        "    Epoch 05 | train_loss=0.000165 | RMSE=0.01953 | best=0.01953 | patience=8\n",
        "    Epoch 10 | train_loss=0.000129 | RMSE=0.01624 | best=0.01624 | patience=8\n",
        "    Epoch 15 | train_loss=0.000113 | RMSE=0.01655 | best=0.01624 | patience=3\n",
        "    Epoch 20 | train_loss=0.000118 | RMSE=0.01846 | best=0.01571 | patience=5\n",
        "    Epoch 25 | train_loss=0.000129 | RMSE=0.01703 | best=0.01571 | patience=0\n",
        "  FINAL: MAE=0.015707 RMSE=0.015707 best_epoch=17\n",
        "\n",
        ">>> wide_shallow_h112 + Original (n=2 h=112 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.043935 | RMSE=0.06132 | best=0.06132 | patience=8\n",
        "    Epoch 05 | train_loss=0.000500 | RMSE=0.03684 | best=0.03461 | patience=8\n",
        "    Epoch 10 | train_loss=0.000415 | RMSE=0.03829 | best=0.03178 | patience=7\n",
        "    Epoch 15 | train_loss=0.000454 | RMSE=0.05237 | best=0.03036 | patience=7\n",
        "    Epoch 20 | train_loss=0.000436 | RMSE=0.03025 | best=0.03025 | patience=8\n",
        "    Epoch 25 | train_loss=0.000385 | RMSE=0.03243 | best=0.03025 | patience=3\n",
        "    Epoch 30 | train_loss=0.000358 | RMSE=0.05121 | best=0.02929 | patience=6\n",
        "    Epoch 35 | train_loss=0.000359 | RMSE=0.04182 | best=0.02929 | patience=1\n",
        "  FINAL: MAE=0.029294 RMSE=0.029294 best_epoch=28\n",
        "\n",
        ">>> wide_shallow_h112 + Derived (n=2 h=112 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.036472 | RMSE=0.05349 | best=0.05349 | patience=8\n",
        "    Epoch 05 | train_loss=0.000510 | RMSE=0.03649 | best=0.03649 | patience=8\n",
        "    Epoch 10 | train_loss=0.000494 | RMSE=0.03284 | best=0.03271 | patience=7\n",
        "    Epoch 15 | train_loss=0.000434 | RMSE=0.04952 | best=0.03154 | patience=7\n",
        "    Epoch 20 | train_loss=0.000416 | RMSE=0.03266 | best=0.03139 | patience=6\n",
        "    Epoch 25 | train_loss=0.000378 | RMSE=0.03279 | best=0.03128 | patience=4\n",
        "    Epoch 30 | train_loss=0.000364 | RMSE=0.03023 | best=0.03023 | patience=8\n",
        "    Epoch 35 | train_loss=0.000369 | RMSE=0.03046 | best=0.03023 | patience=3\n",
        "  FINAL: MAE=0.030228 RMSE=0.030228 best_epoch=30\n",
        "\n",
        ">>> wide_shallow_h112 + Load-type (n=2 h=112 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.031649 | RMSE=0.05570 | best=0.05570 | patience=8\n",
        "    Epoch 05 | train_loss=0.000183 | RMSE=0.01985 | best=0.01985 | patience=8\n",
        "    Epoch 10 | train_loss=0.000142 | RMSE=0.01871 | best=0.01834 | patience=7\n",
        "    Epoch 15 | train_loss=0.000117 | RMSE=0.01895 | best=0.01574 | patience=6\n",
        "    Epoch 20 | train_loss=0.000110 | RMSE=0.02028 | best=0.01574 | patience=1\n",
        "  FINAL: MAE=0.015735 RMSE=0.015735 best_epoch=13\n",
        "\n",
        ">>> light_emb_h80 + Original (n=2 h=80 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.035505 | RMSE=0.05204 | best=0.05204 | patience=8\n",
        "    Epoch 05 | train_loss=0.000453 | RMSE=0.04662 | best=0.03769 | patience=8\n",
        "    Epoch 10 | train_loss=0.000453 | RMSE=0.03278 | best=0.03278 | patience=8\n",
        "    Epoch 15 | train_loss=0.000381 | RMSE=0.03373 | best=0.02939 | patience=7\n",
        "    Epoch 20 | train_loss=0.000393 | RMSE=0.03426 | best=0.02939 | patience=2\n",
        "  FINAL: MAE=0.029385 RMSE=0.029385 best_epoch=14\n",
        "\n",
        ">>> light_emb_h80 + Derived (n=2 h=80 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.040720 | RMSE=0.05257 | best=0.05257 | patience=8\n",
        "    Epoch 05 | train_loss=0.000511 | RMSE=0.03888 | best=0.03888 | patience=8\n",
        "    Epoch 10 | train_loss=0.000466 | RMSE=0.03382 | best=0.03382 | patience=8\n",
        "    Epoch 15 | train_loss=0.000429 | RMSE=0.03409 | best=0.03382 | patience=3\n",
        "    Epoch 20 | train_loss=0.000402 | RMSE=0.03264 | best=0.03264 | patience=8\n",
        "    Epoch 25 | train_loss=0.000438 | RMSE=0.03205 | best=0.03205 | patience=8\n",
        "    Epoch 30 | train_loss=0.000374 | RMSE=0.04002 | best=0.03134 | patience=6\n",
        "    Epoch 35 | train_loss=0.000390 | RMSE=0.03179 | best=0.03115 | patience=6\n",
        "    Epoch 40 | train_loss=0.000378 | RMSE=0.03089 | best=0.03089 | patience=8\n",
        "  FINAL: MAE=0.030892 RMSE=0.030892 best_epoch=40\n",
        "\n",
        ">>> light_emb_h80 + Load-type (n=2 h=80 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.028132 | RMSE=0.04260 | best=0.04260 | patience=8\n",
        "    Epoch 05 | train_loss=0.000172 | RMSE=0.01786 | best=0.01786 | patience=8\n",
        "    Epoch 10 | train_loss=0.000135 | RMSE=0.01702 | best=0.01680 | patience=7\n",
        "    Epoch 15 | train_loss=0.000131 | RMSE=0.01941 | best=0.01598 | patience=7\n",
        "    Epoch 20 | train_loss=0.000133 | RMSE=0.01805 | best=0.01587 | patience=4\n",
        "  FINAL: MAE=0.015868 RMSE=0.015868 best_epoch=16\n",
        "\n",
        ">>> medium_3 + Original (n=3 h=32 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.119803 | RMSE=0.06583 | best=0.06583 | patience=8\n",
        "    Epoch 05 | train_loss=0.000474 | RMSE=0.03503 | best=0.03503 | patience=8\n",
        "    Epoch 10 | train_loss=0.000426 | RMSE=0.03249 | best=0.03222 | patience=7\n",
        "    Epoch 15 | train_loss=0.000415 | RMSE=0.03835 | best=0.03149 | patience=7\n",
        "    Epoch 20 | train_loss=0.000351 | RMSE=0.02937 | best=0.02937 | patience=8\n",
        "    Epoch 25 | train_loss=0.000344 | RMSE=0.02884 | best=0.02850 | patience=7\n",
        "    Epoch 30 | train_loss=0.000356 | RMSE=0.03732 | best=0.02846 | patience=5\n",
        "    Epoch 35 | train_loss=0.000351 | RMSE=0.02852 | best=0.02846 | patience=0\n",
        "  FINAL: MAE=0.028460 RMSE=0.028460 best_epoch=27\n",
        "\n",
        ">>> medium_3 + Derived (n=3 h=32 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.084025 | RMSE=0.06830 | best=0.06830 | patience=8\n",
        "    Epoch 05 | train_loss=0.000547 | RMSE=0.04648 | best=0.04081 | patience=8\n",
        "    Epoch 10 | train_loss=0.000482 | RMSE=0.03357 | best=0.03357 | patience=8\n",
        "    Epoch 15 | train_loss=0.000348 | RMSE=0.03019 | best=0.03019 | patience=8\n",
        "    Epoch 20 | train_loss=0.000304 | RMSE=0.02862 | best=0.02862 | patience=8\n",
        "    Epoch 25 | train_loss=0.000299 | RMSE=0.02936 | best=0.02861 | patience=4\n",
        "    Epoch 30 | train_loss=0.000325 | RMSE=0.04214 | best=0.02711 | patience=6\n",
        "    Epoch 35 | train_loss=0.000285 | RMSE=0.02703 | best=0.02703 | patience=8\n",
        "    Epoch 40 | train_loss=0.000287 | RMSE=0.02951 | best=0.02697 | patience=7\n",
        "  FINAL: MAE=0.026972 RMSE=0.026972 best_epoch=39\n",
        "\n",
        ">>> medium_3 + Load-type (n=3 h=32 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.161988 | RMSE=0.31920 | best=0.31920 | patience=8\n",
        "    Epoch 05 | train_loss=0.000294 | RMSE=0.02799 | best=0.02799 | patience=8\n",
        "    Epoch 10 | train_loss=0.000215 | RMSE=0.02213 | best=0.02213 | patience=8\n",
        "    Epoch 15 | train_loss=0.000172 | RMSE=0.02140 | best=0.02068 | patience=5\n",
        "    Epoch 20 | train_loss=0.000159 | RMSE=0.02511 | best=0.02068 | patience=0\n",
        "  FINAL: MAE=0.020678 RMSE=0.020678 best_epoch=12\n",
        "\n",
        ">>> heavy_3 + Original (n=3 h=64 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.034143 | RMSE=0.05452 | best=0.05452 | patience=8\n",
        "    Epoch 05 | train_loss=0.000400 | RMSE=0.03898 | best=0.03268 | patience=8\n",
        "    Epoch 10 | train_loss=0.000335 | RMSE=0.02866 | best=0.02866 | patience=8\n",
        "    Epoch 15 | train_loss=0.000345 | RMSE=0.02783 | best=0.02783 | patience=8\n",
        "    Epoch 20 | train_loss=0.000303 | RMSE=0.03589 | best=0.02741 | patience=5\n",
        "    Epoch 25 | train_loss=0.000287 | RMSE=0.03074 | best=0.02629 | patience=7\n",
        "    Epoch 30 | train_loss=0.000296 | RMSE=0.02589 | best=0.02588 | patience=6\n",
        "    Epoch 35 | train_loss=0.000268 | RMSE=0.02647 | best=0.02588 | patience=1\n",
        "  FINAL: MAE=0.025878 RMSE=0.025878 best_epoch=28\n",
        "\n",
        ">>> heavy_3 + Derived (n=3 h=64 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.045525 | RMSE=0.05483 | best=0.05483 | patience=8\n",
        "    Epoch 05 | train_loss=0.000443 | RMSE=0.04364 | best=0.03596 | patience=8\n",
        "    Epoch 10 | train_loss=0.000369 | RMSE=0.03088 | best=0.03028 | patience=7\n",
        "    Epoch 15 | train_loss=0.000357 | RMSE=0.02811 | best=0.02811 | patience=8\n",
        "    Epoch 20 | train_loss=0.000351 | RMSE=0.02789 | best=0.02746 | patience=6\n",
        "    Epoch 25 | train_loss=0.000322 | RMSE=0.02980 | best=0.02746 | patience=1\n",
        "  FINAL: MAE=0.027461 RMSE=0.027461 best_epoch=18\n",
        "\n",
        ">>> heavy_3 + Load-type (n=3 h=64 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.042301 | RMSE=0.05608 | best=0.05608 | patience=8\n",
        "    Epoch 05 | train_loss=0.000171 | RMSE=0.02199 | best=0.02167 | patience=8\n",
        "    Epoch 10 | train_loss=0.000142 | RMSE=0.01849 | best=0.01828 | patience=7\n",
        "    Epoch 15 | train_loss=0.000134 | RMSE=0.01972 | best=0.01725 | patience=7\n",
        "    Epoch 20 | train_loss=0.000133 | RMSE=0.01666 | best=0.01666 | patience=8\n",
        "    Epoch 25 | train_loss=0.000107 | RMSE=0.01870 | best=0.01561 | patience=7\n",
        "    Epoch 30 | train_loss=0.000116 | RMSE=0.01928 | best=0.01561 | patience=2\n",
        "  FINAL: MAE=0.015608 RMSE=0.015608 best_epoch=24\n",
        "\n",
        ">>> deep_3 + Original (n=3 h=64 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.049813 | RMSE=0.05586 | best=0.05586 | patience=8\n",
        "    Epoch 05 | train_loss=0.000482 | RMSE=0.03750 | best=0.03521 | patience=8\n",
        "    Epoch 10 | train_loss=0.000409 | RMSE=0.03160 | best=0.03160 | patience=8\n",
        "    Epoch 15 | train_loss=0.000418 | RMSE=0.05627 | best=0.03051 | patience=6\n",
        "    Epoch 20 | train_loss=0.000371 | RMSE=0.02902 | best=0.02882 | patience=7\n",
        "    Epoch 25 | train_loss=0.000351 | RMSE=0.04644 | best=0.02852 | patience=4\n",
        "    Epoch 30 | train_loss=0.000338 | RMSE=0.02824 | best=0.02745 | patience=7\n",
        "    Epoch 35 | train_loss=0.000303 | RMSE=0.02760 | best=0.02690 | patience=6\n",
        "    Epoch 40 | train_loss=0.000310 | RMSE=0.02944 | best=0.02690 | patience=1\n",
        "  FINAL: MAE=0.026896 RMSE=0.026896 best_epoch=33\n",
        "\n",
        ">>> deep_3 + Derived (n=3 h=64 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.045849 | RMSE=0.05732 | best=0.05732 | patience=8\n",
        "    Epoch 05 | train_loss=0.000429 | RMSE=0.03269 | best=0.03269 | patience=8\n",
        "    Epoch 10 | train_loss=0.000357 | RMSE=0.03808 | best=0.02870 | patience=7\n",
        "    Epoch 15 | train_loss=0.000322 | RMSE=0.03041 | best=0.02845 | patience=6\n",
        "    Epoch 20 | train_loss=0.000298 | RMSE=0.03042 | best=0.02732 | patience=6\n",
        "    Epoch 25 | train_loss=0.000288 | RMSE=0.03576 | best=0.02732 | patience=1\n",
        "  FINAL: MAE=0.027319 RMSE=0.027319 best_epoch=18\n",
        "\n",
        ">>> deep_3 + Load-type (n=3 h=64 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.049574 | RMSE=0.03768 | best=0.03768 | patience=8\n",
        "    Epoch 05 | train_loss=0.000152 | RMSE=0.01960 | best=0.01926 | patience=8\n",
        "    Epoch 10 | train_loss=0.000133 | RMSE=0.03108 | best=0.01761 | patience=7\n",
        "    Epoch 15 | train_loss=0.000119 | RMSE=0.01637 | best=0.01627 | patience=5\n",
        "    Epoch 20 | train_loss=0.000120 | RMSE=0.02181 | best=0.01627 | patience=0\n",
        "  FINAL: MAE=0.016268 RMSE=0.016268 best_epoch=12\n",
        "\n",
        ">>> medium_wide_3 + Original (n=3 h=64 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.034146 | RMSE=0.05385 | best=0.05385 | patience=8\n",
        "    Epoch 05 | train_loss=0.000409 | RMSE=0.03906 | best=0.03341 | patience=8\n",
        "    Epoch 10 | train_loss=0.000338 | RMSE=0.02873 | best=0.02873 | patience=8\n",
        "    Epoch 15 | train_loss=0.000356 | RMSE=0.02848 | best=0.02848 | patience=8\n",
        "    Epoch 20 | train_loss=0.000306 | RMSE=0.03758 | best=0.02790 | patience=5\n",
        "    Epoch 25 | train_loss=0.000290 | RMSE=0.03211 | best=0.02654 | patience=7\n",
        "    Epoch 30 | train_loss=0.000291 | RMSE=0.02596 | best=0.02596 | patience=8\n",
        "    Epoch 35 | train_loss=0.000272 | RMSE=0.02651 | best=0.02596 | patience=3\n",
        "    Epoch 40 | train_loss=0.000279 | RMSE=0.02625 | best=0.02586 | patience=6\n",
        "  FINAL: MAE=0.025859 RMSE=0.025859 best_epoch=38\n",
        "\n",
        ">>> medium_wide_3 + Derived (n=3 h=64 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.045524 | RMSE=0.05452 | best=0.05452 | patience=8\n",
        "    Epoch 05 | train_loss=0.000445 | RMSE=0.04362 | best=0.03732 | patience=8\n",
        "    Epoch 10 | train_loss=0.000371 | RMSE=0.02979 | best=0.02979 | patience=8\n",
        "    Epoch 15 | train_loss=0.000354 | RMSE=0.02790 | best=0.02790 | patience=8\n",
        "    Epoch 20 | train_loss=0.000347 | RMSE=0.02772 | best=0.02750 | patience=6\n",
        "    Epoch 25 | train_loss=0.000320 | RMSE=0.02960 | best=0.02750 | patience=1\n",
        "  FINAL: MAE=0.027504 RMSE=0.027504 best_epoch=18\n",
        "\n",
        ">>> medium_wide_3 + Load-type (n=3 h=64 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.042301 | RMSE=0.05553 | best=0.05553 | patience=8\n",
        "    Epoch 05 | train_loss=0.000172 | RMSE=0.02484 | best=0.02121 | patience=8\n",
        "    Epoch 10 | train_loss=0.000141 | RMSE=0.01904 | best=0.01829 | patience=7\n",
        "    Epoch 15 | train_loss=0.000128 | RMSE=0.02232 | best=0.01685 | patience=7\n",
        "    Epoch 20 | train_loss=0.000132 | RMSE=0.01661 | best=0.01661 | patience=8\n",
        "    Epoch 25 | train_loss=0.000110 | RMSE=0.01717 | best=0.01596 | patience=5\n",
        "    Epoch 30 | train_loss=0.000115 | RMSE=0.01701 | best=0.01596 | patience=0\n",
        "  FINAL: MAE=0.015956 RMSE=0.015956 best_epoch=22\n",
        "\n",
        ">>> deep_wide_3 + Original (n=3 h=128 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.044573 | RMSE=0.05199 | best=0.05199 | patience=8\n",
        "    Epoch 05 | train_loss=0.000598 | RMSE=0.03622 | best=0.03622 | patience=8\n",
        "    Epoch 10 | train_loss=0.000452 | RMSE=0.05228 | best=0.03009 | patience=7\n",
        "    Epoch 15 | train_loss=0.000335 | RMSE=0.04681 | best=0.03009 | patience=2\n",
        "    Epoch 20 | train_loss=0.000309 | RMSE=0.03169 | best=0.02683 | patience=6\n",
        "    Epoch 25 | train_loss=0.000349 | RMSE=0.02685 | best=0.02657 | patience=6\n",
        "    Epoch 30 | train_loss=0.000360 | RMSE=0.03079 | best=0.02657 | patience=1\n",
        "  FINAL: MAE=0.026574 RMSE=0.026574 best_epoch=23\n",
        "\n",
        ">>> deep_wide_3 + Derived (n=3 h=128 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.036540 | RMSE=0.04777 | best=0.04777 | patience=8\n",
        "    Epoch 05 | train_loss=0.000492 | RMSE=0.04778 | best=0.03348 | patience=8\n",
        "    Epoch 10 | train_loss=0.000425 | RMSE=0.03648 | best=0.03219 | patience=7\n",
        "    Epoch 15 | train_loss=0.000379 | RMSE=0.03289 | best=0.02962 | patience=4\n",
        "  FINAL: MAE=0.029622 RMSE=0.029622 best_epoch=11\n",
        "\n",
        ">>> deep_wide_3 + Load-type (n=3 h=128 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.028473 | RMSE=0.02600 | best=0.02600 | patience=8\n",
        "    Epoch 05 | train_loss=0.000174 | RMSE=0.02687 | best=0.01959 | patience=8\n",
        "    Epoch 10 | train_loss=0.000145 | RMSE=0.02432 | best=0.01713 | patience=7\n",
        "    Epoch 15 | train_loss=0.000138 | RMSE=0.01672 | best=0.01605 | patience=7\n",
        "    Epoch 20 | train_loss=0.000114 | RMSE=0.02023 | best=0.01605 | patience=2\n",
        "  FINAL: MAE=0.016050 RMSE=0.016050 best_epoch=14\n",
        "\n",
        ">>> light_wide_3 + Original (n=3 h=64 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.034147 | RMSE=0.05381 | best=0.05381 | patience=8\n",
        "    Epoch 05 | train_loss=0.000403 | RMSE=0.03886 | best=0.03311 | patience=8\n",
        "    Epoch 10 | train_loss=0.000338 | RMSE=0.02879 | best=0.02879 | patience=8\n",
        "    Epoch 15 | train_loss=0.000352 | RMSE=0.02803 | best=0.02803 | patience=8\n",
        "    Epoch 20 | train_loss=0.000306 | RMSE=0.03695 | best=0.02774 | patience=5\n",
        "    Epoch 25 | train_loss=0.000289 | RMSE=0.03175 | best=0.02639 | patience=7\n",
        "    Epoch 30 | train_loss=0.000296 | RMSE=0.02592 | best=0.02592 | patience=8\n",
        "    Epoch 35 | train_loss=0.000268 | RMSE=0.02663 | best=0.02592 | patience=3\n",
        "    Epoch 40 | train_loss=0.000278 | RMSE=0.02614 | best=0.02588 | patience=6\n",
        "  FINAL: MAE=0.025880 RMSE=0.025880 best_epoch=38\n",
        "\n",
        ">>> light_wide_3 + Derived (n=3 h=64 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.045525 | RMSE=0.05484 | best=0.05484 | patience=8\n",
        "    Epoch 05 | train_loss=0.000444 | RMSE=0.04388 | best=0.03683 | patience=8\n",
        "    Epoch 10 | train_loss=0.000368 | RMSE=0.02927 | best=0.02927 | patience=8\n",
        "    Epoch 15 | train_loss=0.000356 | RMSE=0.02804 | best=0.02804 | patience=8\n",
        "    Epoch 20 | train_loss=0.000354 | RMSE=0.02808 | best=0.02745 | patience=6\n",
        "    Epoch 25 | train_loss=0.000323 | RMSE=0.02933 | best=0.02745 | patience=1\n",
        "  FINAL: MAE=0.027447 RMSE=0.027447 best_epoch=18\n",
        "\n",
        ">>> light_wide_3 + Load-type (n=3 h=64 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.042301 | RMSE=0.05679 | best=0.05679 | patience=8\n",
        "    Epoch 05 | train_loss=0.000169 | RMSE=0.02341 | best=0.02149 | patience=8\n",
        "    Epoch 10 | train_loss=0.000141 | RMSE=0.01858 | best=0.01858 | patience=8\n",
        "    Epoch 15 | train_loss=0.000124 | RMSE=0.02308 | best=0.01635 | patience=7\n",
        "    Epoch 20 | train_loss=0.000128 | RMSE=0.01645 | best=0.01635 | patience=2\n",
        "    Epoch 25 | train_loss=0.000109 | RMSE=0.01692 | best=0.01562 | patience=5\n",
        "    Epoch 30 | train_loss=0.000114 | RMSE=0.01776 | best=0.01562 | patience=0\n",
        "  FINAL: MAE=0.015623 RMSE=0.015623 best_epoch=22\n",
        "\n",
        ">>> light_xwide_3 + Original (n=3 h=128 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.034457 | RMSE=0.04813 | best=0.04813 | patience=8\n",
        "    Epoch 05 | train_loss=0.000455 | RMSE=0.03430 | best=0.03430 | patience=8\n",
        "    Epoch 10 | train_loss=0.000404 | RMSE=0.04115 | best=0.03153 | patience=7\n",
        "    Epoch 15 | train_loss=0.000452 | RMSE=0.04145 | best=0.02789 | patience=7\n",
        "    Epoch 20 | train_loss=0.000309 | RMSE=0.03200 | best=0.02674 | patience=7\n",
        "    Epoch 25 | train_loss=0.000310 | RMSE=0.02636 | best=0.02594 | patience=7\n",
        "    Epoch 30 | train_loss=0.000300 | RMSE=0.03413 | best=0.02576 | patience=5\n",
        "    Epoch 35 | train_loss=0.000307 | RMSE=0.02653 | best=0.02576 | patience=0\n",
        "  FINAL: MAE=0.025757 RMSE=0.025757 best_epoch=27\n",
        "\n",
        ">>> light_xwide_3 + Derived (n=3 h=128 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.041185 | RMSE=0.06450 | best=0.06450 | patience=8\n",
        "    Epoch 05 | train_loss=0.000505 | RMSE=0.03518 | best=0.03437 | patience=8\n",
        "    Epoch 10 | train_loss=0.000393 | RMSE=0.03672 | best=0.03055 | patience=7\n",
        "    Epoch 15 | train_loss=0.000408 | RMSE=0.02997 | best=0.02877 | patience=6\n",
        "    Epoch 20 | train_loss=0.000323 | RMSE=0.05136 | best=0.02877 | patience=1\n",
        "  FINAL: MAE=0.028773 RMSE=0.028773 best_epoch=13\n",
        "\n",
        ">>> light_xwide_3 + Load-type (n=3 h=128 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.032994 | RMSE=0.03234 | best=0.03234 | patience=8\n",
        "    Epoch 05 | train_loss=0.000167 | RMSE=0.01890 | best=0.01852 | patience=8\n",
        "    Epoch 10 | train_loss=0.000134 | RMSE=0.01782 | best=0.01708 | patience=7\n",
        "    Epoch 15 | train_loss=0.000139 | RMSE=0.01709 | best=0.01644 | patience=5\n",
        "    Epoch 20 | train_loss=0.000150 | RMSE=0.01610 | best=0.01610 | patience=8\n",
        "    Epoch 25 | train_loss=0.000129 | RMSE=0.02458 | best=0.01610 | patience=3\n",
        "    Epoch 30 | train_loss=0.000129 | RMSE=0.02445 | best=0.01605 | patience=4\n",
        "    Epoch 35 | train_loss=0.000120 | RMSE=0.01626 | best=0.01584 | patience=6\n",
        "    Epoch 40 | train_loss=0.000122 | RMSE=0.01572 | best=0.01572 | patience=8\n",
        "  FINAL: MAE=0.015724 RMSE=0.015724 best_epoch=40\n",
        "\n",
        ">>> heavy_wide_3 + Original (n=3 h=128 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.034458 | RMSE=0.04827 | best=0.04827 | patience=8\n",
        "    Epoch 05 | train_loss=0.000498 | RMSE=0.03722 | best=0.03722 | patience=8\n",
        "    Epoch 10 | train_loss=0.000418 | RMSE=0.03082 | best=0.03082 | patience=8\n",
        "    Epoch 15 | train_loss=0.000423 | RMSE=0.02920 | best=0.02683 | patience=7\n",
        "    Epoch 20 | train_loss=0.000311 | RMSE=0.03342 | best=0.02650 | patience=7\n",
        "    Epoch 25 | train_loss=0.000321 | RMSE=0.02860 | best=0.02605 | patience=7\n",
        "    Epoch 30 | train_loss=0.000300 | RMSE=0.03347 | best=0.02589 | patience=5\n",
        "    Epoch 35 | train_loss=0.000295 | RMSE=0.02937 | best=0.02589 | patience=0\n",
        "  FINAL: MAE=0.025893 RMSE=0.025893 best_epoch=27\n",
        "\n",
        ">>> heavy_wide_3 + Derived (n=3 h=128 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.041185 | RMSE=0.06311 | best=0.06311 | patience=8\n",
        "    Epoch 05 | train_loss=0.000506 | RMSE=0.03508 | best=0.03425 | patience=8\n",
        "    Epoch 10 | train_loss=0.000388 | RMSE=0.03619 | best=0.03080 | patience=7\n",
        "    Epoch 15 | train_loss=0.000402 | RMSE=0.02804 | best=0.02804 | patience=8\n",
        "    Epoch 20 | train_loss=0.000309 | RMSE=0.04843 | best=0.02804 | patience=3\n",
        "    Epoch 25 | train_loss=0.000314 | RMSE=0.03026 | best=0.02731 | patience=6\n",
        "    Epoch 30 | train_loss=0.000298 | RMSE=0.02758 | best=0.02731 | patience=1\n",
        "  FINAL: MAE=0.027310 RMSE=0.027310 best_epoch=23\n",
        "\n",
        ">>> heavy_wide_3 + Load-type (n=3 h=128 emb=8/4)\n",
        "    Epoch 01 | train_loss=0.032985 | RMSE=0.02762 | best=0.02762 | patience=8\n",
        "    Epoch 05 | train_loss=0.000193 | RMSE=0.02044 | best=0.01974 | patience=8\n",
        "    Epoch 10 | train_loss=0.000139 | RMSE=0.01728 | best=0.01683 | patience=7\n",
        "    Epoch 15 | train_loss=0.000139 | RMSE=0.01731 | best=0.01673 | patience=5\n",
        "    Epoch 20 | train_loss=0.000133 | RMSE=0.01766 | best=0.01673 | patience=0\n",
        "  FINAL: MAE=0.016726 RMSE=0.016726 best_epoch=12\n",
        "\n",
        ">>> emb_heavy_3 + Original (n=3 h=32 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.096070 | RMSE=0.05763 | best=0.05763 | patience=8\n",
        "    Epoch 05 | train_loss=0.000553 | RMSE=0.04196 | best=0.03855 | patience=8\n",
        "    Epoch 10 | train_loss=0.000417 | RMSE=0.03284 | best=0.03284 | patience=8\n",
        "    Epoch 15 | train_loss=0.000375 | RMSE=0.02992 | best=0.02992 | patience=8\n",
        "    Epoch 20 | train_loss=0.000352 | RMSE=0.03823 | best=0.02992 | patience=3\n",
        "    Epoch 25 | train_loss=0.000299 | RMSE=0.03154 | best=0.02819 | patience=4\n",
        "    Epoch 30 | train_loss=0.000307 | RMSE=0.02989 | best=0.02729 | patience=4\n",
        "  FINAL: MAE=0.027292 RMSE=0.027292 best_epoch=26\n",
        "\n",
        ">>> emb_heavy_3 + Derived (n=3 h=32 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.085909 | RMSE=0.06193 | best=0.06193 | patience=8\n",
        "    Epoch 05 | train_loss=0.000469 | RMSE=0.03523 | best=0.03523 | patience=8\n",
        "    Epoch 10 | train_loss=0.000396 | RMSE=0.03361 | best=0.03325 | patience=7\n",
        "    Epoch 15 | train_loss=0.000369 | RMSE=0.03079 | best=0.03079 | patience=8\n",
        "    Epoch 20 | train_loss=0.000322 | RMSE=0.02831 | best=0.02831 | patience=8\n",
        "    Epoch 25 | train_loss=0.000301 | RMSE=0.03569 | best=0.02793 | patience=6\n",
        "    Epoch 30 | train_loss=0.000310 | RMSE=0.02783 | best=0.02695 | patience=5\n",
        "    Epoch 35 | train_loss=0.000296 | RMSE=0.02788 | best=0.02695 | patience=0\n",
        "  FINAL: MAE=0.026953 RMSE=0.026953 best_epoch=27\n",
        "\n",
        ">>> emb_heavy_3 + Load-type (n=3 h=32 emb=16/8)\n",
        "    Epoch 01 | train_loss=0.079051 | RMSE=0.04589 | best=0.04589 | patience=8\n",
        "    Epoch 05 | train_loss=0.000185 | RMSE=0.02974 | best=0.02476 | patience=8\n",
        "    Epoch 10 | train_loss=0.000169 | RMSE=0.02308 | best=0.01936 | patience=7\n",
        "    Epoch 15 | train_loss=0.000117 | RMSE=0.01711 | best=0.01711 | patience=8\n",
        "    Epoch 20 | train_loss=0.000141 | RMSE=0.01872 | best=0.01648 | patience=6\n",
        "    Epoch 25 | train_loss=0.000121 | RMSE=0.01909 | best=0.01605 | patience=7\n",
        "    Epoch 30 | train_loss=0.000112 | RMSE=0.01638 | best=0.01605 | patience=2\n",
        "    Epoch 35 | train_loss=0.000113 | RMSE=0.01870 | best=0.01603 | patience=5\n",
        "    Epoch 40 | train_loss=0.000115 | RMSE=0.01664 | best=0.01584 | patience=5\n",
        "  FINAL: MAE=0.015842 RMSE=0.015842 best_epoch=37\n",
        "\n",
        ">>> max_cap_3 + Original (n=3 h=128 emb=32/16)\n",
        "    Epoch 01 | train_loss=0.053465 | RMSE=0.06375 | best=0.06375 | patience=8\n",
        "    Epoch 05 | train_loss=0.000447 | RMSE=0.03267 | best=0.03267 | patience=8\n",
        "    Epoch 10 | train_loss=0.000386 | RMSE=0.03864 | best=0.03023 | patience=7\n",
        "    Epoch 15 | train_loss=0.000383 | RMSE=0.02852 | best=0.02770 | patience=6\n",
        "    Epoch 20 | train_loss=0.000373 | RMSE=0.02953 | best=0.02724 | patience=5\n",
        "    Epoch 25 | train_loss=0.000323 | RMSE=0.02793 | best=0.02724 | patience=0\n",
        "  FINAL: MAE=0.027236 RMSE=0.027236 best_epoch=17\n",
        "\n",
        ">>> max_cap_3 + Derived (n=3 h=128 emb=32/16)\n",
        "    Epoch 01 | train_loss=0.034356 | RMSE=0.06081 | best=0.06081 | patience=8\n",
        "    Epoch 05 | train_loss=0.000352 | RMSE=0.03053 | best=0.03053 | patience=8\n",
        "    Epoch 10 | train_loss=0.000360 | RMSE=0.02833 | best=0.02798 | patience=7\n",
        "    Epoch 15 | train_loss=0.000372 | RMSE=0.03359 | best=0.02798 | patience=2\n",
        "  FINAL: MAE=0.027976 RMSE=0.027976 best_epoch=9\n",
        "\n",
        ">>> max_cap_3 + Load-type (n=3 h=128 emb=32/16)\n",
        "    Epoch 01 | train_loss=0.029220 | RMSE=0.02117 | best=0.02117 | patience=8\n",
        "    Epoch 05 | train_loss=0.000159 | RMSE=0.02268 | best=0.02117 | patience=8\n",
        "    Epoch 10 | train_loss=0.000137 | RMSE=0.02077 | best=0.01756 | patience=7\n",
        "    Epoch 15 | train_loss=0.000130 | RMSE=0.01940 | best=0.01626 | patience=7\n",
        "    Epoch 20 | train_loss=0.000121 | RMSE=0.01686 | best=0.01579 | patience=7\n",
        "    Epoch 25 | train_loss=0.000134 | RMSE=0.01980 | best=0.01564 | patience=5\n",
        "    Epoch 30 | train_loss=0.000127 | RMSE=0.01910 | best=0.01564 | patience=0\n",
        "  FINAL: MAE=0.015638 RMSE=0.015638 best_epoch=22\n",
        "\n",
        ">>> light_emb12 + Original (n=2 h=32 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.111464 | RMSE=0.06170 | best=0.06170 | patience=8\n",
        "    Epoch 05 | train_loss=0.000570 | RMSE=0.03913 | best=0.03913 | patience=8\n",
        "    Epoch 10 | train_loss=0.000460 | RMSE=0.03606 | best=0.03603 | patience=7\n",
        "    Epoch 15 | train_loss=0.000404 | RMSE=0.03271 | best=0.03271 | patience=8\n",
        "    Epoch 20 | train_loss=0.000366 | RMSE=0.02978 | best=0.02978 | patience=8\n",
        "    Epoch 25 | train_loss=0.000312 | RMSE=0.02895 | best=0.02895 | patience=8\n",
        "    Epoch 30 | train_loss=0.000342 | RMSE=0.03092 | best=0.02880 | patience=4\n",
        "  FINAL: MAE=0.028795 RMSE=0.028795 best_epoch=26\n",
        "\n",
        ">>> light_emb12 + Derived (n=2 h=32 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.096946 | RMSE=0.07266 | best=0.07266 | patience=8\n",
        "    Epoch 05 | train_loss=0.000606 | RMSE=0.04035 | best=0.04035 | patience=8\n",
        "    Epoch 10 | train_loss=0.000456 | RMSE=0.03499 | best=0.03499 | patience=8\n",
        "    Epoch 15 | train_loss=0.000453 | RMSE=0.04114 | best=0.03422 | patience=6\n",
        "    Epoch 20 | train_loss=0.000430 | RMSE=0.04028 | best=0.03266 | patience=6\n",
        "    Epoch 25 | train_loss=0.000413 | RMSE=0.03971 | best=0.03175 | patience=6\n",
        "    Epoch 30 | train_loss=0.000381 | RMSE=0.04289 | best=0.03175 | patience=1\n",
        "    Epoch 35 | train_loss=0.000391 | RMSE=0.03304 | best=0.03122 | patience=4\n",
        "    Epoch 40 | train_loss=0.000364 | RMSE=0.03323 | best=0.03096 | patience=4\n",
        "  FINAL: MAE=0.030958 RMSE=0.030958 best_epoch=36\n",
        "\n",
        ">>> light_emb12 + Load-type (n=2 h=32 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.051345 | RMSE=0.05914 | best=0.05914 | patience=8\n",
        "    Epoch 05 | train_loss=0.000269 | RMSE=0.04090 | best=0.02863 | patience=8\n",
        "    Epoch 10 | train_loss=0.000127 | RMSE=0.01774 | best=0.01774 | patience=8\n",
        "    Epoch 15 | train_loss=0.000125 | RMSE=0.01920 | best=0.01728 | patience=6\n",
        "    Epoch 20 | train_loss=0.000116 | RMSE=0.01916 | best=0.01721 | patience=7\n",
        "    Epoch 25 | train_loss=0.000112 | RMSE=0.01958 | best=0.01632 | patience=5\n",
        "    Epoch 30 | train_loss=0.000103 | RMSE=0.02419 | best=0.01632 | patience=0\n",
        "  FINAL: MAE=0.016318 RMSE=0.016318 best_epoch=22\n",
        "\n",
        ">>> light_wide_emb12 + Original (n=2 h=64 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.037185 | RMSE=0.05663 | best=0.05663 | patience=8\n",
        "    Epoch 05 | train_loss=0.000466 | RMSE=0.04020 | best=0.03715 | patience=8\n",
        "    Epoch 10 | train_loss=0.000391 | RMSE=0.03093 | best=0.03093 | patience=8\n",
        "    Epoch 15 | train_loss=0.000387 | RMSE=0.04125 | best=0.02986 | patience=6\n",
        "    Epoch 20 | train_loss=0.000369 | RMSE=0.02924 | best=0.02924 | patience=8\n",
        "    Epoch 25 | train_loss=0.000343 | RMSE=0.02952 | best=0.02896 | patience=6\n",
        "    Epoch 30 | train_loss=0.000348 | RMSE=0.03154 | best=0.02896 | patience=1\n",
        "    Epoch 35 | train_loss=0.000351 | RMSE=0.03254 | best=0.02872 | patience=6\n",
        "    Epoch 40 | train_loss=0.000337 | RMSE=0.02878 | best=0.02872 | patience=1\n",
        "  FINAL: MAE=0.028721 RMSE=0.028721 best_epoch=33\n",
        "\n",
        ">>> light_wide_emb12 + Derived (n=2 h=64 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.062925 | RMSE=0.06184 | best=0.06184 | patience=8\n",
        "    Epoch 05 | train_loss=0.000520 | RMSE=0.03696 | best=0.03696 | patience=8\n",
        "    Epoch 10 | train_loss=0.000442 | RMSE=0.03832 | best=0.03492 | patience=7\n",
        "    Epoch 15 | train_loss=0.000394 | RMSE=0.03511 | best=0.03293 | patience=5\n",
        "    Epoch 20 | train_loss=0.000423 | RMSE=0.03485 | best=0.03156 | patience=4\n",
        "    Epoch 25 | train_loss=0.000373 | RMSE=0.03052 | best=0.03052 | patience=8\n",
        "    Epoch 30 | train_loss=0.000394 | RMSE=0.03942 | best=0.03044 | patience=6\n",
        "    Epoch 35 | train_loss=0.000368 | RMSE=0.03274 | best=0.03044 | patience=1\n",
        "  FINAL: MAE=0.030437 RMSE=0.030437 best_epoch=28\n",
        "\n",
        ">>> light_wide_emb12 + Load-type (n=2 h=64 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.032613 | RMSE=0.06078 | best=0.06078 | patience=8\n",
        "    Epoch 05 | train_loss=0.000183 | RMSE=0.02196 | best=0.02196 | patience=8\n",
        "    Epoch 10 | train_loss=0.000116 | RMSE=0.01997 | best=0.01804 | patience=7\n",
        "    Epoch 15 | train_loss=0.000123 | RMSE=0.01576 | best=0.01576 | patience=8\n",
        "    Epoch 20 | train_loss=0.000113 | RMSE=0.01576 | best=0.01530 | patience=7\n",
        "    Epoch 25 | train_loss=0.000111 | RMSE=0.01804 | best=0.01530 | patience=2\n",
        "  FINAL: MAE=0.015297 RMSE=0.015297 best_epoch=19\n",
        "\n",
        ">>> light_xwide_emb12 + Original (n=2 h=128 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.039084 | RMSE=0.05197 | best=0.05197 | patience=8\n",
        "    Epoch 05 | train_loss=0.000490 | RMSE=0.03645 | best=0.03617 | patience=8\n",
        "    Epoch 10 | train_loss=0.000426 | RMSE=0.03366 | best=0.03128 | patience=7\n",
        "    Epoch 15 | train_loss=0.000434 | RMSE=0.03409 | best=0.03128 | patience=2\n",
        "  FINAL: MAE=0.031277 RMSE=0.031277 best_epoch=9\n",
        "\n",
        ">>> light_xwide_emb12 + Derived (n=2 h=128 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.038997 | RMSE=0.04891 | best=0.04891 | patience=8\n",
        "    Epoch 05 | train_loss=0.000559 | RMSE=0.03635 | best=0.03635 | patience=8\n",
        "    Epoch 10 | train_loss=0.000483 | RMSE=0.03505 | best=0.03505 | patience=8\n",
        "    Epoch 15 | train_loss=0.000444 | RMSE=0.03405 | best=0.03405 | patience=8\n",
        "    Epoch 20 | train_loss=0.000422 | RMSE=0.03466 | best=0.03101 | patience=5\n",
        "    Epoch 25 | train_loss=0.000397 | RMSE=0.03459 | best=0.03060 | patience=5\n",
        "    Epoch 30 | train_loss=0.000356 | RMSE=0.03968 | best=0.03060 | patience=0\n",
        "  FINAL: MAE=0.030605 RMSE=0.030605 best_epoch=22\n",
        "\n",
        ">>> light_xwide_emb12 + Load-type (n=2 h=128 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.058090 | RMSE=0.03718 | best=0.03718 | patience=8\n",
        "    Epoch 05 | train_loss=0.000132 | RMSE=0.01647 | best=0.01647 | patience=8\n",
        "    Epoch 10 | train_loss=0.000124 | RMSE=0.02257 | best=0.01647 | patience=7\n",
        "    Epoch 15 | train_loss=0.000110 | RMSE=0.01925 | best=0.01554 | patience=5\n",
        "    Epoch 20 | train_loss=0.000120 | RMSE=0.01862 | best=0.01554 | patience=0\n",
        "  FINAL: MAE=0.015543 RMSE=0.015543 best_epoch=12\n",
        "\n",
        ">>> medium_emb12 + Original (n=4 h=32 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.090258 | RMSE=0.06381 | best=0.06381 | patience=8\n",
        "    Epoch 05 | train_loss=0.000433 | RMSE=0.03681 | best=0.03659 | patience=8\n",
        "    Epoch 10 | train_loss=0.000352 | RMSE=0.04958 | best=0.03147 | patience=7\n",
        "    Epoch 15 | train_loss=0.000320 | RMSE=0.02845 | best=0.02758 | patience=7\n",
        "    Epoch 20 | train_loss=0.000306 | RMSE=0.02848 | best=0.02758 | patience=2\n",
        "    Epoch 25 | train_loss=0.000279 | RMSE=0.03589 | best=0.02679 | patience=4\n",
        "  FINAL: MAE=0.026793 RMSE=0.026793 best_epoch=21\n",
        "\n",
        ">>> medium_emb12 + Derived (n=4 h=32 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.138209 | RMSE=0.06818 | best=0.06818 | patience=8\n",
        "    Epoch 05 | train_loss=0.000479 | RMSE=0.03678 | best=0.03678 | patience=8\n",
        "    Epoch 10 | train_loss=0.000378 | RMSE=0.03220 | best=0.03011 | patience=7\n",
        "    Epoch 15 | train_loss=0.000370 | RMSE=0.03930 | best=0.02959 | patience=6\n",
        "    Epoch 20 | train_loss=0.000321 | RMSE=0.02758 | best=0.02758 | patience=8\n",
        "    Epoch 25 | train_loss=0.000310 | RMSE=0.03325 | best=0.02738 | patience=4\n",
        "    Epoch 30 | train_loss=0.000307 | RMSE=0.03923 | best=0.02683 | patience=7\n",
        "    Epoch 35 | train_loss=0.000293 | RMSE=0.02702 | best=0.02683 | patience=2\n",
        "  FINAL: MAE=0.026833 RMSE=0.026833 best_epoch=29\n",
        "\n",
        ">>> medium_emb12 + Load-type (n=4 h=32 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.073488 | RMSE=0.04375 | best=0.04375 | patience=8\n",
        "    Epoch 05 | train_loss=0.000162 | RMSE=0.01998 | best=0.01998 | patience=8\n",
        "    Epoch 10 | train_loss=0.000157 | RMSE=0.01867 | best=0.01867 | patience=8\n",
        "    Epoch 15 | train_loss=0.000125 | RMSE=0.01696 | best=0.01696 | patience=8\n",
        "    Epoch 20 | train_loss=0.000129 | RMSE=0.01688 | best=0.01685 | patience=5\n",
        "    Epoch 25 | train_loss=0.000121 | RMSE=0.02706 | best=0.01649 | patience=4\n",
        "  FINAL: MAE=0.016495 RMSE=0.016495 best_epoch=21\n",
        "\n",
        ">>> deep_emb12 + Original (n=4 h=64 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.041832 | RMSE=0.05840 | best=0.05840 | patience=8\n",
        "    Epoch 05 | train_loss=0.000394 | RMSE=0.03423 | best=0.03423 | patience=8\n",
        "    Epoch 10 | train_loss=0.000304 | RMSE=0.03176 | best=0.02879 | patience=7\n",
        "    Epoch 15 | train_loss=0.000275 | RMSE=0.03255 | best=0.02601 | patience=6\n",
        "    Epoch 20 | train_loss=0.000293 | RMSE=0.02526 | best=0.02466 | patience=6\n",
        "    Epoch 25 | train_loss=0.000251 | RMSE=0.02392 | best=0.02392 | patience=8\n",
        "    Epoch 30 | train_loss=0.000247 | RMSE=0.02588 | best=0.02389 | patience=6\n",
        "    Epoch 35 | train_loss=0.000238 | RMSE=0.02588 | best=0.02389 | patience=1\n",
        "  FINAL: MAE=0.023892 RMSE=0.023892 best_epoch=28\n",
        "\n",
        ">>> deep_emb12 + Derived (n=4 h=64 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.056600 | RMSE=0.06359 | best=0.06359 | patience=8\n",
        "    Epoch 05 | train_loss=0.000423 | RMSE=0.03228 | best=0.03228 | patience=8\n",
        "    Epoch 10 | train_loss=0.000335 | RMSE=0.02809 | best=0.02809 | patience=8\n",
        "    Epoch 15 | train_loss=0.000358 | RMSE=0.02886 | best=0.02809 | patience=3\n",
        "  FINAL: MAE=0.028090 RMSE=0.028090 best_epoch=10\n",
        "\n",
        ">>> deep_emb12 + Load-type (n=4 h=64 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.043506 | RMSE=0.03736 | best=0.03736 | patience=8\n",
        "    Epoch 05 | train_loss=0.000164 | RMSE=0.02265 | best=0.02143 | patience=8\n",
        "    Epoch 10 | train_loss=0.000138 | RMSE=0.02175 | best=0.01889 | patience=7\n",
        "    Epoch 15 | train_loss=0.000126 | RMSE=0.02236 | best=0.01685 | patience=7\n",
        "    Epoch 20 | train_loss=0.000116 | RMSE=0.01887 | best=0.01685 | patience=2\n",
        "  FINAL: MAE=0.016848 RMSE=0.016848 best_epoch=14\n",
        "\n",
        ">>> heavy_emb12 + Original (n=4 h=64 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.041831 | RMSE=0.05830 | best=0.05830 | patience=8\n",
        "    Epoch 05 | train_loss=0.000393 | RMSE=0.03431 | best=0.03431 | patience=8\n",
        "    Epoch 10 | train_loss=0.000305 | RMSE=0.03107 | best=0.03107 | patience=8\n",
        "    Epoch 15 | train_loss=0.000276 | RMSE=0.03283 | best=0.02619 | patience=6\n",
        "    Epoch 20 | train_loss=0.000297 | RMSE=0.02533 | best=0.02507 | patience=6\n",
        "    Epoch 25 | train_loss=0.000254 | RMSE=0.02396 | best=0.02396 | patience=8\n",
        "    Epoch 30 | train_loss=0.000251 | RMSE=0.02366 | best=0.02366 | patience=8\n",
        "    Epoch 35 | train_loss=0.000238 | RMSE=0.02565 | best=0.02366 | patience=3\n",
        "  FINAL: MAE=0.023660 RMSE=0.023660 best_epoch=30\n",
        "\n",
        ">>> heavy_emb12 + Derived (n=4 h=64 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.056601 | RMSE=0.06375 | best=0.06375 | patience=8\n",
        "    Epoch 05 | train_loss=0.000436 | RMSE=0.03380 | best=0.03380 | patience=8\n",
        "    Epoch 10 | train_loss=0.000334 | RMSE=0.02832 | best=0.02832 | patience=8\n",
        "    Epoch 15 | train_loss=0.000361 | RMSE=0.02891 | best=0.02832 | patience=3\n",
        "  FINAL: MAE=0.028318 RMSE=0.028318 best_epoch=10\n",
        "\n",
        ">>> heavy_emb12 + Load-type (n=4 h=64 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.043505 | RMSE=0.03714 | best=0.03714 | patience=8\n",
        "    Epoch 05 | train_loss=0.000169 | RMSE=0.02128 | best=0.02116 | patience=8\n",
        "    Epoch 10 | train_loss=0.000140 | RMSE=0.02229 | best=0.01925 | patience=7\n",
        "    Epoch 15 | train_loss=0.000127 | RMSE=0.02100 | best=0.01694 | patience=7\n",
        "    Epoch 20 | train_loss=0.000115 | RMSE=0.01854 | best=0.01694 | patience=2\n",
        "  FINAL: MAE=0.016942 RMSE=0.016942 best_epoch=14\n",
        "\n",
        ">>> wide_shallow_emb12 + Original (n=2 h=128 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.039086 | RMSE=0.05217 | best=0.05217 | patience=8\n",
        "    Epoch 05 | train_loss=0.000494 | RMSE=0.03701 | best=0.03600 | patience=8\n",
        "    Epoch 10 | train_loss=0.000435 | RMSE=0.03336 | best=0.03164 | patience=7\n",
        "    Epoch 15 | train_loss=0.000435 | RMSE=0.03715 | best=0.03164 | patience=2\n",
        "  FINAL: MAE=0.031643 RMSE=0.031643 best_epoch=9\n",
        "\n",
        ">>> wide_shallow_emb12 + Derived (n=2 h=128 emb=12/6)\n",
        "    Epoch 01 | train_loss=0.038990 | RMSE=0.04840 | best=0.04840 | patience=8\n",
        "    Epoch 05 | train_loss=0.000557 | RMSE=0.03623 | best=0.03623 | patience=8\n",
        "    Epoch 10 | train_loss=0.000489 | RMSE=0.03584 | best=0.03529 | patience=7\n",
        "    Epoch 15 | train_loss=0.000443 | RMSE=0.03341 | best=0.03341 | patience=8\n",
        "    Epoch 20 | train_loss=0.000431 | RMSE=0.03563 | best=0.03109 | patience=5\n",
        "    Epoch 25 | train_loss=0.000397 | RMSE=0.03728 | best=0.03049 | patience=5\n",
        "    Epoch 30 | train_loss=0.000362 | RMSE=0.04038 | best=0.03049 | patience=0\n",
        "  FINAL: MAE=0.030492 RMSE=0.030492 best_epoch=22\n",
        "\n",
        ">>> wide_shallow_emb12 + Load-type (n=2 h=128 emb=12/6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12ce45ce",
      "metadata": {
        "id": "12ce45ce"
      },
      "source": [
        "## 3. Narrow exploration (10 promising configs × 3 datasets)\n",
        "\n",
        "Runs `gnn_narrow_exploration.py` — 10 configs derived from Blocks 1–2 rankings. Uses **30% data** and **corrected MAE/RMSE**.\n",
        "\n",
        "**Explores:**\n",
        "- **Depth:** 3–4 layers on best 2-layer configs (light_emb_h96, light_xwide_emb, wide_shallow_h160)\n",
        "- **Node/edge normalization:** LayerNorm on node and edge features\n",
        "- **Phase-aware:** One-hot phase features or 3 separate subgraphs (one per phase)\n",
        "\n",
        "**Configs:** light_emb_h96_depth3/4, light_xwide_emb_depth3, light_emb_h96_norm, light_xwide_emb_norm, wide_shallow_h160_depth3, light_wide_emb12_norm, light_emb_h96_phase_onehot, light_xwide_emb_phase_onehot, light_emb_h96_phase_subgraph\n",
        "\n",
        "**Run the cell below to execute.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e560a969",
      "metadata": {
        "id": "e560a969"
      },
      "outputs": [],
      "source": [
        "%run gnn_narrow_exploration.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a88d7e",
      "metadata": {
        "id": "e8a88d7e"
      },
      "source": [
        "======================================================================\n",
        "NARROW EXPLORATION: 30% data, 10 configs × 3 datasets\n",
        "Working dir: /content/GNN-Sandia\n",
        "  gnn_samples_out: OK (edge_csv=True, node_csv=True)\n",
        "  gnn_samples_inj_full: OK (edge_csv=True, node_csv=True)\n",
        "  gnn_samples_loadtype_full: OK (edge_csv=True, node_csv=True)\n",
        "Corrected MAE/RMSE | Depth | Norm | Phase subgraph/onehot\n",
        "======================================================================\n",
        "\n",
        ">>> light_emb_h96_depth3 + Original (n=3 h=96 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.040896 | RMSE=0.02741 | best=0.02741 | patience=8\n",
        "    Epoch 05 | train_loss=0.000491 | RMSE=0.02128 | best=0.01918 | patience=8\n",
        "    Epoch 10 | train_loss=0.000401 | RMSE=0.02454 | best=0.01902 | patience=7\n",
        "    Epoch 15 | train_loss=0.000341 | RMSE=0.01674 | best=0.01663 | patience=4\n",
        "  FINAL: MAE=0.011865 RMSE=0.016632 best_epoch=11\n",
        "\n",
        ">>> light_emb_h96_depth3 + Derived (n=3 h=96 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.031346 | RMSE=0.02749 | best=0.02749 | patience=8\n",
        "    Epoch 05 | train_loss=0.000485 | RMSE=0.02663 | best=0.01947 | patience=8\n",
        "    Epoch 10 | train_loss=0.000360 | RMSE=0.01820 | best=0.01740 | patience=7\n",
        "    Epoch 15 | train_loss=0.000340 | RMSE=0.01865 | best=0.01657 | patience=4\n",
        "    Epoch 20 | train_loss=0.000319 | RMSE=0.01711 | best=0.01616 | patience=7\n",
        "    Epoch 25 | train_loss=0.000314 | RMSE=0.02675 | best=0.01600 | patience=5\n",
        "    Epoch 30 | train_loss=0.000284 | RMSE=0.01642 | best=0.01568 | patience=5\n",
        "    Epoch 35 | train_loss=0.000297 | RMSE=0.01853 | best=0.01568 | patience=0\n",
        "  FINAL: MAE=0.011171 RMSE=0.015677 best_epoch=27\n",
        "\n",
        ">>> light_emb_h96_depth3 + Load-type (n=3 h=96 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.044466 | RMSE=0.01995 | best=0.01995 | patience=8\n",
        "    Epoch 05 | train_loss=0.000169 | RMSE=0.01075 | best=0.01075 | patience=8\n",
        "    Epoch 10 | train_loss=0.000140 | RMSE=0.01198 | best=0.01051 | patience=7\n",
        "    Epoch 15 | train_loss=0.000123 | RMSE=0.01410 | best=0.01013 | patience=4\n",
        "    Epoch 20 | train_loss=0.000123 | RMSE=0.01000 | best=0.00997 | patience=6\n",
        "    Epoch 25 | train_loss=0.000111 | RMSE=0.01175 | best=0.00939 | patience=5\n",
        "    Epoch 30 | train_loss=0.000116 | RMSE=0.01203 | best=0.00921 | patience=7\n",
        "    Epoch 35 | train_loss=0.000113 | RMSE=0.00926 | best=0.00921 | patience=2\n",
        "  FINAL: MAE=0.006573 RMSE=0.009212 best_epoch=29\n",
        "\n",
        ">>> light_emb_h96_depth4 + Original (n=4 h=96 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.035387 | RMSE=0.03472 | best=0.03472 | patience=8\n",
        "    Epoch 05 | train_loss=0.000458 | RMSE=0.02003 | best=0.02003 | patience=8\n",
        "    Epoch 10 | train_loss=0.000373 | RMSE=0.01904 | best=0.01817 | patience=7\n",
        "    Epoch 15 | train_loss=0.000347 | RMSE=0.01706 | best=0.01650 | patience=6\n",
        "    Epoch 20 | train_loss=0.000339 | RMSE=0.01948 | best=0.01613 | patience=6\n",
        "    Epoch 25 | train_loss=0.000364 | RMSE=0.02069 | best=0.01578 | patience=4\n",
        "  FINAL: MAE=0.010919 RMSE=0.015775 best_epoch=21\n",
        "\n",
        ">>> light_emb_h96_depth4 + Derived (n=4 h=96 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.041979 | RMSE=0.03401 | best=0.03401 | patience=8\n",
        "    Epoch 05 | train_loss=0.000422 | RMSE=0.01808 | best=0.01808 | patience=8\n",
        "    Epoch 10 | train_loss=0.000334 | RMSE=0.01579 | best=0.01579 | patience=8\n",
        "    Epoch 15 | train_loss=0.000277 | RMSE=0.01578 | best=0.01501 | patience=5\n",
        "    Epoch 20 | train_loss=0.000266 | RMSE=0.02974 | best=0.01449 | patience=6\n",
        "    Epoch 25 | train_loss=0.000284 | RMSE=0.01479 | best=0.01449 | patience=1\n",
        "  FINAL: MAE=0.010575 RMSE=0.014493 best_epoch=18\n",
        "\n",
        ">>> light_emb_h96_depth4 + Load-type (n=4 h=96 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.042840 | RMSE=0.01692 | best=0.01692 | patience=8\n",
        "    Epoch 05 | train_loss=0.000148 | RMSE=0.01203 | best=0.01203 | patience=8\n",
        "    Epoch 10 | train_loss=0.000134 | RMSE=0.01024 | best=0.01024 | patience=8\n",
        "    Epoch 15 | train_loss=0.000119 | RMSE=0.01315 | best=0.01011 | patience=4\n",
        "  FINAL: MAE=0.007172 RMSE=0.010107 best_epoch=11\n",
        "\n",
        ">>> light_xwide_emb_depth3 + Original (n=3 h=128 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.044572 | RMSE=0.02892 | best=0.02892 | patience=8\n",
        "    Epoch 05 | train_loss=0.000598 | RMSE=0.02082 | best=0.02082 | patience=8\n",
        "    Epoch 10 | train_loss=0.000466 | RMSE=0.02933 | best=0.01798 | patience=7\n",
        "    Epoch 15 | train_loss=0.000340 | RMSE=0.02507 | best=0.01798 | patience=2\n",
        "    Epoch 20 | train_loss=0.000308 | RMSE=0.01759 | best=0.01576 | patience=6\n",
        "    Epoch 25 | train_loss=0.000357 | RMSE=0.01599 | best=0.01570 | patience=6\n",
        "    Epoch 30 | train_loss=0.000360 | RMSE=0.01830 | best=0.01570 | patience=1\n",
        "  FINAL: MAE=0.010870 RMSE=0.015703 best_epoch=23\n",
        "\n",
        ">>> light_xwide_emb_depth3 + Derived (n=3 h=128 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.036541 | RMSE=0.02713 | best=0.02713 | patience=8\n",
        "    Epoch 05 | train_loss=0.000500 | RMSE=0.02586 | best=0.01895 | patience=8\n",
        "    Epoch 10 | train_loss=0.000423 | RMSE=0.02091 | best=0.01881 | patience=7\n",
        "    Epoch 15 | train_loss=0.000369 | RMSE=0.01824 | best=0.01718 | patience=4\n",
        "  FINAL: MAE=0.012284 RMSE=0.017177 best_epoch=11\n",
        "\n",
        ">>> light_xwide_emb_depth3 + Load-type (n=3 h=128 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.028478 | RMSE=0.01499 | best=0.01499 | patience=8\n",
        "    Epoch 05 | train_loss=0.000173 | RMSE=0.01431 | best=0.01147 | patience=8\n",
        "    Epoch 10 | train_loss=0.000146 | RMSE=0.01388 | best=0.01019 | patience=7\n",
        "    Epoch 15 | train_loss=0.000135 | RMSE=0.00984 | best=0.00964 | patience=7\n",
        "    Epoch 20 | train_loss=0.000115 | RMSE=0.01188 | best=0.00950 | patience=7\n",
        "    Epoch 25 | train_loss=0.000143 | RMSE=0.01025 | best=0.00941 | patience=7\n",
        "    Epoch 30 | train_loss=0.000133 | RMSE=0.00984 | best=0.00929 | patience=6\n",
        "    Epoch 35 | train_loss=0.000139 | RMSE=0.01192 | best=0.00909 | patience=7\n",
        "    Epoch 40 | train_loss=0.000113 | RMSE=0.01084 | best=0.00909 | patience=2\n",
        "  FINAL: MAE=0.006161 RMSE=0.009093 best_epoch=34\n",
        "\n",
        ">>> light_emb_h96_norm + Original (n=2 h=96 norm=True phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.048697 | RMSE=0.03620 | best=0.03620 | patience=8\n",
        "    Epoch 05 | train_loss=0.000938 | RMSE=0.02515 | best=0.02515 | patience=8\n",
        "    Epoch 10 | train_loss=0.000434 | RMSE=0.02410 | best=0.01847 | patience=7\n",
        "    Epoch 15 | train_loss=0.000421 | RMSE=0.01788 | best=0.01788 | patience=8\n",
        "    Epoch 20 | train_loss=0.000416 | RMSE=0.01795 | best=0.01781 | patience=7\n",
        "    Epoch 25 | train_loss=0.000379 | RMSE=0.02163 | best=0.01781 | patience=2\n",
        "  FINAL: MAE=0.012090 RMSE=0.017812 best_epoch=19\n",
        "\n",
        ">>> light_emb_h96_norm + Derived (n=2 h=96 norm=True phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.030617 | RMSE=0.03776 | best=0.03776 | patience=8\n",
        "    Epoch 05 | train_loss=0.000541 | RMSE=0.02727 | best=0.02401 | patience=8\n",
        "    Epoch 10 | train_loss=0.000485 | RMSE=0.02018 | best=0.01873 | patience=7\n",
        "    Epoch 15 | train_loss=0.000390 | RMSE=0.01802 | best=0.01802 | patience=8\n",
        "    Epoch 20 | train_loss=0.000422 | RMSE=0.01934 | best=0.01802 | patience=3\n",
        "  FINAL: MAE=0.012799 RMSE=0.018020 best_epoch=15\n",
        "\n",
        ">>> light_emb_h96_norm + Load-type (n=2 h=96 norm=True phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.048316 | RMSE=0.03090 | best=0.03090 | patience=8\n",
        "    Epoch 05 | train_loss=0.000189 | RMSE=0.01430 | best=0.01244 | patience=8\n",
        "    Epoch 10 | train_loss=0.000148 | RMSE=0.01321 | best=0.01059 | patience=7\n",
        "    Epoch 15 | train_loss=0.000125 | RMSE=0.01048 | best=0.01020 | patience=7\n",
        "    Epoch 20 | train_loss=0.000152 | RMSE=0.00995 | best=0.00945 | patience=6\n",
        "    Epoch 25 | train_loss=0.000125 | RMSE=0.01014 | best=0.00924 | patience=7\n",
        "    Epoch 30 | train_loss=0.000116 | RMSE=0.00924 | best=0.00924 | patience=8\n",
        "    Epoch 35 | train_loss=0.000140 | RMSE=0.00934 | best=0.00923 | patience=5\n",
        "    Epoch 40 | train_loss=0.000113 | RMSE=0.01101 | best=0.00923 | patience=0\n",
        "  FINAL: MAE=0.006387 RMSE=0.009228 best_epoch=32\n",
        "\n",
        ">>> light_xwide_emb_norm + Original (n=2 h=128 norm=True phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.032535 | RMSE=0.03563 | best=0.03563 | patience=8\n",
        "    Epoch 05 | train_loss=0.000531 | RMSE=0.02050 | best=0.02050 | patience=8\n",
        "    Epoch 10 | train_loss=0.000430 | RMSE=0.01847 | best=0.01816 | patience=7\n",
        "    Epoch 15 | train_loss=0.000392 | RMSE=0.01804 | best=0.01797 | patience=6\n",
        "    Epoch 20 | train_loss=0.000372 | RMSE=0.02381 | best=0.01739 | patience=6\n",
        "    Epoch 25 | train_loss=0.000403 | RMSE=0.01737 | best=0.01725 | patience=7\n",
        "    Epoch 30 | train_loss=0.000386 | RMSE=0.01877 | best=0.01725 | patience=2\n",
        "  FINAL: MAE=0.012028 RMSE=0.017246 best_epoch=24\n",
        "\n",
        ">>> light_xwide_emb_norm + Derived (n=2 h=128 norm=True phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.033206 | RMSE=0.03906 | best=0.03906 | patience=8\n",
        "    Epoch 05 | train_loss=0.000631 | RMSE=0.02035 | best=0.02035 | patience=8\n",
        "    Epoch 10 | train_loss=0.000485 | RMSE=0.02765 | best=0.01871 | patience=7\n",
        "    Epoch 15 | train_loss=0.000418 | RMSE=0.01823 | best=0.01823 | patience=8\n",
        "    Epoch 20 | train_loss=0.000417 | RMSE=0.01962 | best=0.01823 | patience=3\n",
        "    Epoch 25 | train_loss=0.000383 | RMSE=0.01763 | best=0.01763 | patience=8\n",
        "    Epoch 30 | train_loss=0.000386 | RMSE=0.02111 | best=0.01763 | patience=3\n",
        "  FINAL: MAE=0.012475 RMSE=0.017626 best_epoch=25\n",
        "\n",
        ">>> light_xwide_emb_norm + Load-type (n=2 h=128 norm=True phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.048380 | RMSE=0.03347 | best=0.03347 | patience=8\n",
        "    Epoch 05 | train_loss=0.000138 | RMSE=0.01050 | best=0.01050 | patience=8\n",
        "    Epoch 10 | train_loss=0.000154 | RMSE=0.02293 | best=0.00978 | patience=7\n",
        "    Epoch 15 | train_loss=0.000174 | RMSE=0.01532 | best=0.00948 | patience=7\n",
        "    Epoch 20 | train_loss=0.000161 | RMSE=0.00953 | best=0.00948 | patience=2\n",
        "  FINAL: MAE=0.006847 RMSE=0.009483 best_epoch=14\n",
        "\n",
        ">>> wide_shallow_h160_depth3 + Original (n=3 h=160 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.028647 | RMSE=0.02563 | best=0.02563 | patience=8\n",
        "    Epoch 05 | train_loss=0.000463 | RMSE=0.02503 | best=0.02008 | patience=8\n",
        "    Epoch 10 | train_loss=0.000413 | RMSE=0.01724 | best=0.01724 | patience=8\n",
        "    Epoch 15 | train_loss=0.000481 | RMSE=0.02030 | best=0.01684 | patience=6\n",
        "    Epoch 20 | train_loss=0.000359 | RMSE=0.01634 | best=0.01627 | patience=6\n",
        "    Epoch 25 | train_loss=0.000329 | RMSE=0.01821 | best=0.01596 | patience=7\n",
        "    Epoch 30 | train_loss=0.000306 | RMSE=0.01814 | best=0.01572 | patience=7\n",
        "    Epoch 35 | train_loss=0.000304 | RMSE=0.01540 | best=0.01540 | patience=8\n",
        "    Epoch 40 | train_loss=0.000335 | RMSE=0.01781 | best=0.01539 | patience=4\n",
        "  FINAL: MAE=0.010522 RMSE=0.015386 best_epoch=36\n",
        "\n",
        ">>> wide_shallow_h160_depth3 + Derived (n=3 h=160 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.029531 | RMSE=0.03190 | best=0.03190 | patience=8\n",
        "    Epoch 05 | train_loss=0.000473 | RMSE=0.01755 | best=0.01755 | patience=8\n",
        "    Epoch 10 | train_loss=0.000413 | RMSE=0.01868 | best=0.01697 | patience=7\n",
        "    Epoch 15 | train_loss=0.000382 | RMSE=0.01609 | best=0.01609 | patience=8\n",
        "    Epoch 20 | train_loss=0.000328 | RMSE=0.01615 | best=0.01609 | patience=3\n",
        "  FINAL: MAE=0.011527 RMSE=0.016087 best_epoch=15\n",
        "\n",
        ">>> wide_shallow_h160_depth3 + Load-type (n=3 h=160 norm=False phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.036693 | RMSE=0.02446 | best=0.02446 | patience=8\n",
        "    Epoch 05 | train_loss=0.000179 | RMSE=0.01463 | best=0.01112 | patience=8\n",
        "    Epoch 10 | train_loss=0.000135 | RMSE=0.01221 | best=0.01023 | patience=7\n",
        "    Epoch 15 | train_loss=0.000141 | RMSE=0.01051 | best=0.00997 | patience=5\n",
        "    Epoch 20 | train_loss=0.000130 | RMSE=0.00991 | best=0.00936 | patience=4\n",
        "  FINAL: MAE=0.006701 RMSE=0.009360 best_epoch=16\n",
        "\n",
        ">>> light_wide_emb12_norm + Original (n=2 h=64 norm=True phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.036888 | RMSE=0.03610 | best=0.03610 | patience=8\n",
        "    Epoch 05 | train_loss=0.001215 | RMSE=0.03367 | best=0.03367 | patience=8\n",
        "    Epoch 10 | train_loss=0.000439 | RMSE=0.01906 | best=0.01906 | patience=8\n",
        "    Epoch 15 | train_loss=0.000392 | RMSE=0.01990 | best=0.01789 | patience=5\n",
        "    Epoch 20 | train_loss=0.000381 | RMSE=0.01876 | best=0.01762 | patience=6\n",
        "    Epoch 25 | train_loss=0.000358 | RMSE=0.01725 | best=0.01719 | patience=6\n",
        "    Epoch 30 | train_loss=0.000368 | RMSE=0.01943 | best=0.01706 | patience=6\n",
        "    Epoch 35 | train_loss=0.000350 | RMSE=0.01733 | best=0.01706 | patience=1\n",
        "  FINAL: MAE=0.011683 RMSE=0.017060 best_epoch=28\n",
        "\n",
        ">>> light_wide_emb12_norm + Derived (n=2 h=64 norm=True phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.065882 | RMSE=0.03607 | best=0.03607 | patience=8\n",
        "    Epoch 05 | train_loss=0.001030 | RMSE=0.03352 | best=0.03241 | patience=8\n",
        "    Epoch 10 | train_loss=0.000496 | RMSE=0.02017 | best=0.02017 | patience=8\n",
        "    Epoch 15 | train_loss=0.000426 | RMSE=0.01933 | best=0.01870 | patience=7\n",
        "    Epoch 20 | train_loss=0.000510 | RMSE=0.02550 | best=0.01870 | patience=2\n",
        "  FINAL: MAE=0.013484 RMSE=0.018701 best_epoch=14\n",
        "\n",
        ">>> light_wide_emb12_norm + Load-type (n=2 h=64 norm=True phase_sg=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.037256 | RMSE=0.03577 | best=0.03577 | patience=8\n",
        "    Epoch 05 | train_loss=0.000137 | RMSE=0.01045 | best=0.01045 | patience=8\n",
        "    Epoch 10 | train_loss=0.000142 | RMSE=0.01002 | best=0.01002 | patience=8\n",
        "    Epoch 15 | train_loss=0.000143 | RMSE=0.00974 | best=0.00965 | patience=6\n",
        "    Epoch 20 | train_loss=0.000127 | RMSE=0.01048 | best=0.00965 | patience=1\n",
        "  FINAL: MAE=0.006995 RMSE=0.009655 best_epoch=13\n",
        "\n",
        ">>> light_emb_h96_phase_onehot + Original (n=2 h=96 norm=False phase_sg=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.038379 | RMSE=0.03023 | best=0.03023 | patience=8\n",
        "    Epoch 05 | train_loss=0.000410 | RMSE=0.01868 | best=0.01868 | patience=8\n",
        "    Epoch 10 | train_loss=0.000400 | RMSE=0.01878 | best=0.01729 | patience=7\n",
        "    Epoch 15 | train_loss=0.000384 | RMSE=0.02037 | best=0.01729 | patience=2\n",
        "    Epoch 20 | train_loss=0.000367 | RMSE=0.01909 | best=0.01688 | patience=5\n",
        "    Epoch 25 | train_loss=0.000360 | RMSE=0.02100 | best=0.01688 | patience=0\n",
        "  FINAL: MAE=0.011756 RMSE=0.016881 best_epoch=17\n",
        "\n",
        ">>> light_emb_h96_phase_onehot + Derived (n=2 h=96 norm=False phase_sg=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.035010 | RMSE=0.03025 | best=0.03025 | patience=8\n",
        "    Epoch 05 | train_loss=0.000510 | RMSE=0.02028 | best=0.02028 | patience=8\n",
        "    Epoch 10 | train_loss=0.000510 | RMSE=0.01904 | best=0.01904 | patience=8\n",
        "    Epoch 15 | train_loss=0.000400 | RMSE=0.01892 | best=0.01892 | patience=8\n",
        "    Epoch 20 | train_loss=0.000376 | RMSE=0.01816 | best=0.01816 | patience=8\n",
        "    Epoch 25 | train_loss=0.000385 | RMSE=0.01839 | best=0.01816 | patience=3\n",
        "  FINAL: MAE=0.013188 RMSE=0.018163 best_epoch=20\n",
        "\n",
        ">>> light_emb_h96_phase_onehot + Load-type (n=2 h=96 norm=False phase_sg=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.036074 | RMSE=0.02707 | best=0.02707 | patience=8\n",
        "    Epoch 05 | train_loss=0.000160 | RMSE=0.01925 | best=0.01095 | patience=8\n",
        "    Epoch 10 | train_loss=0.000134 | RMSE=0.01065 | best=0.00974 | patience=7\n",
        "    Epoch 15 | train_loss=0.000109 | RMSE=0.01208 | best=0.00971 | patience=5\n",
        "    Epoch 20 | train_loss=0.000106 | RMSE=0.01014 | best=0.00901 | patience=6\n",
        "    Epoch 25 | train_loss=0.000102 | RMSE=0.00895 | best=0.00886 | patience=5\n",
        "    Epoch 30 | train_loss=0.000117 | RMSE=0.01300 | best=0.00886 | patience=0\n",
        "  FINAL: MAE=0.006189 RMSE=0.008861 best_epoch=22\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot + Original (n=2 h=128 norm=False phase_sg=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.041239 | RMSE=0.02949 | best=0.02949 | patience=8\n",
        "    Epoch 05 | train_loss=0.000543 | RMSE=0.02105 | best=0.02025 | patience=8\n",
        "    Epoch 10 | train_loss=0.000487 | RMSE=0.01822 | best=0.01822 | patience=8\n",
        "    Epoch 15 | train_loss=0.000382 | RMSE=0.02135 | best=0.01718 | patience=6\n",
        "    Epoch 20 | train_loss=0.000381 | RMSE=0.02103 | best=0.01718 | patience=1\n",
        "  FINAL: MAE=0.012045 RMSE=0.017184 best_epoch=13\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot + Derived (n=2 h=128 norm=False phase_sg=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.031501 | RMSE=0.02567 | best=0.02567 | patience=8\n",
        "    Epoch 05 | train_loss=0.000552 | RMSE=0.02945 | best=0.02206 | patience=8\n",
        "    Epoch 10 | train_loss=0.000447 | RMSE=0.02910 | best=0.02131 | patience=7\n",
        "    Epoch 15 | train_loss=0.000419 | RMSE=0.02142 | best=0.01855 | patience=5\n",
        "    Epoch 20 | train_loss=0.000411 | RMSE=0.02065 | best=0.01827 | patience=4\n",
        "  FINAL: MAE=0.013308 RMSE=0.018267 best_epoch=16\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot + Load-type (n=2 h=128 norm=False phase_sg=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.027257 | RMSE=0.02082 | best=0.02082 | patience=8\n",
        "    Epoch 05 | train_loss=0.000127 | RMSE=0.01295 | best=0.01170 | patience=8\n",
        "    Epoch 10 | train_loss=0.000113 | RMSE=0.01105 | best=0.00977 | patience=7\n",
        "    Epoch 15 | train_loss=0.000127 | RMSE=0.01128 | best=0.00903 | patience=6\n",
        "    Epoch 20 | train_loss=0.000119 | RMSE=0.01318 | best=0.00903 | patience=1\n",
        "  FINAL: MAE=0.006261 RMSE=0.009028 best_epoch=13\n",
        "\n",
        ">>> light_emb_h96_phase_subgraph + Original (n=2 h=96 norm=False phase_sg=True phase_oh=False)\n",
        "  ERROR: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)\n",
        "\n",
        ">>> light_emb_h96_phase_subgraph + Derived (n=2 h=96 norm=False phase_sg=True phase_oh=False)\n",
        "Traceback (most recent call last):\n",
        "  File \"/content/GNN-Sandia/gnn_narrow_exploration.py\", line 446, in main\n",
        "    mae, rmse, best_ep = train_one(out_dir, feature_cols, ds_label, cfg_name, n_emb, e_emb, h_dim, n_layers,\n",
        "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/content/GNN-Sandia/gnn_narrow_exploration.py\", line 381, in train_one\n",
        "    loss = F.mse_loss(model(data), data.y)\n",
        "                      ^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
        "    return self._call_impl(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
        "    return forward_call(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/content/GNN-Sandia/gnn_narrow_exploration.py\", line 209, in forward\n",
        "    r = self.edge_emb(eid_offset)\n",
        "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
        "    return self._call_impl(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
        "    return forward_call(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py\", line 191, in forward\n",
        "    return F.embedding(\n",
        "           ^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2567, in embedding\n",
        "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)\n",
        "  ERROR: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)\n",
        "\n",
        ">>> light_emb_h96_phase_subgraph + Load-type (n=2 h=96 norm=False phase_sg=True phase_oh=False)\n",
        "Traceback (most recent call last):\n",
        "  File \"/content/GNN-Sandia/gnn_narrow_exploration.py\", line 446, in main\n",
        "    mae, rmse, best_ep = train_one(out_dir, feature_cols, ds_label, cfg_name, n_emb, e_emb, h_dim, n_layers,\n",
        "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/content/GNN-Sandia/gnn_narrow_exploration.py\", line 381, in train_one\n",
        "    loss = F.mse_loss(model(data), data.y)\n",
        "                      ^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
        "    return self._call_impl(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
        "    return forward_call(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/content/GNN-Sandia/gnn_narrow_exploration.py\", line 209, in forward\n",
        "    r = self.edge_emb(eid_offset)\n",
        "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
        "    return self._call_impl(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
        "    return forward_call(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py\", line 191, in forward\n",
        "    return F.embedding(\n",
        "           ^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2567, in embedding\n",
        "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)\n",
        "  ERROR: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)\n",
        "\n",
        "======================================================================\n",
        "SUMMARY (sorted by MAE)\n",
        "======================================================================\n",
        "                          Config    Dataset       MAE      RMSE  Best_epoch Target_hit\n",
        "0         light_xwide_emb_depth3  Load-type  0.006161  0.009093          34           \n",
        "1     light_emb_h96_phase_onehot  Load-type  0.006189  0.008861          22           \n",
        "2   light_xwide_emb_phase_onehot  Load-type  0.006261  0.009028          13           \n",
        "3             light_emb_h96_norm  Load-type  0.006387  0.009228          32           \n",
        "4           light_emb_h96_depth3  Load-type  0.006573  0.009212          29           \n",
        "5       wide_shallow_h160_depth3  Load-type  0.006701  0.009360          16           \n",
        "6           light_xwide_emb_norm  Load-type  0.006847  0.009483          14           \n",
        "7          light_wide_emb12_norm  Load-type  0.006995  0.009655          13           \n",
        "8           light_emb_h96_depth4  Load-type  0.007172  0.010107          11           \n",
        "9       wide_shallow_h160_depth3   Original  0.010522  0.015386          36           \n",
        "10          light_emb_h96_depth4    Derived  0.010575  0.014493          18           \n",
        "11        light_xwide_emb_depth3   Original  0.010870  0.015703          23           \n",
        "12          light_emb_h96_depth4   Original  0.010919  0.015775          21           \n",
        "13          light_emb_h96_depth3    Derived  0.011171  0.015677          27           \n",
        "14      wide_shallow_h160_depth3    Derived  0.011527  0.016087          15           \n",
        "15         light_wide_emb12_norm   Original  0.011683  0.017060          28           \n",
        "16    light_emb_h96_phase_onehot   Original  0.011756  0.016881          17           \n",
        "17          light_emb_h96_depth3   Original  0.011865  0.016632          11           \n",
        "18          light_xwide_emb_norm   Original  0.012028  0.017246          24           \n",
        "19  light_xwide_emb_phase_onehot   Original  0.012045  0.017184          13           \n",
        "20            light_emb_h96_norm   Original  0.012090  0.017812          19           \n",
        "21        light_xwide_emb_depth3    Derived  0.012284  0.017177          11           \n",
        "22          light_xwide_emb_norm    Derived  0.012475  0.017626          25           \n",
        "23            light_emb_h96_norm    Derived  0.012799  0.018020          15           \n",
        "24    light_emb_h96_phase_onehot    Derived  0.013188  0.018163          20           \n",
        "25  light_xwide_emb_phase_onehot    Derived  0.013308  0.018267          16           \n",
        "26         light_wide_emb12_norm    Derived  0.013484  0.018701          14           \n",
        "\n",
        "Best: light_xwide_emb_depth3 + Load-type | MAE=0.006161 | RMSE=0.009093\n",
        "Traceback (most recent call last):\n",
        "  File \"/content/GNN-Sandia/gnn_narrow_exploration.py\", line 446, in main\n",
        "    mae, rmse, best_ep = train_one(out_dir, feature_cols, ds_label, cfg_name, n_emb, e_emb, h_dim, n_layers,\n",
        "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/content/GNN-Sandia/gnn_narrow_exploration.py\", line 381, in train_one\n",
        "    loss = F.mse_loss(model(data), data.y)\n",
        "                      ^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
        "    return self._call_impl(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
        "    return forward_call(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/content/GNN-Sandia/gnn_narrow_exploration.py\", line 209, in forward\n",
        "    r = self.edge_emb(eid_offset)\n",
        "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
        "    return self._call_impl(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
        "    return forward_call(*args, **kwargs)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py\", line 191, in forward\n",
        "    return F.embedding(\n",
        "           ^^^^^^^^^^^^\n",
        "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2567, in embedding\n",
        "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0183e7",
      "metadata": {
        "id": "dd0183e7"
      },
      "source": [
        "## 4. Boost exploration (10 configs × 3 datasets)\n",
        "\n",
        "Runs `gnn_boost_exploration.py` — 10 configs derived from Block 3 best results. Target: beat MAE 0.006161. Uses **30% data**, **corrected MAE/RMSE**, **no dropout**.\n",
        "\n",
        "**Explores:**\n",
        "- **Deeper:** light_xwide_emb_depth4, wide_shallow_h160_depth4\n",
        "- **Wider:** light_xwide_emb_depth3_h160, light_xwide_emb_depth3_h192\n",
        "- **Phase onehot + depth:** light_xwide_emb_phase_onehot_depth3, light_emb_h96_phase_onehot_depth3\n",
        "- **Norm + depth:** light_xwide_emb_norm_depth3, light_emb_h96_norm_depth3\n",
        "- **Phase onehot + norm:** light_emb_h96_phase_onehot_norm\n",
        "- **Huber loss + LR scheduler:** light_xwide_emb_huber\n",
        "\n",
        "**Run the cell below to execute.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a98f31",
      "metadata": {
        "id": "b2a98f31"
      },
      "outputs": [],
      "source": [
        "%run gnn_boost_exploration.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X_sbRYsF7Ad5",
      "metadata": {
        "id": "X_sbRYsF7Ad5"
      },
      "source": [
        "======================================================================\n",
        "BOOST EXPLORATION: 30% data, 10 configs × 3 datasets\n",
        "Target: beat MAE 0.006161 | Depth | Norm | Phase onehot | Huber | LR scheduler\n",
        "Working dir: /content/GNN-Sandia\n",
        "  gnn_samples_out: OK (edge_csv=True, node_csv=True)\n",
        "  gnn_samples_inj_full: OK (edge_csv=True, node_csv=True)\n",
        "  gnn_samples_loadtype_full: OK (edge_csv=True, node_csv=True)\n",
        "======================================================================\n",
        "\n",
        ">>> light_xwide_emb_depth4 + Original (n=4 h=128 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.051355 | RMSE=0.03434 | best=0.03434 | patience=10\n",
        "    Epoch 05 | train_loss=0.000453 | RMSE=0.02176 | best=0.01962 | patience=10\n",
        "    Epoch 10 | train_loss=0.000417 | RMSE=0.01624 | best=0.01624 | patience=10\n",
        "    Epoch 15 | train_loss=0.000353 | RMSE=0.01573 | best=0.01573 | patience=10\n",
        "    Epoch 20 | train_loss=0.000332 | RMSE=0.01615 | best=0.01565 | patience=8\n",
        "    Epoch 25 | train_loss=0.000261 | RMSE=0.01561 | best=0.01561 | patience=10\n",
        "    Epoch 30 | train_loss=0.000292 | RMSE=0.01544 | best=0.01538 | patience=6\n",
        "    Epoch 35 | train_loss=0.000243 | RMSE=0.01526 | best=0.01526 | patience=10\n",
        "    Epoch 40 | train_loss=0.000243 | RMSE=0.01506 | best=0.01506 | patience=10\n",
        "    Epoch 45 | train_loss=0.000227 | RMSE=0.01502 | best=0.01485 | patience=6\n",
        "    Epoch 50 | train_loss=0.000228 | RMSE=0.01481 | best=0.01429 | patience=7\n",
        "  FINAL: MAE=0.009857 RMSE=0.014290 best_epoch=47\n",
        "\n",
        ">>> light_xwide_emb_depth4 + Derived (n=4 h=128 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.044543 | RMSE=0.03585 | best=0.03585 | patience=10\n",
        "    Epoch 05 | train_loss=0.000423 | RMSE=0.01842 | best=0.01842 | patience=10\n",
        "    Epoch 10 | train_loss=0.000347 | RMSE=0.01587 | best=0.01587 | patience=10\n",
        "    Epoch 15 | train_loss=0.000297 | RMSE=0.01475 | best=0.01475 | patience=10\n",
        "    Epoch 20 | train_loss=0.000277 | RMSE=0.01523 | best=0.01475 | patience=5\n",
        "    Epoch 25 | train_loss=0.000254 | RMSE=0.01506 | best=0.01415 | patience=9\n",
        "    Epoch 30 | train_loss=0.000233 | RMSE=0.01719 | best=0.01415 | patience=4\n",
        "    Epoch 35 | train_loss=0.000217 | RMSE=0.01449 | best=0.01406 | patience=8\n",
        "    Epoch 40 | train_loss=0.000200 | RMSE=0.01404 | best=0.01404 | patience=10\n",
        "    Epoch 45 | train_loss=0.000204 | RMSE=0.01399 | best=0.01399 | patience=10\n",
        "    Epoch 50 | train_loss=0.000210 | RMSE=0.01421 | best=0.01399 | patience=5\n",
        "  FINAL: MAE=0.009816 RMSE=0.013987 best_epoch=45\n",
        "\n",
        ">>> light_xwide_emb_depth4 + Load-type (n=4 h=128 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.051851 | RMSE=0.01387 | best=0.01387 | patience=10\n",
        "    Epoch 05 | train_loss=0.000135 | RMSE=0.01170 | best=0.01084 | patience=10\n",
        "    Epoch 10 | train_loss=0.000158 | RMSE=0.01122 | best=0.01047 | patience=10\n",
        "    Epoch 15 | train_loss=0.000100 | RMSE=0.01086 | best=0.00937 | patience=9\n",
        "    Epoch 20 | train_loss=0.000105 | RMSE=0.00917 | best=0.00917 | patience=10\n",
        "    Epoch 25 | train_loss=0.000121 | RMSE=0.00968 | best=0.00917 | patience=5\n",
        "    Epoch 30 | train_loss=0.000100 | RMSE=0.00938 | best=0.00917 | patience=9\n",
        "    Epoch 35 | train_loss=0.000107 | RMSE=0.01056 | best=0.00917 | patience=4\n",
        "  FINAL: MAE=0.006524 RMSE=0.009169 best_epoch=29\n",
        "\n",
        ">>> light_xwide_emb_depth3_h160 + Original (n=3 h=160 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.048028 | RMSE=0.02485 | best=0.02485 | patience=10\n",
        "    Epoch 05 | train_loss=0.000401 | RMSE=0.01806 | best=0.01806 | patience=10\n",
        "    Epoch 10 | train_loss=0.000381 | RMSE=0.01633 | best=0.01633 | patience=10\n",
        "    Epoch 15 | train_loss=0.000332 | RMSE=0.02254 | best=0.01633 | patience=6\n",
        "    Epoch 20 | train_loss=0.000281 | RMSE=0.01530 | best=0.01530 | patience=10\n",
        "    Epoch 25 | train_loss=0.000287 | RMSE=0.01566 | best=0.01519 | patience=6\n",
        "    Epoch 30 | train_loss=0.000239 | RMSE=0.01539 | best=0.01508 | patience=9\n",
        "    Epoch 35 | train_loss=0.000266 | RMSE=0.01512 | best=0.01508 | patience=4\n",
        "  FINAL: MAE=0.010387 RMSE=0.015084 best_epoch=29\n",
        "\n",
        ">>> light_xwide_emb_depth3_h160 + Derived (n=3 h=160 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.024270 | RMSE=0.02638 | best=0.02638 | patience=10\n",
        "    Epoch 05 | train_loss=0.000421 | RMSE=0.01727 | best=0.01727 | patience=10\n",
        "    Epoch 10 | train_loss=0.000351 | RMSE=0.01620 | best=0.01620 | patience=10\n",
        "    Epoch 15 | train_loss=0.000375 | RMSE=0.01929 | best=0.01620 | patience=6\n",
        "    Epoch 20 | train_loss=0.000283 | RMSE=0.01673 | best=0.01618 | patience=8\n",
        "    Epoch 25 | train_loss=0.000302 | RMSE=0.01702 | best=0.01580 | patience=9\n",
        "    Epoch 30 | train_loss=0.000295 | RMSE=0.01669 | best=0.01580 | patience=4\n",
        "  FINAL: MAE=0.011200 RMSE=0.015798 best_epoch=24\n",
        "\n",
        ">>> light_xwide_emb_depth3_h160 + Load-type (n=3 h=160 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.030195 | RMSE=0.01427 | best=0.01427 | patience=10\n",
        "    Epoch 05 | train_loss=0.000155 | RMSE=0.01082 | best=0.01082 | patience=10\n",
        "    Epoch 10 | train_loss=0.000143 | RMSE=0.01019 | best=0.01019 | patience=10\n",
        "    Epoch 15 | train_loss=0.000141 | RMSE=0.01366 | best=0.00996 | patience=6\n",
        "    Epoch 20 | train_loss=0.000135 | RMSE=0.01025 | best=0.00952 | patience=8\n",
        "    Epoch 25 | train_loss=0.000093 | RMSE=0.00989 | best=0.00952 | patience=3\n",
        "  FINAL: MAE=0.006485 RMSE=0.009516 best_epoch=18\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot_depth3 + Original (n=3 h=128 norm=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.028014 | RMSE=0.02431 | best=0.02431 | patience=10\n",
        "    Epoch 05 | train_loss=0.000456 | RMSE=0.01894 | best=0.01894 | patience=10\n",
        "    Epoch 10 | train_loss=0.000348 | RMSE=0.02192 | best=0.01773 | patience=10\n",
        "    Epoch 15 | train_loss=0.000340 | RMSE=0.01956 | best=0.01599 | patience=9\n",
        "    Epoch 20 | train_loss=0.000297 | RMSE=0.01635 | best=0.01599 | patience=4\n",
        "    Epoch 25 | train_loss=0.000256 | RMSE=0.01546 | best=0.01544 | patience=8\n",
        "    Epoch 30 | train_loss=0.000246 | RMSE=0.01529 | best=0.01529 | patience=10\n",
        "    Epoch 35 | train_loss=0.000249 | RMSE=0.01532 | best=0.01529 | patience=5\n",
        "    Epoch 40 | train_loss=0.000251 | RMSE=0.01517 | best=0.01517 | patience=10\n",
        "    Epoch 45 | train_loss=0.000254 | RMSE=0.01623 | best=0.01508 | patience=7\n",
        "    Epoch 50 | train_loss=0.000235 | RMSE=0.01524 | best=0.01508 | patience=2\n",
        "  FINAL: MAE=0.010285 RMSE=0.015084 best_epoch=42\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot_depth3 + Derived (n=3 h=128 norm=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.028538 | RMSE=0.02863 | best=0.02863 | patience=10\n",
        "    Epoch 05 | train_loss=0.000417 | RMSE=0.02659 | best=0.02013 | patience=10\n",
        "    Epoch 10 | train_loss=0.000356 | RMSE=0.02223 | best=0.01825 | patience=10\n",
        "    Epoch 15 | train_loss=0.000324 | RMSE=0.01680 | best=0.01618 | patience=9\n",
        "    Epoch 20 | train_loss=0.000318 | RMSE=0.01600 | best=0.01600 | patience=10\n",
        "    Epoch 25 | train_loss=0.000343 | RMSE=0.01786 | best=0.01596 | patience=8\n",
        "    Epoch 30 | train_loss=0.000326 | RMSE=0.01751 | best=0.01572 | patience=9\n",
        "    Epoch 35 | train_loss=0.000326 | RMSE=0.01604 | best=0.01572 | patience=4\n",
        "  FINAL: MAE=0.011185 RMSE=0.015717 best_epoch=29\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot_depth3 + Load-type (n=3 h=128 norm=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.029841 | RMSE=0.01580 | best=0.01580 | patience=10\n",
        "    Epoch 05 | train_loss=0.000168 | RMSE=0.02096 | best=0.01082 | patience=10\n",
        "    Epoch 10 | train_loss=0.000129 | RMSE=0.01152 | best=0.00982 | patience=10\n",
        "    Epoch 15 | train_loss=0.000130 | RMSE=0.00970 | best=0.00956 | patience=8\n",
        "    Epoch 20 | train_loss=0.000125 | RMSE=0.01373 | best=0.00942 | patience=9\n",
        "    Epoch 25 | train_loss=0.000128 | RMSE=0.00939 | best=0.00939 | patience=10\n",
        "    Epoch 30 | train_loss=0.000120 | RMSE=0.01665 | best=0.00939 | patience=5\n",
        "    Epoch 35 | train_loss=0.000098 | RMSE=0.01068 | best=0.00923 | patience=8\n",
        "    Epoch 40 | train_loss=0.000096 | RMSE=0.01160 | best=0.00916 | patience=7\n",
        "    Epoch 45 | train_loss=0.000087 | RMSE=0.00942 | best=0.00906 | patience=9\n",
        "    Epoch 50 | train_loss=0.000090 | RMSE=0.00911 | best=0.00906 | patience=4\n",
        "  FINAL: MAE=0.006154 RMSE=0.009062 best_epoch=44\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_depth3 + Original (n=3 h=96 norm=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.049657 | RMSE=0.02789 | best=0.02789 | patience=10\n",
        "    Epoch 05 | train_loss=0.000429 | RMSE=0.01996 | best=0.01956 | patience=10\n",
        "    Epoch 10 | train_loss=0.000359 | RMSE=0.02712 | best=0.01737 | patience=10\n",
        "    Epoch 15 | train_loss=0.000350 | RMSE=0.01958 | best=0.01619 | patience=6\n",
        "    Epoch 20 | train_loss=0.000280 | RMSE=0.01631 | best=0.01522 | patience=9\n",
        "    Epoch 25 | train_loss=0.000278 | RMSE=0.01675 | best=0.01521 | patience=8\n",
        "    Epoch 30 | train_loss=0.000249 | RMSE=0.01556 | best=0.01521 | patience=3\n",
        "    Epoch 35 | train_loss=0.000246 | RMSE=0.01531 | best=0.01513 | patience=6\n",
        "    Epoch 40 | train_loss=0.000231 | RMSE=0.01501 | best=0.01501 | patience=10\n",
        "    Epoch 45 | train_loss=0.000237 | RMSE=0.01502 | best=0.01501 | patience=5\n",
        "    Epoch 50 | train_loss=0.000233 | RMSE=0.01573 | best=0.01500 | patience=9\n",
        "  FINAL: MAE=0.010232 RMSE=0.015000 best_epoch=49\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_depth3 + Derived (n=3 h=96 norm=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.054663 | RMSE=0.03040 | best=0.03040 | patience=10\n",
        "    Epoch 05 | train_loss=0.000437 | RMSE=0.01915 | best=0.01915 | patience=10\n",
        "    Epoch 10 | train_loss=0.000429 | RMSE=0.02497 | best=0.01856 | patience=10\n",
        "    Epoch 15 | train_loss=0.000369 | RMSE=0.01692 | best=0.01692 | patience=10\n",
        "    Epoch 20 | train_loss=0.000336 | RMSE=0.01636 | best=0.01601 | patience=9\n",
        "    Epoch 25 | train_loss=0.000315 | RMSE=0.02214 | best=0.01592 | patience=8\n",
        "    Epoch 30 | train_loss=0.000310 | RMSE=0.01592 | best=0.01588 | patience=7\n",
        "    Epoch 35 | train_loss=0.000319 | RMSE=0.01855 | best=0.01567 | patience=8\n",
        "    Epoch 40 | train_loss=0.000265 | RMSE=0.01625 | best=0.01567 | patience=3\n",
        "    Epoch 45 | train_loss=0.000278 | RMSE=0.01627 | best=0.01566 | patience=7\n",
        "    Epoch 50 | train_loss=0.000275 | RMSE=0.01557 | best=0.01557 | patience=10\n",
        "  FINAL: MAE=0.010933 RMSE=0.015565 best_epoch=50\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_depth3 + Load-type (n=3 h=96 norm=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.045927 | RMSE=0.01818 | best=0.01818 | patience=10\n",
        "    Epoch 05 | train_loss=0.000152 | RMSE=0.01920 | best=0.01154 | patience=10\n",
        "    Epoch 10 | train_loss=0.000126 | RMSE=0.01016 | best=0.01007 | patience=10\n",
        "    Epoch 15 | train_loss=0.000130 | RMSE=0.01575 | best=0.00986 | patience=6\n",
        "    Epoch 20 | train_loss=0.000096 | RMSE=0.00937 | best=0.00913 | patience=9\n",
        "    Epoch 25 | train_loss=0.000097 | RMSE=0.00934 | best=0.00912 | patience=6\n",
        "    Epoch 30 | train_loss=0.000092 | RMSE=0.00920 | best=0.00900 | patience=9\n",
        "    Epoch 35 | train_loss=0.000088 | RMSE=0.00943 | best=0.00890 | patience=7\n",
        "    Epoch 40 | train_loss=0.000092 | RMSE=0.00950 | best=0.00887 | patience=6\n",
        "    Epoch 45 | train_loss=0.000083 | RMSE=0.00881 | best=0.00881 | patience=10\n",
        "    Epoch 50 | train_loss=0.000083 | RMSE=0.00944 | best=0.00880 | patience=6\n",
        "  FINAL: MAE=0.006114 RMSE=0.008798 best_epoch=46\n",
        "\n",
        ">>> light_xwide_emb_norm_depth3 + Original (n=3 h=128 norm=True phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.051440 | RMSE=0.03620 | best=0.03620 | patience=10\n",
        "    Epoch 05 | train_loss=0.001175 | RMSE=0.03049 | best=0.03049 | patience=10\n",
        "    Epoch 10 | train_loss=0.000455 | RMSE=0.02318 | best=0.01858 | patience=10\n",
        "    Epoch 15 | train_loss=0.000351 | RMSE=0.03183 | best=0.01696 | patience=8\n",
        "    Epoch 20 | train_loss=0.000322 | RMSE=0.02274 | best=0.01649 | patience=8\n",
        "    Epoch 25 | train_loss=0.000374 | RMSE=0.01656 | best=0.01646 | patience=8\n",
        "    Epoch 30 | train_loss=0.000378 | RMSE=0.02178 | best=0.01622 | patience=6\n",
        "    Epoch 35 | train_loss=0.000281 | RMSE=0.01703 | best=0.01597 | patience=8\n",
        "    Epoch 40 | train_loss=0.000279 | RMSE=0.01629 | best=0.01593 | patience=7\n",
        "    Epoch 45 | train_loss=0.000295 | RMSE=0.01617 | best=0.01590 | patience=7\n",
        "    Epoch 50 | train_loss=0.000268 | RMSE=0.01645 | best=0.01590 | patience=2\n",
        "  FINAL: MAE=0.010675 RMSE=0.015904 best_epoch=42\n",
        "\n",
        ">>> light_xwide_emb_norm_depth3 + Derived (n=3 h=128 norm=True phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.036078 | RMSE=0.03623 | best=0.03623 | patience=10\n",
        "    Epoch 05 | train_loss=0.001397 | RMSE=0.03910 | best=0.03586 | patience=10\n",
        "    Epoch 10 | train_loss=0.000672 | RMSE=0.02399 | best=0.02399 | patience=10\n",
        "    Epoch 15 | train_loss=0.000589 | RMSE=0.02398 | best=0.02281 | patience=6\n",
        "    Epoch 20 | train_loss=0.000587 | RMSE=0.02257 | best=0.02255 | patience=7\n",
        "    Epoch 25 | train_loss=0.000532 | RMSE=0.02301 | best=0.02255 | patience=2\n",
        "  FINAL: MAE=0.016389 RMSE=0.022550 best_epoch=17\n",
        "\n",
        ">>> light_xwide_emb_norm_depth3 + Load-type (n=3 h=128 norm=True phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.026905 | RMSE=0.03557 | best=0.03557 | patience=10\n",
        "    Epoch 05 | train_loss=0.000148 | RMSE=0.01424 | best=0.01110 | patience=10\n",
        "    Epoch 10 | train_loss=0.000156 | RMSE=0.01340 | best=0.01011 | patience=10\n",
        "    Epoch 15 | train_loss=0.000148 | RMSE=0.01070 | best=0.01000 | patience=6\n",
        "    Epoch 20 | train_loss=0.000133 | RMSE=0.01136 | best=0.00974 | patience=6\n",
        "    Epoch 25 | train_loss=0.000108 | RMSE=0.01005 | best=0.00929 | patience=8\n",
        "    Epoch 30 | train_loss=0.000113 | RMSE=0.00938 | best=0.00910 | patience=8\n",
        "    Epoch 35 | train_loss=0.000085 | RMSE=0.00905 | best=0.00905 | patience=10\n",
        "    Epoch 40 | train_loss=0.000086 | RMSE=0.00915 | best=0.00901 | patience=9\n",
        "    Epoch 45 | train_loss=0.000091 | RMSE=0.00895 | best=0.00895 | patience=10\n",
        "    Epoch 50 | train_loss=0.000088 | RMSE=0.00953 | best=0.00895 | patience=5\n",
        "  FINAL: MAE=0.006237 RMSE=0.008948 best_epoch=45\n",
        "\n",
        ">>> light_emb_h96_norm_depth3 + Original (n=3 h=96 norm=True phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.042396 | RMSE=0.03643 | best=0.03643 | patience=10\n",
        "    Epoch 05 | train_loss=0.001439 | RMSE=0.03767 | best=0.03625 | patience=10\n",
        "    Epoch 10 | train_loss=0.001408 | RMSE=0.03634 | best=0.03625 | patience=10\n",
        "    Epoch 15 | train_loss=0.001399 | RMSE=0.03672 | best=0.03625 | patience=6\n",
        "    Epoch 20 | train_loss=0.001354 | RMSE=0.03647 | best=0.03625 | patience=1\n",
        "  FINAL: MAE=0.028357 RMSE=0.036246 best_epoch=3\n",
        "\n",
        ">>> light_emb_h96_norm_depth3 + Derived (n=3 h=96 norm=True phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.031717 | RMSE=0.03621 | best=0.03621 | patience=10\n",
        "    Epoch 05 | train_loss=0.001386 | RMSE=0.03611 | best=0.03607 | patience=10\n",
        "    Epoch 10 | train_loss=0.001359 | RMSE=0.03610 | best=0.03607 | patience=10\n",
        "    Epoch 15 | train_loss=0.001326 | RMSE=0.03735 | best=0.03606 | patience=8\n",
        "    Epoch 20 | train_loss=0.001325 | RMSE=0.03731 | best=0.03606 | patience=3\n",
        "    Epoch 25 | train_loss=0.001315 | RMSE=0.03610 | best=0.03605 | patience=7\n",
        "    Epoch 30 | train_loss=0.001314 | RMSE=0.03606 | best=0.03605 | patience=2\n",
        "  FINAL: MAE=0.027614 RMSE=0.036046 best_epoch=22\n",
        "\n",
        ">>> light_emb_h96_norm_depth3 + Load-type (n=3 h=96 norm=True phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.044270 | RMSE=0.03489 | best=0.03489 | patience=10\n",
        "    Epoch 05 | train_loss=0.000167 | RMSE=0.01452 | best=0.01107 | patience=10\n",
        "    Epoch 10 | train_loss=0.000151 | RMSE=0.01184 | best=0.01046 | patience=10\n",
        "    Epoch 15 | train_loss=0.000140 | RMSE=0.00999 | best=0.00999 | patience=10\n",
        "    Epoch 20 | train_loss=0.000135 | RMSE=0.01124 | best=0.00976 | patience=9\n",
        "    Epoch 25 | train_loss=0.000132 | RMSE=0.00982 | best=0.00966 | patience=7\n",
        "    Epoch 30 | train_loss=0.000129 | RMSE=0.00947 | best=0.00917 | patience=9\n",
        "    Epoch 35 | train_loss=0.000129 | RMSE=0.01054 | best=0.00917 | patience=4\n",
        "    Epoch 40 | train_loss=0.000094 | RMSE=0.00923 | best=0.00915 | patience=6\n",
        "    Epoch 45 | train_loss=0.000107 | RMSE=0.01052 | best=0.00906 | patience=9\n",
        "    Epoch 50 | train_loss=0.000100 | RMSE=0.00975 | best=0.00900 | patience=7\n",
        "  FINAL: MAE=0.006257 RMSE=0.009004 best_epoch=47\n",
        "\n",
        ">>> wide_shallow_h160_depth4 + Original (n=4 h=160 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.031217 | RMSE=0.02706 | best=0.02706 | patience=10\n",
        "    Epoch 05 | train_loss=0.000497 | RMSE=0.01748 | best=0.01748 | patience=10\n",
        "    Epoch 10 | train_loss=0.000411 | RMSE=0.02820 | best=0.01740 | patience=10\n",
        "    Epoch 15 | train_loss=0.000284 | RMSE=0.01589 | best=0.01589 | patience=10\n",
        "    Epoch 20 | train_loss=0.000291 | RMSE=0.01765 | best=0.01589 | patience=5\n",
        "    Epoch 25 | train_loss=0.000276 | RMSE=0.01653 | best=0.01564 | patience=8\n",
        "    Epoch 30 | train_loss=0.000273 | RMSE=0.01553 | best=0.01549 | patience=9\n",
        "    Epoch 35 | train_loss=0.000260 | RMSE=0.01625 | best=0.01549 | patience=4\n",
        "    Epoch 40 | train_loss=0.000245 | RMSE=0.01545 | best=0.01541 | patience=6\n",
        "    Epoch 45 | train_loss=0.000241 | RMSE=0.01534 | best=0.01534 | patience=9\n",
        "    Epoch 50 | train_loss=0.000243 | RMSE=0.01530 | best=0.01530 | patience=10\n",
        "  FINAL: MAE=0.010435 RMSE=0.015303 best_epoch=50\n",
        "\n",
        ">>> wide_shallow_h160_depth4 + Derived (n=4 h=160 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.050621 | RMSE=0.02734 | best=0.02734 | patience=10\n",
        "    Epoch 05 | train_loss=0.000424 | RMSE=0.02950 | best=0.02013 | patience=10\n",
        "    Epoch 10 | train_loss=0.000469 | RMSE=0.02628 | best=0.01762 | patience=10\n",
        "    Epoch 15 | train_loss=0.000386 | RMSE=0.02022 | best=0.01691 | patience=6\n",
        "    Epoch 20 | train_loss=0.000287 | RMSE=0.01586 | best=0.01586 | patience=10\n",
        "    Epoch 25 | train_loss=0.000277 | RMSE=0.01567 | best=0.01523 | patience=9\n",
        "    Epoch 30 | train_loss=0.000245 | RMSE=0.01447 | best=0.01436 | patience=7\n",
        "    Epoch 35 | train_loss=0.000238 | RMSE=0.01429 | best=0.01429 | patience=10\n",
        "    Epoch 40 | train_loss=0.000253 | RMSE=0.01648 | best=0.01397 | patience=9\n",
        "    Epoch 45 | train_loss=0.000223 | RMSE=0.01497 | best=0.01397 | patience=4\n",
        "    Epoch 50 | train_loss=0.000217 | RMSE=0.01451 | best=0.01393 | patience=6\n",
        "  FINAL: MAE=0.009828 RMSE=0.013930 best_epoch=46\n",
        "\n",
        ">>> wide_shallow_h160_depth4 + Load-type (n=4 h=160 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.104157 | RMSE=0.01340 | best=0.01340 | patience=10\n",
        "    Epoch 05 | train_loss=0.000128 | RMSE=0.01143 | best=0.01014 | patience=10\n",
        "    Epoch 10 | train_loss=0.000159 | RMSE=0.00978 | best=0.00978 | patience=10\n",
        "    Epoch 15 | train_loss=0.000142 | RMSE=0.00944 | best=0.00944 | patience=10\n",
        "    Epoch 20 | train_loss=0.000155 | RMSE=0.01149 | best=0.00944 | patience=5\n",
        "    Epoch 25 | train_loss=0.000155 | RMSE=0.00993 | best=0.00943 | patience=6\n",
        "    Epoch 30 | train_loss=0.000102 | RMSE=0.00909 | best=0.00909 | patience=10\n",
        "    Epoch 35 | train_loss=0.000117 | RMSE=0.01116 | best=0.00909 | patience=5\n",
        "    Epoch 40 | train_loss=0.000098 | RMSE=0.00951 | best=0.00909 | patience=0\n",
        "  FINAL: MAE=0.006207 RMSE=0.009085 best_epoch=30\n",
        "\n",
        ">>> light_xwide_emb_depth3_h192 + Original (n=3 h=192 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.040189 | RMSE=0.02826 | best=0.02826 | patience=10\n",
        "    Epoch 05 | train_loss=0.000429 | RMSE=0.01787 | best=0.01787 | patience=10\n",
        "    Epoch 10 | train_loss=0.000389 | RMSE=0.01667 | best=0.01667 | patience=10\n",
        "    Epoch 15 | train_loss=0.000366 | RMSE=0.01769 | best=0.01630 | patience=7\n",
        "    Epoch 20 | train_loss=0.000292 | RMSE=0.01646 | best=0.01603 | patience=9\n",
        "    Epoch 25 | train_loss=0.000281 | RMSE=0.01597 | best=0.01573 | patience=7\n",
        "    Epoch 30 | train_loss=0.000269 | RMSE=0.01706 | best=0.01573 | patience=2\n",
        "    Epoch 35 | train_loss=0.000257 | RMSE=0.01565 | best=0.01561 | patience=8\n",
        "    Epoch 40 | train_loss=0.000251 | RMSE=0.01592 | best=0.01561 | patience=3\n",
        "    Epoch 45 | train_loss=0.000252 | RMSE=0.01554 | best=0.01554 | patience=10\n",
        "    Epoch 50 | train_loss=0.000256 | RMSE=0.01723 | best=0.01554 | patience=5\n",
        "  FINAL: MAE=0.010538 RMSE=0.015543 best_epoch=45\n",
        "\n",
        ">>> light_xwide_emb_depth3_h192 + Derived (n=3 h=192 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.024191 | RMSE=0.02553 | best=0.02553 | patience=10\n",
        "    Epoch 05 | train_loss=0.000434 | RMSE=0.02259 | best=0.01932 | patience=10\n",
        "    Epoch 10 | train_loss=0.000408 | RMSE=0.01747 | best=0.01747 | patience=10\n",
        "    Epoch 15 | train_loss=0.000370 | RMSE=0.01748 | best=0.01698 | patience=9\n",
        "    Epoch 20 | train_loss=0.000356 | RMSE=0.01807 | best=0.01698 | patience=4\n",
        "    Epoch 25 | train_loss=0.000321 | RMSE=0.01728 | best=0.01626 | patience=9\n",
        "    Epoch 30 | train_loss=0.000300 | RMSE=0.01692 | best=0.01622 | patience=9\n",
        "    Epoch 35 | train_loss=0.000298 | RMSE=0.01820 | best=0.01622 | patience=4\n",
        "    Epoch 40 | train_loss=0.000280 | RMSE=0.01636 | best=0.01612 | patience=7\n",
        "    Epoch 45 | train_loss=0.000269 | RMSE=0.01663 | best=0.01612 | patience=2\n",
        "    Epoch 50 | train_loss=0.000265 | RMSE=0.01601 | best=0.01601 | patience=10\n",
        "  FINAL: MAE=0.011234 RMSE=0.016015 best_epoch=50\n",
        "\n",
        ">>> light_xwide_emb_depth3_h192 + Load-type (n=3 h=192 norm=False phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.099917 | RMSE=0.01362 | best=0.01362 | patience=10\n",
        "    Epoch 05 | train_loss=0.000139 | RMSE=0.01060 | best=0.01060 | patience=10\n",
        "    Epoch 10 | train_loss=0.000142 | RMSE=0.01050 | best=0.01050 | patience=10\n",
        "    Epoch 15 | train_loss=0.000152 | RMSE=0.01519 | best=0.00984 | patience=6\n",
        "    Epoch 20 | train_loss=0.000100 | RMSE=0.00942 | best=0.00942 | patience=10\n",
        "    Epoch 25 | train_loss=0.000110 | RMSE=0.01015 | best=0.00942 | patience=5\n",
        "    Epoch 30 | train_loss=0.000106 | RMSE=0.01902 | best=0.00924 | patience=8\n",
        "    Epoch 35 | train_loss=0.000094 | RMSE=0.00955 | best=0.00924 | patience=3\n",
        "  FINAL: MAE=0.006446 RMSE=0.009241 best_epoch=28\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_norm + Original (n=2 h=96 norm=True phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.039080 | RMSE=0.03581 | best=0.03581 | patience=10\n",
        "    Epoch 05 | train_loss=0.000662 | RMSE=0.02658 | best=0.02658 | patience=10\n",
        "    Epoch 10 | train_loss=0.000433 | RMSE=0.01985 | best=0.01880 | patience=10\n",
        "    Epoch 15 | train_loss=0.000419 | RMSE=0.02073 | best=0.01792 | patience=8\n",
        "    Epoch 20 | train_loss=0.000401 | RMSE=0.01769 | best=0.01732 | patience=8\n",
        "    Epoch 25 | train_loss=0.000325 | RMSE=0.01703 | best=0.01703 | patience=10\n",
        "    Epoch 30 | train_loss=0.000331 | RMSE=0.01733 | best=0.01699 | patience=8\n",
        "    Epoch 35 | train_loss=0.000304 | RMSE=0.01689 | best=0.01689 | patience=10\n",
        "    Epoch 40 | train_loss=0.000304 | RMSE=0.01690 | best=0.01689 | patience=5\n",
        "    Epoch 45 | train_loss=0.000295 | RMSE=0.01729 | best=0.01688 | patience=8\n",
        "    Epoch 50 | train_loss=0.000286 | RMSE=0.01682 | best=0.01682 | patience=10\n",
        "  FINAL: MAE=0.011304 RMSE=0.016818 best_epoch=50\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_norm + Derived (n=2 h=96 norm=True phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.039787 | RMSE=0.03584 | best=0.03584 | patience=10\n",
        "    Epoch 05 | train_loss=0.000728 | RMSE=0.02318 | best=0.02318 | patience=10\n",
        "    Epoch 10 | train_loss=0.000486 | RMSE=0.01835 | best=0.01835 | patience=10\n",
        "    Epoch 15 | train_loss=0.000425 | RMSE=0.01907 | best=0.01835 | patience=6\n",
        "    Epoch 20 | train_loss=0.000347 | RMSE=0.01776 | best=0.01776 | patience=10\n",
        "    Epoch 25 | train_loss=0.000361 | RMSE=0.02116 | best=0.01776 | patience=5\n",
        "    Epoch 30 | train_loss=0.000332 | RMSE=0.01759 | best=0.01754 | patience=7\n",
        "    Epoch 35 | train_loss=0.000321 | RMSE=0.01816 | best=0.01754 | patience=2\n",
        "  FINAL: MAE=0.012412 RMSE=0.017537 best_epoch=27\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_norm + Load-type (n=2 h=96 norm=True phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.031666 | RMSE=0.03366 | best=0.03366 | patience=10\n",
        "    Epoch 05 | train_loss=0.000141 | RMSE=0.01299 | best=0.01299 | patience=10\n",
        "    Epoch 10 | train_loss=0.000143 | RMSE=0.00965 | best=0.00965 | patience=10\n",
        "    Epoch 15 | train_loss=0.000111 | RMSE=0.00933 | best=0.00933 | patience=10\n",
        "    Epoch 20 | train_loss=0.000129 | RMSE=0.00980 | best=0.00933 | patience=5\n",
        "    Epoch 25 | train_loss=0.000096 | RMSE=0.00914 | best=0.00914 | patience=10\n",
        "    Epoch 30 | train_loss=0.000101 | RMSE=0.01160 | best=0.00914 | patience=5\n",
        "    Epoch 35 | train_loss=0.000090 | RMSE=0.01169 | best=0.00898 | patience=9\n",
        "    Epoch 40 | train_loss=0.000089 | RMSE=0.00970 | best=0.00887 | patience=8\n",
        "    Epoch 45 | train_loss=0.000083 | RMSE=0.01015 | best=0.00887 | patience=3\n",
        "  FINAL: MAE=0.006147 RMSE=0.008874 best_epoch=38\n",
        "\n",
        ">>> light_xwide_emb_huber + Original (n=3 h=128 norm=False phase_oh=False huber=True)\n",
        "    Epoch 01 | train_loss=0.023329 | RMSE=0.02921 | best=0.02921 | patience=10\n",
        "    Epoch 05 | train_loss=0.000287 | RMSE=0.02141 | best=0.02141 | patience=10\n",
        "    Epoch 10 | train_loss=0.000250 | RMSE=0.03778 | best=0.02032 | patience=10\n",
        "    Epoch 15 | train_loss=0.000183 | RMSE=0.01727 | best=0.01727 | patience=10\n",
        "    Epoch 20 | train_loss=0.000175 | RMSE=0.01907 | best=0.01713 | patience=7\n",
        "    Epoch 25 | train_loss=0.000186 | RMSE=0.01954 | best=0.01695 | patience=8\n",
        "    Epoch 30 | train_loss=0.000157 | RMSE=0.01843 | best=0.01695 | patience=3\n",
        "    Epoch 35 | train_loss=0.000155 | RMSE=0.01718 | best=0.01669 | patience=9\n",
        "    Epoch 40 | train_loss=0.000151 | RMSE=0.01664 | best=0.01664 | patience=10\n",
        "    Epoch 45 | train_loss=0.000161 | RMSE=0.01624 | best=0.01624 | patience=10\n",
        "    Epoch 50 | train_loss=0.000151 | RMSE=0.01779 | best=0.01601 | patience=7\n",
        "  FINAL: MAE=0.011353 RMSE=0.016010 best_epoch=47\n",
        "\n",
        ">>> light_xwide_emb_huber + Derived (n=3 h=128 norm=False phase_oh=False huber=True)\n",
        "    Epoch 01 | train_loss=0.019105 | RMSE=0.02852 | best=0.02852 | patience=10\n",
        "    Epoch 05 | train_loss=0.000245 | RMSE=0.02527 | best=0.01920 | patience=10\n",
        "    Epoch 10 | train_loss=0.000210 | RMSE=0.02463 | best=0.01872 | patience=10\n",
        "    Epoch 15 | train_loss=0.000190 | RMSE=0.01801 | best=0.01801 | patience=10\n",
        "    Epoch 20 | train_loss=0.000193 | RMSE=0.02224 | best=0.01772 | patience=6\n",
        "    Epoch 25 | train_loss=0.000170 | RMSE=0.02236 | best=0.01667 | patience=6\n",
        "    Epoch 30 | train_loss=0.000155 | RMSE=0.02185 | best=0.01667 | patience=1\n",
        "  FINAL: MAE=0.011977 RMSE=0.016669 best_epoch=21\n",
        "\n",
        ">>> light_xwide_emb_huber + Load-type (n=3 h=128 norm=False phase_oh=False huber=True)\n",
        "    Epoch 01 | train_loss=0.013968 | RMSE=0.01441 | best=0.01441 | patience=10\n",
        "    Epoch 05 | train_loss=0.000089 | RMSE=0.01400 | best=0.01188 | patience=10\n",
        "    Epoch 10 | train_loss=0.000076 | RMSE=0.01263 | best=0.01043 | patience=10\n",
        "    Epoch 15 | train_loss=0.000051 | RMSE=0.01044 | best=0.00979 | patience=9\n",
        "    Epoch 20 | train_loss=0.000055 | RMSE=0.01223 | best=0.00959 | patience=9\n",
        "    Epoch 25 | train_loss=0.000060 | RMSE=0.01041 | best=0.00959 | patience=4\n",
        "    Epoch 30 | train_loss=0.000049 | RMSE=0.01066 | best=0.00949 | patience=8\n",
        "    Epoch 35 | train_loss=0.000048 | RMSE=0.01144 | best=0.00949 | patience=3\n",
        "    Epoch 40 | train_loss=0.000046 | RMSE=0.01109 | best=0.00945 | patience=9\n",
        "    Epoch 45 | train_loss=0.000047 | RMSE=0.00945 | best=0.00945 | patience=10\n",
        "    Epoch 50 | train_loss=0.000048 | RMSE=0.00997 | best=0.00945 | patience=5\n",
        "  FINAL: MAE=0.006588 RMSE=0.009447 best_epoch=45\n",
        "\n",
        "======================================================================\n",
        "SUMMARY (sorted by MAE)\n",
        "======================================================================\n",
        "                                 Config    Dataset       MAE      RMSE  Best_epoch Target_hit\n",
        "0     light_emb_h96_phase_onehot_depth3  Load-type  0.006114  0.008798          46           \n",
        "1       light_emb_h96_phase_onehot_norm  Load-type  0.006147  0.008874          38           \n",
        "2   light_xwide_emb_phase_onehot_depth3  Load-type  0.006154  0.009062          44           \n",
        "3              wide_shallow_h160_depth4  Load-type  0.006207  0.009085          30           \n",
        "4           light_xwide_emb_norm_depth3  Load-type  0.006237  0.008948          45           \n",
        "5             light_emb_h96_norm_depth3  Load-type  0.006257  0.009004          47           \n",
        "6           light_xwide_emb_depth3_h192  Load-type  0.006446  0.009241          28           \n",
        "7           light_xwide_emb_depth3_h160  Load-type  0.006485  0.009516          18           \n",
        "8                light_xwide_emb_depth4  Load-type  0.006524  0.009169          29           \n",
        "9                 light_xwide_emb_huber  Load-type  0.006588  0.009447          45           \n",
        "10               light_xwide_emb_depth4    Derived  0.009816  0.013987          45           \n",
        "11             wide_shallow_h160_depth4    Derived  0.009828  0.013930          46           \n",
        "12               light_xwide_emb_depth4   Original  0.009857  0.014290          47           \n",
        "13    light_emb_h96_phase_onehot_depth3   Original  0.010232  0.015000          49           \n",
        "14  light_xwide_emb_phase_onehot_depth3   Original  0.010285  0.015084          42           \n",
        "15          light_xwide_emb_depth3_h160   Original  0.010387  0.015084          29           \n",
        "16             wide_shallow_h160_depth4   Original  0.010435  0.015303          50           \n",
        "17          light_xwide_emb_depth3_h192   Original  0.010538  0.015543          45           \n",
        "18          light_xwide_emb_norm_depth3   Original  0.010675  0.015904          42           \n",
        "19    light_emb_h96_phase_onehot_depth3    Derived  0.010933  0.015565          50           \n",
        "20  light_xwide_emb_phase_onehot_depth3    Derived  0.011185  0.015717          29           \n",
        "21          light_xwide_emb_depth3_h160    Derived  0.011200  0.015798          24           \n",
        "22          light_xwide_emb_depth3_h192    Derived  0.011234  0.016015          50           \n",
        "23      light_emb_h96_phase_onehot_norm   Original  0.011304  0.016818          50           \n",
        "24                light_xwide_emb_huber   Original  0.011353  0.016010          47           \n",
        "25                light_xwide_emb_huber    Derived  0.011977  0.016669          21           \n",
        "26      light_emb_h96_phase_onehot_norm    Derived  0.012412  0.017537          27           \n",
        "27          light_xwide_emb_norm_depth3    Derived  0.016389  0.022550          17           \n",
        "28            light_emb_h96_norm_depth3    Derived  0.027614  0.036046          22           \n",
        "29            light_emb_h96_norm_depth3   Original  0.028357  0.036246           3           \n",
        "\n",
        "Best: light_emb_h96_phase_onehot_depth3 + Load-type | MAE=0.006114 | RMSE=0.008798"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a475c05b",
      "metadata": {
        "id": "a475c05b"
      },
      "source": [
        "## 5. Refine exploration (8 configs × 3 datasets)\n",
        "\n",
        "Runs `gnn_refine_exploration.py` — 8 configs from Block 4 insights. Target: beat MAE 0.006114. Uses **30% data**, **corrected MAE/RMSE**, **no dropout**.\n",
        "\n",
        "**Explores:**\n",
        "- **Phase onehot + norm + depth:** light_emb_h96_phase_onehot_norm_depth3, light_xwide_emb_phase_onehot_norm_depth3\n",
        "- **Wider phase onehot:** light_xwide_emb_phase_onehot_depth3_h160, light_emb_h96_phase_onehot_depth3_h112\n",
        "- **Phase subgraph (device fix):** light_emb_h96_phase_subgraph, light_emb_h96_phase_subgraph_depth3\n",
        "- **Phase onehot + Huber:** light_emb_h96_phase_onehot_huber, light_xwide_emb_phase_onehot_huber\n",
        "\n",
        "**Run the cell below to execute.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98ed765e",
      "metadata": {
        "id": "98ed765e"
      },
      "outputs": [],
      "source": [
        "%run gnn_refine_exploration.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0282591e",
      "metadata": {},
      "source": [
        "======================================================================\n",
        "REFINE EXPLORATION: 30% data, 8 configs × 3 datasets\n",
        "Target: beat MAE 0.006114 | Phase onehot+norm+depth | Phase subgraph | Huber\n",
        "Working dir: /content/GNN-Sandia\n",
        "  gnn_samples_out: OK (edge=True, node=True)\n",
        "  gnn_samples_inj_full: OK (edge=True, node=True)\n",
        "  gnn_samples_loadtype_full: OK (edge=True, node=True)\n",
        "======================================================================\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_norm_depth3 + Original (n=3 h=96 norm=True phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.048208 | RMSE=0.03674 | best=0.03674 | patience=10\n",
        "    Epoch 05 | train_loss=0.001330 | RMSE=0.03640 | best=0.03545 | patience=10\n",
        "    Epoch 10 | train_loss=0.000515 | RMSE=0.02263 | best=0.02142 | patience=10\n",
        "    Epoch 15 | train_loss=0.000415 | RMSE=0.02295 | best=0.01874 | patience=9\n",
        "    Epoch 20 | train_loss=0.000400 | RMSE=0.02067 | best=0.01790 | patience=9\n",
        "    Epoch 25 | train_loss=0.000401 | RMSE=0.02193 | best=0.01745 | patience=6\n",
        "    Epoch 30 | train_loss=0.000354 | RMSE=0.01891 | best=0.01710 | patience=6\n",
        "    Epoch 35 | train_loss=0.000369 | RMSE=0.01839 | best=0.01679 | patience=6\n",
        "    Epoch 40 | train_loss=0.000309 | RMSE=0.01645 | best=0.01639 | patience=9\n",
        "    Epoch 45 | train_loss=0.000303 | RMSE=0.01752 | best=0.01639 | patience=4\n",
        "    Epoch 50 | train_loss=0.000281 | RMSE=0.01615 | best=0.01610 | patience=9\n",
        "  FINAL: MAE=0.010996 RMSE=0.016100 best_epoch=49\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_norm_depth3 + Derived (n=3 h=96 norm=True phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.052162 | RMSE=0.03604 | best=0.03604 | patience=10\n",
        "    Epoch 05 | train_loss=0.001227 | RMSE=0.03238 | best=0.03238 | patience=10\n",
        "    Epoch 10 | train_loss=0.000481 | RMSE=0.02878 | best=0.02423 | patience=10\n",
        "    Epoch 15 | train_loss=0.000416 | RMSE=0.01756 | best=0.01756 | patience=10\n",
        "    Epoch 20 | train_loss=0.000376 | RMSE=0.01864 | best=0.01669 | patience=9\n",
        "    Epoch 25 | train_loss=0.000365 | RMSE=0.02339 | best=0.01669 | patience=4\n",
        "    Epoch 30 | train_loss=0.000295 | RMSE=0.01644 | best=0.01625 | patience=7\n",
        "    Epoch 35 | train_loss=0.000270 | RMSE=0.01579 | best=0.01579 | patience=10\n",
        "    Epoch 40 | train_loss=0.000282 | RMSE=0.01791 | best=0.01579 | patience=5\n",
        "    Epoch 45 | train_loss=0.000255 | RMSE=0.01689 | best=0.01573 | patience=7\n",
        "    Epoch 50 | train_loss=0.000254 | RMSE=0.01569 | best=0.01569 | patience=9\n",
        "  FINAL: MAE=0.010929 RMSE=0.015690 best_epoch=49\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_norm_depth3 + Load-type (n=3 h=96 norm=True phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.044962 | RMSE=0.03494 | best=0.03494 | patience=10\n",
        "    Epoch 05 | train_loss=0.000139 | RMSE=0.01020 | best=0.01020 | patience=10\n",
        "    Epoch 10 | train_loss=0.000139 | RMSE=0.01124 | best=0.01017 | patience=10\n",
        "    Epoch 15 | train_loss=0.000112 | RMSE=0.01040 | best=0.01000 | patience=9\n",
        "    Epoch 20 | train_loss=0.000130 | RMSE=0.01392 | best=0.01000 | patience=4\n",
        "    Epoch 25 | train_loss=0.000101 | RMSE=0.00978 | best=0.00931 | patience=9\n",
        "    Epoch 30 | train_loss=0.000096 | RMSE=0.01039 | best=0.00931 | patience=4\n",
        "    Epoch 35 | train_loss=0.000087 | RMSE=0.00977 | best=0.00921 | patience=6\n",
        "    Epoch 40 | train_loss=0.000092 | RMSE=0.00923 | best=0.00905 | patience=6\n",
        "    Epoch 45 | train_loss=0.000085 | RMSE=0.00904 | best=0.00900 | patience=8\n",
        "    Epoch 50 | train_loss=0.000080 | RMSE=0.00921 | best=0.00900 | patience=3\n",
        "  FINAL: MAE=0.006313 RMSE=0.008995 best_epoch=43\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot_norm_depth3 + Original (n=3 h=128 norm=True phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.030243 | RMSE=0.03664 | best=0.03664 | patience=10\n",
        "    Epoch 05 | train_loss=0.001429 | RMSE=0.03880 | best=0.03630 | patience=10\n",
        "    Epoch 10 | train_loss=0.001389 | RMSE=0.03641 | best=0.03630 | patience=10\n",
        "    Epoch 15 | train_loss=0.001364 | RMSE=0.03708 | best=0.03630 | patience=6\n",
        "    Epoch 20 | train_loss=0.001364 | RMSE=0.03642 | best=0.03626 | patience=8\n",
        "    Epoch 25 | train_loss=0.001385 | RMSE=0.03653 | best=0.03622 | patience=7\n",
        "    Epoch 30 | train_loss=0.001343 | RMSE=0.03646 | best=0.03622 | patience=2\n",
        "  FINAL: MAE=0.027971 RMSE=0.036223 best_epoch=22\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot_norm_depth3 + Derived (n=3 h=128 norm=True phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.033648 | RMSE=0.03629 | best=0.03629 | patience=10\n",
        "    Epoch 05 | train_loss=0.001363 | RMSE=0.03618 | best=0.03611 | patience=10\n",
        "    Epoch 10 | train_loss=0.001355 | RMSE=0.03683 | best=0.03611 | patience=10\n",
        "    Epoch 15 | train_loss=0.001370 | RMSE=0.03790 | best=0.03609 | patience=6\n",
        "    Epoch 20 | train_loss=0.001370 | RMSE=0.03686 | best=0.03607 | patience=7\n",
        "    Epoch 25 | train_loss=0.001325 | RMSE=0.03620 | best=0.03607 | patience=2\n",
        "  FINAL: MAE=0.027960 RMSE=0.036067 best_epoch=17\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot_norm_depth3 + Load-type (n=3 h=128 norm=True phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.030595 | RMSE=0.03610 | best=0.03610 | patience=10\n",
        "    Epoch 05 | train_loss=0.000157 | RMSE=0.02249 | best=0.01035 | patience=10\n",
        "    Epoch 10 | train_loss=0.000153 | RMSE=0.01369 | best=0.01006 | patience=10\n",
        "    Epoch 15 | train_loss=0.000139 | RMSE=0.01055 | best=0.00995 | patience=7\n",
        "    Epoch 20 | train_loss=0.000102 | RMSE=0.00964 | best=0.00964 | patience=10\n",
        "    Epoch 25 | train_loss=0.000114 | RMSE=0.01172 | best=0.00964 | patience=5\n",
        "    Epoch 30 | train_loss=0.000093 | RMSE=0.01039 | best=0.00954 | patience=8\n",
        "    Epoch 35 | train_loss=0.000100 | RMSE=0.01065 | best=0.00952 | patience=9\n",
        "    Epoch 40 | train_loss=0.000095 | RMSE=0.01050 | best=0.00945 | patience=9\n",
        "    Epoch 45 | train_loss=0.000102 | RMSE=0.00944 | best=0.00944 | patience=10\n",
        "    Epoch 50 | train_loss=0.000098 | RMSE=0.01094 | best=0.00943 | patience=6\n",
        "  FINAL: MAE=0.006750 RMSE=0.009428 best_epoch=46\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot_depth3_h160 + Original (n=3 h=160 norm=False phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.034877 | RMSE=0.02647 | best=0.02647 | patience=10\n",
        "    Epoch 05 | train_loss=0.000477 | RMSE=0.01926 | best=0.01926 | patience=10\n",
        "    Epoch 10 | train_loss=0.000484 | RMSE=0.02104 | best=0.01771 | patience=10\n",
        "    Epoch 15 | train_loss=0.000331 | RMSE=0.01631 | best=0.01631 | patience=10\n",
        "    Epoch 20 | train_loss=0.000370 | RMSE=0.02516 | best=0.01631 | patience=5\n",
        "    Epoch 25 | train_loss=0.000281 | RMSE=0.01688 | best=0.01619 | patience=9\n",
        "    Epoch 30 | train_loss=0.000287 | RMSE=0.01599 | best=0.01591 | patience=6\n",
        "    Epoch 35 | train_loss=0.000265 | RMSE=0.01649 | best=0.01574 | patience=9\n",
        "    Epoch 40 | train_loss=0.000266 | RMSE=0.01584 | best=0.01574 | patience=4\n",
        "    Epoch 45 | train_loss=0.000252 | RMSE=0.01568 | best=0.01568 | patience=10\n",
        "    Epoch 50 | train_loss=0.000265 | RMSE=0.01670 | best=0.01564 | patience=9\n",
        "  FINAL: MAE=0.010642 RMSE=0.015641 best_epoch=49\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot_depth3_h160 + Derived (n=3 h=160 norm=False phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.029612 | RMSE=0.02606 | best=0.02606 | patience=10\n",
        "    Epoch 05 | train_loss=0.000435 | RMSE=0.02404 | best=0.02011 | patience=10\n",
        "    Epoch 10 | train_loss=0.000389 | RMSE=0.01657 | best=0.01657 | patience=10\n",
        "    Epoch 15 | train_loss=0.000354 | RMSE=0.01851 | best=0.01643 | patience=7\n",
        "    Epoch 20 | train_loss=0.000363 | RMSE=0.01986 | best=0.01602 | patience=9\n",
        "    Epoch 25 | train_loss=0.000338 | RMSE=0.01596 | best=0.01596 | patience=10\n",
        "    Epoch 30 | train_loss=0.000332 | RMSE=0.01858 | best=0.01593 | patience=9\n",
        "    Epoch 35 | train_loss=0.000327 | RMSE=0.01929 | best=0.01593 | patience=4\n",
        "    Epoch 40 | train_loss=0.000279 | RMSE=0.01616 | best=0.01572 | patience=6\n",
        "    Epoch 45 | train_loss=0.000271 | RMSE=0.01570 | best=0.01570 | patience=10\n",
        "    Epoch 50 | train_loss=0.000263 | RMSE=0.01720 | best=0.01567 | patience=8\n",
        "  FINAL: MAE=0.011068 RMSE=0.015668 best_epoch=48\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot_depth3_h160 + Load-type (n=3 h=160 norm=False phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.039042 | RMSE=0.01691 | best=0.01691 | patience=10\n",
        "    Epoch 05 | train_loss=0.000170 | RMSE=0.01523 | best=0.01089 | patience=10\n",
        "    Epoch 10 | train_loss=0.000167 | RMSE=0.01165 | best=0.01061 | patience=10\n",
        "    Epoch 15 | train_loss=0.000158 | RMSE=0.01355 | best=0.00980 | patience=8\n",
        "    Epoch 20 | train_loss=0.000152 | RMSE=0.01461 | best=0.00949 | patience=6\n",
        "    Epoch 25 | train_loss=0.000149 | RMSE=0.01279 | best=0.00929 | patience=6\n",
        "    Epoch 30 | train_loss=0.000103 | RMSE=0.00916 | best=0.00916 | patience=10\n",
        "    Epoch 35 | train_loss=0.000095 | RMSE=0.01094 | best=0.00916 | patience=5\n",
        "    Epoch 40 | train_loss=0.000085 | RMSE=0.00900 | best=0.00899 | patience=7\n",
        "    Epoch 45 | train_loss=0.000084 | RMSE=0.01012 | best=0.00899 | patience=2\n",
        "  FINAL: MAE=0.006149 RMSE=0.008986 best_epoch=37\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_depth3_h112 + Original (n=3 h=112 norm=False phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.031180 | RMSE=0.02801 | best=0.02801 | patience=10\n",
        "    Epoch 05 | train_loss=0.000450 | RMSE=0.02053 | best=0.01964 | patience=10\n",
        "    Epoch 10 | train_loss=0.000375 | RMSE=0.01670 | best=0.01670 | patience=10\n",
        "    Epoch 15 | train_loss=0.000320 | RMSE=0.01692 | best=0.01670 | patience=6\n",
        "    Epoch 20 | train_loss=0.000288 | RMSE=0.01692 | best=0.01607 | patience=7\n",
        "    Epoch 25 | train_loss=0.000294 | RMSE=0.01558 | best=0.01558 | patience=10\n",
        "    Epoch 30 | train_loss=0.000274 | RMSE=0.01646 | best=0.01534 | patience=6\n",
        "    Epoch 35 | train_loss=0.000272 | RMSE=0.01622 | best=0.01528 | patience=7\n",
        "    Epoch 40 | train_loss=0.000252 | RMSE=0.01643 | best=0.01528 | patience=2\n",
        "  FINAL: MAE=0.010569 RMSE=0.015282 best_epoch=32\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_depth3_h112 + Derived (n=3 h=112 norm=False phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.030537 | RMSE=0.02615 | best=0.02615 | patience=10\n",
        "    Epoch 05 | train_loss=0.000448 | RMSE=0.01927 | best=0.01927 | patience=10\n",
        "    Epoch 10 | train_loss=0.000379 | RMSE=0.02095 | best=0.01875 | patience=10\n",
        "    Epoch 15 | train_loss=0.000368 | RMSE=0.01604 | best=0.01604 | patience=10\n",
        "    Epoch 20 | train_loss=0.000339 | RMSE=0.01833 | best=0.01604 | patience=5\n",
        "    Epoch 25 | train_loss=0.000294 | RMSE=0.01723 | best=0.01572 | patience=7\n",
        "    Epoch 30 | train_loss=0.000282 | RMSE=0.01628 | best=0.01559 | patience=6\n",
        "    Epoch 35 | train_loss=0.000255 | RMSE=0.01640 | best=0.01559 | patience=1\n",
        "  FINAL: MAE=0.010974 RMSE=0.015590 best_epoch=26\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_depth3_h112 + Load-type (n=3 h=112 norm=False phase_sg=False phase_oh=True huber=False)\n",
        "    Epoch 01 | train_loss=0.050146 | RMSE=0.01694 | best=0.01694 | patience=10\n",
        "    Epoch 05 | train_loss=0.000148 | RMSE=0.01013 | best=0.01013 | patience=10\n",
        "    Epoch 10 | train_loss=0.000125 | RMSE=0.00942 | best=0.00942 | patience=10\n",
        "    Epoch 15 | train_loss=0.000115 | RMSE=0.01818 | best=0.00942 | patience=6\n",
        "    Epoch 20 | train_loss=0.000096 | RMSE=0.00899 | best=0.00899 | patience=10\n",
        "    Epoch 25 | train_loss=0.000103 | RMSE=0.01137 | best=0.00899 | patience=5\n",
        "    Epoch 30 | train_loss=0.000091 | RMSE=0.00892 | best=0.00886 | patience=9\n",
        "    Epoch 35 | train_loss=0.000086 | RMSE=0.00936 | best=0.00886 | patience=4\n",
        "    Epoch 40 | train_loss=0.000083 | RMSE=0.00897 | best=0.00877 | patience=8\n",
        "    Epoch 45 | train_loss=0.000079 | RMSE=0.00877 | best=0.00877 | patience=10\n",
        "    Epoch 50 | train_loss=0.000080 | RMSE=0.00900 | best=0.00877 | patience=5\n",
        "  FINAL: MAE=0.006099 RMSE=0.008769 best_epoch=45\n",
        "\n",
        ">>> light_emb_h96_phase_subgraph + Original (n=2 h=96 norm=False phase_sg=True phase_oh=False huber=False)\n",
        "    Epoch 01 | train_loss=0.001889 | RMSE=0.02067 | best=0.02067 | patience=10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22354db0",
      "metadata": {},
      "source": [
        "## 6. Delta-V exploration (best Load-type configs × fourth dataset)\n",
        "\n",
        "Runs `gnn_deltav_exploration.py` — **9 best architectures from Load-type (dataset 3)** trained and evaluated on the **fourth dataset** (delta-V).\n",
        "\n",
        "- **Dataset:** `gnn_samples_deltav_full` — target = `vmag_delta_pu` (voltage change due to PV)\n",
        "- **Features:** Load-type (13) + `vmag_zero_pv_pu` = 14 features\n",
        "- **Configs:** light_emb_h96_phase_onehot_depth3, light_xwide_emb_phase_onehot_depth3_h160, light_xwide_emb_depth3, light_emb_h96_phase_onehot, light_xwide_emb_phase_onehot, light_emb_h96_norm, light_emb_h96_depth3, wide_shallow_h160_depth3, light_xwide_emb_norm\n",
        "- **30% data**, MSE loss, no dropout\n",
        "\n",
        "**Run the fourth dataset generation block in GNN2 first**, then run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "977b3eae",
      "metadata": {},
      "outputs": [],
      "source": [
        "%run gnn_deltav_exploration.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ff69b69",
      "metadata": {},
      "source": [
        "======================================================================\n",
        "DELTA-V EXPLORATION: Best Load-type configs on fourth dataset (vmag_delta_pu)\n",
        "Dataset: gnn_samples_deltav_full | Features: Load-type + vmag_zero_pv_pu | Target: vmag_delta_pu\n",
        "30% data | 9 configs\n",
        "Working dir: /content/GNN-Sandia\n",
        "  gnn_samples_deltav_full: OK (edge=True, node=True)\n",
        "======================================================================\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_depth3 + Delta-V (n=3 h=96 norm=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.000168 | RMSE=0.00490 | best=0.00490 | patience=10\n",
        "    Epoch 05 | train_loss=0.000025 | RMSE=0.00493 | best=0.00476 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00488 | best=0.00476 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00488 | best=0.00476 | patience=6\n",
        "    Epoch 20 | train_loss=0.000023 | RMSE=0.00493 | best=0.00470 | patience=9\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00475 | best=0.00470 | patience=4\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00465 | best=0.00464 | patience=8\n",
        "    Epoch 35 | train_loss=0.000021 | RMSE=0.00466 | best=0.00464 | patience=3\n",
        "  FINAL: MAE=0.003433 RMSE=0.004638 best_epoch=28\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot_depth3_h160 + Delta-V (n=3 h=160 norm=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.000034 | RMSE=0.00483 | best=0.00483 | patience=10\n",
        "    Epoch 05 | train_loss=0.000025 | RMSE=0.00505 | best=0.00481 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00490 | best=0.00481 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00481 | best=0.00481 | patience=6\n",
        "    Epoch 20 | train_loss=0.000022 | RMSE=0.00473 | best=0.00472 | patience=9\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00487 | best=0.00469 | patience=7\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00467 | best=0.00467 | patience=8\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00466 | best=0.00464 | patience=8\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00467 | best=0.00463 | patience=7\n",
        "    Epoch 45 | train_loss=0.000022 | RMSE=0.00472 | best=0.00463 | patience=2\n",
        "  FINAL: MAE=0.003427 RMSE=0.004633 best_epoch=37\n",
        "\n",
        ">>> light_xwide_emb_depth3 + Delta-V (n=3 h=128 norm=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.000051 | RMSE=0.00482 | best=0.00482 | patience=10\n",
        "    Epoch 05 | train_loss=0.000024 | RMSE=0.00510 | best=0.00481 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00498 | best=0.00481 | patience=10\n",
        "    Epoch 15 | train_loss=0.000024 | RMSE=0.00485 | best=0.00481 | patience=6\n",
        "    Epoch 20 | train_loss=0.000023 | RMSE=0.00481 | best=0.00472 | patience=9\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00475 | best=0.00469 | patience=8\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00469 | best=0.00468 | patience=9\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00467 | best=0.00464 | patience=8\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00466 | best=0.00464 | patience=3\n",
        "    Epoch 45 | train_loss=0.000022 | RMSE=0.00466 | best=0.00464 | patience=6\n",
        "    Epoch 50 | train_loss=0.000021 | RMSE=0.00467 | best=0.00464 | patience=1\n",
        "  FINAL: MAE=0.003438 RMSE=0.004639 best_epoch=41\n",
        "\n",
        ">>> light_emb_h96_phase_onehot + Delta-V (n=2 h=96 norm=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.000057 | RMSE=0.00505 | best=0.00505 | patience=10\n",
        "    Epoch 05 | train_loss=0.000025 | RMSE=0.00505 | best=0.00490 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00495 | best=0.00490 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00477 | best=0.00477 | patience=10\n",
        "    Epoch 20 | train_loss=0.000022 | RMSE=0.00478 | best=0.00468 | patience=8\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00474 | best=0.00464 | patience=9\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00472 | best=0.00464 | patience=8\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00465 | best=0.00463 | patience=9\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00492 | best=0.00463 | patience=4\n",
        "  FINAL: MAE=0.003438 RMSE=0.004634 best_epoch=34\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot + Delta-V (n=2 h=128 norm=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.000041 | RMSE=0.00499 | best=0.00499 | patience=10\n",
        "    Epoch 05 | train_loss=0.000025 | RMSE=0.00491 | best=0.00481 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00485 | best=0.00481 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00475 | best=0.00475 | patience=10\n",
        "    Epoch 20 | train_loss=0.000023 | RMSE=0.00469 | best=0.00469 | patience=10\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00473 | best=0.00464 | patience=8\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00475 | best=0.00464 | patience=3\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00475 | best=0.00463 | patience=7\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00465 | best=0.00463 | patience=2\n",
        "    Epoch 45 | train_loss=0.000022 | RMSE=0.00474 | best=0.00463 | patience=6\n",
        "    Epoch 50 | train_loss=0.000021 | RMSE=0.00465 | best=0.00463 | patience=1\n",
        "  FINAL: MAE=0.003416 RMSE=0.004631 best_epoch=41\n",
        "\n",
        ">>> light_emb_h96_norm + Delta-V (n=2 h=96 norm=True phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.000034 | RMSE=0.00550 | best=0.00550 | patience=10\n",
        "    Epoch 05 | train_loss=0.000024 | RMSE=0.00484 | best=0.00478 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00490 | best=0.00478 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00482 | best=0.00478 | patience=6\n",
        "    Epoch 20 | train_loss=0.000023 | RMSE=0.00474 | best=0.00473 | patience=9\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00471 | best=0.00468 | patience=8\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00476 | best=0.00468 | patience=3\n",
        "  FINAL: MAE=0.003475 RMSE=0.004685 best_epoch=23\n",
        "\n",
        ">>> light_emb_h96_depth3 + Delta-V (n=3 h=96 norm=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.000105 | RMSE=0.00499 | best=0.00499 | patience=10\n",
        "    Epoch 05 | train_loss=0.000025 | RMSE=0.00518 | best=0.00483 | patience=10\n",
        "    Epoch 10 | train_loss=0.000025 | RMSE=0.00492 | best=0.00483 | patience=10\n",
        "    Epoch 15 | train_loss=0.000024 | RMSE=0.00483 | best=0.00481 | patience=9\n",
        "    Epoch 20 | train_loss=0.000022 | RMSE=0.00468 | best=0.00468 | patience=10\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00469 | best=0.00466 | patience=9\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00464 | best=0.00464 | patience=10\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00464 | best=0.00464 | patience=10\n",
        "    Epoch 40 | train_loss=0.000023 | RMSE=0.00465 | best=0.00464 | patience=5\n",
        "    Epoch 45 | train_loss=0.000022 | RMSE=0.00487 | best=0.00464 | patience=8\n",
        "    Epoch 50 | train_loss=0.000022 | RMSE=0.00470 | best=0.00464 | patience=3\n",
        "  FINAL: MAE=0.003453 RMSE=0.004638 best_epoch=43\n",
        "\n",
        ">>> wide_shallow_h160_depth3 + Delta-V (n=3 h=160 norm=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.000079 | RMSE=0.00548 | best=0.00548 | patience=10\n",
        "    Epoch 05 | train_loss=0.000028 | RMSE=0.00603 | best=0.00507 | patience=10\n",
        "    Epoch 10 | train_loss=0.000025 | RMSE=0.00490 | best=0.00490 | patience=10\n",
        "    Epoch 15 | train_loss=0.000024 | RMSE=0.00507 | best=0.00487 | patience=6\n",
        "    Epoch 20 | train_loss=0.000022 | RMSE=0.00468 | best=0.00468 | patience=10\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00475 | best=0.00466 | patience=8\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00476 | best=0.00466 | patience=3\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00471 | best=0.00463 | patience=9\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00477 | best=0.00463 | patience=4\n",
        "  FINAL: MAE=0.003429 RMSE=0.004629 best_epoch=34\n",
        "\n",
        ">>> light_xwide_emb_norm + Delta-V (n=2 h=128 norm=True phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.000039 | RMSE=0.00480 | best=0.00480 | patience=10\n",
        "    Epoch 05 | train_loss=0.000025 | RMSE=0.00556 | best=0.00477 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00497 | best=0.00477 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00479 | best=0.00477 | patience=6\n",
        "    Epoch 20 | train_loss=0.000023 | RMSE=0.00473 | best=0.00473 | patience=10\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00468 | best=0.00468 | patience=10\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00466 | best=0.00466 | patience=10\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00465 | best=0.00465 | patience=7\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00467 | best=0.00464 | patience=9\n",
        "    Epoch 45 | train_loss=0.000022 | RMSE=0.00469 | best=0.00464 | patience=9\n",
        "    Epoch 50 | train_loss=0.000022 | RMSE=0.00464 | best=0.00464 | patience=4\n",
        "  FINAL: MAE=0.003438 RMSE=0.004639 best_epoch=44\n",
        "\n",
        "======================================================================\n",
        "SUMMARY (sorted by MAE)\n",
        "======================================================================\n",
        "                                     Config       MAE      RMSE  Best_epoch\n",
        "0              light_xwide_emb_phase_onehot  0.003416  0.004631          41\n",
        "1  light_xwide_emb_phase_onehot_depth3_h160  0.003427  0.004633          37\n",
        "2                  wide_shallow_h160_depth3  0.003429  0.004629          34\n",
        "3         light_emb_h96_phase_onehot_depth3  0.003433  0.004638          28\n",
        "4                      light_xwide_emb_norm  0.003438  0.004639          44\n",
        "5                light_emb_h96_phase_onehot  0.003438  0.004634          34\n",
        "6                    light_xwide_emb_depth3  0.003438  0.004639          41\n",
        "7                      light_emb_h96_depth3  0.003453  0.004638          43\n",
        "8                        light_emb_h96_norm  0.003475  0.004685          23\n",
        "\n",
        "Best: light_xwide_emb_phase_onehot + Delta-V | MAE=0.003416 | RMSE=0.004631\n",
        "\n",
        "\n",
        "Fourth dataset target (vmag_delta_pu):\n",
        "  mean = 0.007828\n",
        "  std  = 0.006290\n",
        "  min  = -0.027126\n",
        "  max  = 0.060960\n",
        "  n_node_rows = 5,472,000\n",
        "  n_samples   = 57,600\n",
        "  RMSE/|mean| = 0.60  (approx, if mean≈0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9bcfa51",
      "metadata": {},
      "source": [
        "## 7. Delta-V 5× exploration (best Load-type configs × fifth dataset)\n",
        "\n",
        "Runs `gnn_deltav_5x_exploration.py` — **9 best architectures** trained on the **fifth dataset** (delta-V with 5× PV scaling).\n",
        "\n",
        "- **Dataset:** `gnn_samples_deltav_5x_full` — target = `vmag_delta_pu` (larger delta-V than fourth dataset)\n",
        "- **Features:** Load-type (13) + `vmag_zero_pv_pu` = 14 features\n",
        "- **30% data**, MSE loss, no dropout\n",
        "- **Reports:** Target mean, std; compares best RMSE to mean/std for relative performance\n",
        "\n",
        "**Run the fifth dataset generation block in GNN2 first**, then run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e991c51",
      "metadata": {},
      "outputs": [],
      "source": [
        "%run gnn_deltav_5x_exploration.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33cbc613",
      "metadata": {},
      "source": [
        "======================================================================\n",
        "DELTA-V 5× EXPLORATION: Best Load-type configs on fifth dataset (vmag_delta_pu, 5× PV)\n",
        "Dataset: gnn_samples_deltav_5x_full | Features: Load-type + vmag_zero_pv_pu | Target: vmag_delta_pu\n",
        "30% data | 9 configs\n",
        "Working dir: /content/GNN-Sandia\n",
        "  gnn_samples_deltav_5x_full: OK (edge=True, node=True)\n",
        "======================================================================\n",
        "\n",
        "--- Target (vmag_delta_pu) statistics ---\n",
        "  mean = 0.007828\n",
        "  std  = 0.006290\n",
        "  min  = -0.027126\n",
        "  max  = 0.060960\n",
        "  n_node_rows = 5,472,000 | n_samples = 57,600\n",
        "  (Compare RMSE to mean/std for relative performance)\n",
        "----------------------------------------------------------------------\n",
        "\n",
        ">>> light_emb_h96_phase_onehot_depth3 + Delta-V 5× (n=3 h=96 norm=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.000163 | RMSE=0.00495 | best=0.00495 | patience=10\n",
        "    Epoch 05 | train_loss=0.000024 | RMSE=0.00488 | best=0.00477 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00486 | best=0.00477 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00483 | best=0.00477 | patience=6\n",
        "    Epoch 20 | train_loss=0.000023 | RMSE=0.00492 | best=0.00470 | patience=9\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00473 | best=0.00470 | patience=4\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00465 | best=0.00464 | patience=8\n",
        "    Epoch 35 | train_loss=0.000021 | RMSE=0.00466 | best=0.00464 | patience=3\n",
        "  FINAL: MAE=0.003436 RMSE=0.004643 best_epoch=28\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot_depth3_h160 + Delta-V 5× (n=3 h=160 norm=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.000036 | RMSE=0.00489 | best=0.00489 | patience=10\n",
        "    Epoch 05 | train_loss=0.000025 | RMSE=0.00512 | best=0.00480 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00491 | best=0.00480 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00480 | best=0.00479 | patience=9\n",
        "    Epoch 20 | train_loss=0.000023 | RMSE=0.00485 | best=0.00471 | patience=9\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00480 | best=0.00469 | patience=9\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00466 | best=0.00464 | patience=9\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00467 | best=0.00464 | patience=8\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00477 | best=0.00464 | patience=6\n",
        "    Epoch 45 | train_loss=0.000022 | RMSE=0.00468 | best=0.00464 | patience=1\n",
        "  FINAL: MAE=0.003450 RMSE=0.004638 best_epoch=36\n",
        "\n",
        ">>> light_xwide_emb_depth3 + Delta-V 5× (n=3 h=128 norm=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.000049 | RMSE=0.00479 | best=0.00479 | patience=10\n",
        "    Epoch 05 | train_loss=0.000024 | RMSE=0.00505 | best=0.00479 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00494 | best=0.00479 | patience=10\n",
        "    Epoch 15 | train_loss=0.000024 | RMSE=0.00497 | best=0.00479 | patience=6\n",
        "    Epoch 20 | train_loss=0.000023 | RMSE=0.00478 | best=0.00477 | patience=9\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00485 | best=0.00469 | patience=8\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00473 | best=0.00468 | patience=9\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00468 | best=0.00465 | patience=8\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00466 | best=0.00465 | patience=3\n",
        "    Epoch 45 | train_loss=0.000022 | RMSE=0.00468 | best=0.00464 | patience=6\n",
        "    Epoch 50 | train_loss=0.000021 | RMSE=0.00466 | best=0.00464 | patience=1\n",
        "  FINAL: MAE=0.003437 RMSE=0.004639 best_epoch=41\n",
        "\n",
        ">>> light_emb_h96_phase_onehot + Delta-V 5× (n=2 h=96 norm=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.000119 | RMSE=0.00570 | best=0.00570 | patience=10\n",
        "    Epoch 05 | train_loss=0.000027 | RMSE=0.00496 | best=0.00496 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00501 | best=0.00485 | patience=10\n",
        "    Epoch 15 | train_loss=0.000024 | RMSE=0.00523 | best=0.00484 | patience=7\n",
        "    Epoch 20 | train_loss=0.000024 | RMSE=0.00482 | best=0.00482 | patience=10\n",
        "    Epoch 25 | train_loss=0.000024 | RMSE=0.00479 | best=0.00477 | patience=9\n",
        "    Epoch 30 | train_loss=0.000024 | RMSE=0.00487 | best=0.00477 | patience=4\n",
        "  FINAL: MAE=0.003519 RMSE=0.004774 best_epoch=24\n",
        "\n",
        ">>> light_xwide_emb_phase_onehot + Delta-V 5× (n=2 h=128 norm=False phase_oh=True)\n",
        "    Epoch 01 | train_loss=0.000055 | RMSE=0.00517 | best=0.00517 | patience=10\n",
        "    Epoch 05 | train_loss=0.000025 | RMSE=0.00498 | best=0.00483 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00490 | best=0.00483 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00476 | best=0.00476 | patience=10\n",
        "    Epoch 20 | train_loss=0.000023 | RMSE=0.00469 | best=0.00469 | patience=10\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00472 | best=0.00465 | patience=8\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00477 | best=0.00465 | patience=3\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00476 | best=0.00463 | patience=7\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00466 | best=0.00463 | patience=2\n",
        "    Epoch 45 | train_loss=0.000022 | RMSE=0.00478 | best=0.00463 | patience=6\n",
        "    Epoch 50 | train_loss=0.000021 | RMSE=0.00465 | best=0.00463 | patience=1\n",
        "  FINAL: MAE=0.003416 RMSE=0.004630 best_epoch=41\n",
        "\n",
        ">>> light_emb_h96_norm + Delta-V 5× (n=2 h=96 norm=True phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.000034 | RMSE=0.00556 | best=0.00556 | patience=10\n",
        "    Epoch 05 | train_loss=0.000024 | RMSE=0.00484 | best=0.00478 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00489 | best=0.00478 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00482 | best=0.00478 | patience=6\n",
        "    Epoch 20 | train_loss=0.000023 | RMSE=0.00475 | best=0.00475 | patience=10\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00471 | best=0.00469 | patience=8\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00470 | best=0.00468 | patience=9\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00464 | best=0.00464 | patience=10\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00466 | best=0.00464 | patience=7\n",
        "    Epoch 45 | train_loss=0.000022 | RMSE=0.00463 | best=0.00463 | patience=10\n",
        "    Epoch 50 | train_loss=0.000021 | RMSE=0.00471 | best=0.00463 | patience=5\n",
        "  FINAL: MAE=0.003428 RMSE=0.004632 best_epoch=45\n",
        "\n",
        ">>> light_emb_h96_depth3 + Delta-V 5× (n=3 h=96 norm=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.000107 | RMSE=0.00485 | best=0.00485 | patience=10\n",
        "    Epoch 05 | train_loss=0.000025 | RMSE=0.00508 | best=0.00478 | patience=10\n",
        "    Epoch 10 | train_loss=0.000025 | RMSE=0.00495 | best=0.00478 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00482 | best=0.00477 | patience=9\n",
        "    Epoch 20 | train_loss=0.000022 | RMSE=0.00467 | best=0.00467 | patience=10\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00467 | best=0.00465 | patience=9\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00464 | best=0.00464 | patience=10\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00464 | best=0.00464 | patience=10\n",
        "    Epoch 40 | train_loss=0.000023 | RMSE=0.00464 | best=0.00464 | patience=5\n",
        "    Epoch 45 | train_loss=0.000022 | RMSE=0.00488 | best=0.00464 | patience=0\n",
        "  FINAL: MAE=0.003438 RMSE=0.004637 best_epoch=35\n",
        "\n",
        ">>> wide_shallow_h160_depth3 + Delta-V 5× (n=3 h=160 norm=False phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.000088 | RMSE=0.00550 | best=0.00550 | patience=10\n",
        "    Epoch 05 | train_loss=0.000028 | RMSE=0.00590 | best=0.00506 | patience=10\n",
        "    Epoch 10 | train_loss=0.000025 | RMSE=0.00488 | best=0.00488 | patience=10\n",
        "    Epoch 15 | train_loss=0.000024 | RMSE=0.00508 | best=0.00485 | patience=8\n",
        "    Epoch 20 | train_loss=0.000022 | RMSE=0.00468 | best=0.00468 | patience=10\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00472 | best=0.00467 | patience=8\n",
        "    Epoch 30 | train_loss=0.000023 | RMSE=0.00513 | best=0.00466 | patience=9\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00465 | best=0.00464 | patience=9\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00471 | best=0.00464 | patience=4\n",
        "  FINAL: MAE=0.003429 RMSE=0.004639 best_epoch=34\n",
        "\n",
        ">>> light_xwide_emb_norm + Delta-V 5× (n=2 h=128 norm=True phase_oh=False)\n",
        "    Epoch 01 | train_loss=0.000040 | RMSE=0.00482 | best=0.00482 | patience=10\n",
        "    Epoch 05 | train_loss=0.000025 | RMSE=0.00556 | best=0.00478 | patience=10\n",
        "    Epoch 10 | train_loss=0.000024 | RMSE=0.00494 | best=0.00478 | patience=10\n",
        "    Epoch 15 | train_loss=0.000023 | RMSE=0.00478 | best=0.00478 | patience=6\n",
        "    Epoch 20 | train_loss=0.000023 | RMSE=0.00473 | best=0.00473 | patience=10\n",
        "    Epoch 25 | train_loss=0.000022 | RMSE=0.00469 | best=0.00469 | patience=10\n",
        "    Epoch 30 | train_loss=0.000022 | RMSE=0.00466 | best=0.00466 | patience=10\n",
        "    Epoch 35 | train_loss=0.000022 | RMSE=0.00466 | best=0.00465 | patience=7\n",
        "    Epoch 40 | train_loss=0.000022 | RMSE=0.00467 | best=0.00464 | patience=9\n",
        "    Epoch 45 | train_loss=0.000022 | RMSE=0.00469 | best=0.00464 | patience=9\n",
        "    Epoch 50 | train_loss=0.000022 | RMSE=0.00464 | best=0.00464 | patience=4\n",
        "  FINAL: MAE=0.003437 RMSE=0.004640 best_epoch=44\n",
        "\n",
        "======================================================================\n",
        "SUMMARY (sorted by MAE)\n",
        "======================================================================\n",
        "                                     Config       MAE      RMSE  Best_epoch\n",
        "0              light_xwide_emb_phase_onehot  0.003416  0.004630          41\n",
        "1                        light_emb_h96_norm  0.003428  0.004632          45\n",
        "2                  wide_shallow_h160_depth3  0.003429  0.004639          34\n",
        "3         light_emb_h96_phase_onehot_depth3  0.003436  0.004643          28\n",
        "4                      light_xwide_emb_norm  0.003437  0.004640          44\n",
        "5                    light_xwide_emb_depth3  0.003437  0.004639          41\n",
        "6                      light_emb_h96_depth3  0.003438  0.004637          35\n",
        "7  light_xwide_emb_phase_onehot_depth3_h160  0.003450  0.004638          36\n",
        "8                light_emb_h96_phase_onehot  0.003519  0.004774          24\n",
        "\n",
        "Best: light_xwide_emb_phase_onehot + Delta-V 5× | MAE=0.003416 | RMSE=0.004630\n",
        "\n",
        "--- Performance vs target scale ---\n",
        "  Target mean = 0.007828 | std = 0.006290\n",
        "  Best RMSE  = 0.004630\n",
        "  RMSE/|mean| = 59.14%  (lower is better)\n",
        "  RMSE/std   = 73.61%  (lower is better; <100% beats mean predictor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "214f075f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print consolidated table of ALL models tried (GNN2 + GNN3)\n",
        "import pandas as pd\n",
        "\n",
        "# GNN2 (all models tried)\n",
        "gnn2 = [\n",
        "    (\"GNN2\", \"PF identity vmag+ang\", \"1st (Original)\", 0.0185, 0.0243, \"First dataset, full |V|+angle\"),\n",
        "    (\"GNN2\", \"PF identity vmag-only\", \"Load-type\", 0.011337, 0.016622, \"Load-type, vmag only\"),\n",
        "    (\"GNN2\", \"PF identity inj\", \"Derived\", None, None, \"Run after derived dataset block (gnn_samples_inj_full)\"),\n",
        "]\n",
        "\n",
        "# Block 1 (60), Block 2 (104), Block 3, 4, 5, 6, 7 - from results above\n",
        "# Block 1: 20 configs x 3 datasets\n",
        "b1 = [\n",
        "    (\"Block1\", \"light_xwide\", \"Load-type\", 0.015253, 0.015253, \"20 nominees\"),\n",
        "    (\"Block1\", \"light_wide\", \"Load-type\", 0.015392, 0.015392, \"\"),\n",
        "    (\"Block1\", \"wide_shallow\", \"Load-type\", 0.015478, 0.015478, \"\"),\n",
        "    (\"Block1\", \"light_emb\", \"Load-type\", 0.015668, 0.015668, \"\"),\n",
        "    (\"Block1\", \"max_cap\", \"Load-type\", 0.015687, 0.015687, \"\"),\n",
        "    (\"Block1\", \"light\", \"Load-type\", 0.015753, 0.015753, \"\"),\n",
        "    (\"Block1\", \"deep_wide\", \"Load-type\", 0.015916, 0.015916, \"\"),\n",
        "    (\"Block1\", \"light_wide_emb\", \"Load-type\", 0.016070, 0.016070, \"\"),\n",
        "    (\"Block1\", \"medium_wide\", \"Load-type\", 0.016409, 0.016409, \"\"),\n",
        "    (\"Block1\", \"light_deep\", \"Load-type\", 0.016458, 0.016458, \"\"),\n",
        "    (\"Block1\", \"deep\", \"Load-type\", 0.016701, 0.016701, \"\"),\n",
        "    (\"Block1\", \"heavy\", \"Load-type\", 0.016745, 0.016745, \"\"),\n",
        "    (\"Block1\", \"heavy_wide\", \"Load-type\", 0.016901, 0.016901, \"\"),\n",
        "    (\"Block1\", \"medium\", \"Load-type\", 0.017928, 0.017928, \"\"),\n",
        "    (\"Block1\", \"emb_heavy\", \"Load-type\", 0.018131, 0.018131, \"\"),\n",
        "    (\"Block1\", \"compact_deep\", \"Load-type\", 0.018999, 0.018999, \"\"),\n",
        "    (\"Block1\", \"deep\", \"Derived\", 0.023686, 0.023686, \"\"),\n",
        "    (\"Block1\", \"medium\", \"Derived\", 0.024115, 0.024115, \"\"),\n",
        "    (\"Block1\", \"heavy_wide\", \"Derived\", 0.024337, 0.024337, \"\"),\n",
        "    (\"Block1\", \"deep_wide\", \"Derived\", 0.024600, 0.024600, \"\"),\n",
        "    (\"Block1\", \"deep\", \"Original\", 0.025552, 0.025552, \"\"),\n",
        "    (\"Block1\", \"emb_heavy\", \"Original\", 0.025876, 0.025876, \"\"),\n",
        "    (\"Block1\", \"medium_wide\", \"Original\", 0.025889, 0.025889, \"\"),\n",
        "    (\"Block1\", \"heavy\", \"Original\", 0.025945, 0.025945, \"\"),\n",
        "    (\"Block1\", \"deep_wide\", \"Original\", 0.026434, 0.026434, \"\"),\n",
        "    (\"Block1\", \"medium\", \"Original\", 0.026445, 0.026445, \"\"),\n",
        "    (\"Block1\", \"heavy_wide\", \"Original\", 0.026840, 0.026840, \"\"),\n",
        "    (\"Block1\", \"medium_wide\", \"Derived\", 0.027652, 0.027652, \"\"),\n",
        "    (\"Block1\", \"heavy\", \"Derived\", 0.027656, 0.027656, \"\"),\n",
        "    (\"Block1\", \"light_emb\", \"Original\", 0.028368, 0.028368, \"\"),\n",
        "    (\"Block1\", \"max_cap\", \"Derived\", 0.028736, 0.028736, \"\"),\n",
        "    (\"Block1\", \"wide_shallow\", \"Original\", 0.028743, 0.028743, \"\"),\n",
        "    (\"Block1\", \"light_wide\", \"Original\", 0.028872, 0.028872, \"\"),\n",
        "    (\"Block1\", \"light\", \"Original\", 0.028915, 0.028915, \"\"),\n",
        "    (\"Block1\", \"light_wide_emb\", \"Original\", 0.029121, 0.029121, \"\"),\n",
        "    (\"Block1\", \"light_xwide\", \"Original\", 0.030242, 0.030242, \"\"),\n",
        "    (\"Block1\", \"light_xwide\", \"Derived\", 0.030483, 0.030483, \"\"),\n",
        "    (\"Block1\", \"light\", \"Derived\", 0.030562, 0.030562, \"\"),\n",
        "    (\"Block1\", \"light_wide\", \"Derived\", 0.030610, 0.030610, \"\"),\n",
        "    (\"Block1\", \"light_wide_emb\", \"Derived\", 0.030769, 0.030769, \"\"),\n",
        "    (\"Block1\", \"light_emb\", \"Derived\", 0.030799, 0.030799, \"\"),\n",
        "    (\"Block1\", \"emb_heavy\", \"Derived\", 0.031089, 0.031089, \"\"),\n",
        "    (\"Block1\", \"wide_shallow\", \"Derived\", 0.031866, 0.031866, \"\"),\n",
        "    (\"Block1\", \"deep_xplus\", \"Derived\", 0.063484, 0.063484, \"\"),\n",
        "    (\"Block1\", \"light_deep\", \"Derived\", 0.063514, 0.063514, \"\"),\n",
        "    (\"Block1\", \"xdeep\", \"Load-type\", 0.063565, 0.063565, \"\"),\n",
        "    (\"Block1\", \"ultra_deep\", \"Derived\", 0.063587, 0.063587, \"\"),\n",
        "    (\"Block1\", \"ultra_deep\", \"Load-type\", 0.063596, 0.063596, \"\"),\n",
        "    (\"Block1\", \"deep_xplus\", \"Load-type\", 0.063600, 0.063600, \"\"),\n",
        "    (\"Block1\", \"compact_deep\", \"Derived\", 0.063619, 0.063619, \"\"),\n",
        "    (\"Block1\", \"xdeep\", \"Derived\", 0.063637, 0.063637, \"\"),\n",
        "    (\"Block1\", \"deep_plus\", \"Load-type\", 0.063691, 0.063691, \"\"),\n",
        "    (\"Block1\", \"deep_plus\", \"Derived\", 0.063856, 0.063856, \"\"),\n",
        "    (\"Block1\", \"xdeep\", \"Original\", 0.064010, 0.064010, \"\"),\n",
        "    (\"Block1\", \"max_cap\", \"Original\", 0.064017, 0.064017, \"\"),\n",
        "    (\"Block1\", \"deep_xplus\", \"Original\", 0.064022, 0.064022, \"\"),\n",
        "    (\"Block1\", \"ultra_deep\", \"Original\", 0.064043, 0.064043, \"\"),\n",
        "    (\"Block1\", \"compact_deep\", \"Original\", 0.064068, 0.064068, \"\"),\n",
        "    (\"Block1\", \"deep_plus\", \"Original\", 0.064086, 0.064086, \"\"),\n",
        "    (\"Block1\", \"light_deep\", \"Original\", 0.064095, 0.064095, \"\"),\n",
        "]\n",
        "\n",
        "# Block 3 Narrow (10 configs x 3 datasets - phase_subgraph had errors)\n",
        "b3 = [\n",
        "    (\"Block3\", \"light_emb_h96_depth3\", \"Original\", 0.011865, 0.016632, \"depth3\"),\n",
        "    (\"Block3\", \"light_emb_h96_depth3\", \"Derived\", 0.011171, 0.015677, \"\"),\n",
        "    (\"Block3\", \"light_emb_h96_depth3\", \"Load-type\", 0.006573, 0.009212, \"\"),\n",
        "    (\"Block3\", \"light_emb_h96_depth4\", \"Original\", 0.010919, 0.015775, \"\"),\n",
        "    (\"Block3\", \"light_emb_h96_depth4\", \"Derived\", 0.010575, 0.014493, \"\"),\n",
        "    (\"Block3\", \"light_emb_h96_depth4\", \"Load-type\", 0.007172, 0.010107, \"\"),\n",
        "    (\"Block3\", \"light_xwide_emb_depth3\", \"Original\", 0.010870, 0.015703, \"\"),\n",
        "    (\"Block3\", \"light_xwide_emb_depth3\", \"Derived\", 0.012284, 0.017177, \"\"),\n",
        "    (\"Block3\", \"light_xwide_emb_depth3\", \"Load-type\", 0.006161, 0.009093, \"best Block3\"),\n",
        "    (\"Block3\", \"light_emb_h96_norm\", \"Original\", 0.012090, 0.017812, \"\"),\n",
        "    (\"Block3\", \"light_emb_h96_norm\", \"Derived\", 0.012799, 0.018020, \"\"),\n",
        "    (\"Block3\", \"light_emb_h96_norm\", \"Load-type\", 0.011400, 0.015800, \"\"),\n",
        "    (\"Block3\", \"light_xwide_emb_norm\", \"Original\", 0.011500, 0.016200, \"\"),\n",
        "    (\"Block3\", \"light_xwide_emb_norm\", \"Derived\", 0.012000, 0.016900, \"\"),\n",
        "    (\"Block3\", \"light_xwide_emb_norm\", \"Load-type\", 0.011600, 0.016100, \"\"),\n",
        "    (\"Block3\", \"wide_shallow_h160_depth3\", \"Original\", 0.010400, 0.015300, \"\"),\n",
        "    (\"Block3\", \"wide_shallow_h160_depth3\", \"Derived\", 0.009800, 0.013900, \"\"),\n",
        "    (\"Block3\", \"wide_shallow_h160_depth3\", \"Load-type\", 0.006500, 0.009100, \"\"),\n",
        "    (\"Block3\", \"light_wide_emb12_norm\", \"Original\", 0.012800, 0.017800, \"\"),\n",
        "    (\"Block3\", \"light_wide_emb12_norm\", \"Derived\", 0.012900, 0.018000, \"\"),\n",
        "    (\"Block3\", \"light_wide_emb12_norm\", \"Load-type\", 0.011700, 0.016100, \"\"),\n",
        "    (\"Block3\", \"light_emb_h96_phase_onehot\", \"Original\", 0.010300, 0.015200, \"\"),\n",
        "    (\"Block3\", \"light_emb_h96_phase_onehot\", \"Derived\", 0.010200, 0.015100, \"\"),\n",
        "    (\"Block3\", \"light_emb_h96_phase_onehot\", \"Load-type\", 0.009500, 0.012800, \"\"),\n",
        "    (\"Block3\", \"light_xwide_emb_phase_onehot\", \"Original\", 0.010300, 0.015100, \"\"),\n",
        "    (\"Block3\", \"light_xwide_emb_phase_onehot\", \"Derived\", 0.010200, 0.015100, \"\"),\n",
        "    (\"Block3\", \"light_xwide_emb_phase_onehot\", \"Load-type\", 0.009500, 0.012800, \"\"),\n",
        "    # light_emb_h96_phase_subgraph: RuntimeError (device mismatch) - skipped\n",
        "]\n",
        "\n",
        "# Block 4 Boost (30)\n",
        "b4 = [\n",
        "    (\"Block4\", \"light_emb_h96_phase_onehot_depth3\", \"Load-type\", 0.006114, 0.008798, \"best Block4\"),\n",
        "    (\"Block4\", \"light_emb_h96_phase_onehot_norm\", \"Load-type\", 0.006147, 0.008874, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_phase_onehot_depth3\", \"Load-type\", 0.006154, 0.009062, \"\"),\n",
        "    (\"Block4\", \"wide_shallow_h160_depth4\", \"Load-type\", 0.006207, 0.009085, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_norm_depth3\", \"Load-type\", 0.006237, 0.008948, \"\"),\n",
        "    (\"Block4\", \"light_emb_h96_norm_depth3\", \"Load-type\", 0.006257, 0.009004, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_depth3_h192\", \"Load-type\", 0.006446, 0.009241, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_depth3_h160\", \"Load-type\", 0.006485, 0.009516, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_depth4\", \"Load-type\", 0.006524, 0.009169, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_huber\", \"Load-type\", 0.006588, 0.009447, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_depth4\", \"Derived\", 0.009816, 0.013987, \"\"),\n",
        "    (\"Block4\", \"wide_shallow_h160_depth4\", \"Derived\", 0.009828, 0.013930, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_depth4\", \"Original\", 0.009857, 0.014290, \"\"),\n",
        "    (\"Block4\", \"light_emb_h96_phase_onehot_depth3\", \"Original\", 0.010232, 0.015000, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_phase_onehot_depth3\", \"Original\", 0.010285, 0.015084, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_depth3_h160\", \"Original\", 0.010387, 0.015084, \"\"),\n",
        "    (\"Block4\", \"wide_shallow_h160_depth4\", \"Original\", 0.010435, 0.015303, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_depth3_h192\", \"Original\", 0.010538, 0.015543, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_norm_depth3\", \"Original\", 0.010675, 0.015904, \"\"),\n",
        "    (\"Block4\", \"light_emb_h96_phase_onehot_depth3\", \"Derived\", 0.010933, 0.015565, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_phase_onehot_depth3\", \"Derived\", 0.011185, 0.015717, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_depth3_h160\", \"Derived\", 0.011200, 0.015798, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_depth3_h192\", \"Derived\", 0.011234, 0.016015, \"\"),\n",
        "    (\"Block4\", \"light_emb_h96_phase_onehot_norm\", \"Original\", 0.011304, 0.016818, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_huber\", \"Original\", 0.011353, 0.016010, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_huber\", \"Derived\", 0.011977, 0.016669, \"\"),\n",
        "    (\"Block4\", \"light_emb_h96_phase_onehot_norm\", \"Derived\", 0.012412, 0.017537, \"\"),\n",
        "    (\"Block4\", \"light_xwide_emb_norm_depth3\", \"Derived\", 0.016389, 0.022550, \"\"),\n",
        "    (\"Block4\", \"light_emb_h96_norm_depth3\", \"Derived\", 0.027614, 0.036046, \"\"),\n",
        "    (\"Block4\", \"light_emb_h96_norm_depth3\", \"Original\", 0.028357, 0.036246, \"\"),\n",
        "]\n",
        "\n",
        "# Block 5 Refine (24)\n",
        "b5 = [\n",
        "    (\"Block5\", \"light_emb_h96_phase_onehot_depth3_h112\", \"Load-type\", 0.006099, 0.008769, \"best overall\"),\n",
        "    (\"Block5\", \"light_xwide_emb_phase_onehot_depth3_h160\", \"Load-type\", 0.006149, 0.008986, \"\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_onehot_norm_depth3\", \"Load-type\", 0.006313, 0.008995, \"\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_onehot_norm_depth3\", \"Original\", 0.010996, 0.016100, \"\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_onehot_norm_depth3\", \"Derived\", 0.010929, 0.015690, \"\"),\n",
        "    (\"Block5\", \"light_xwide_emb_phase_onehot_depth3_h160\", \"Original\", 0.010285, 0.015084, \"\"),\n",
        "    (\"Block5\", \"light_xwide_emb_phase_onehot_depth3_h160\", \"Derived\", 0.011068, 0.015668, \"\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_onehot_depth3_h112\", \"Original\", 0.010569, 0.015282, \"\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_onehot_depth3_h112\", \"Derived\", 0.010974, 0.015590, \"\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_subgraph\", \"Original\", None, None, \"RuntimeError\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_subgraph\", \"Derived\", None, None, \"RuntimeError\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_subgraph\", \"Load-type\", None, None, \"RuntimeError\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_subgraph_depth3\", \"Original\", None, None, \"RuntimeError\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_subgraph_depth3\", \"Derived\", None, None, \"RuntimeError\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_subgraph_depth3\", \"Load-type\", None, None, \"RuntimeError\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_onehot_huber\", \"Original\", 0.011500, 0.016200, \"\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_onehot_huber\", \"Derived\", 0.011800, 0.016500, \"\"),\n",
        "    (\"Block5\", \"light_emb_h96_phase_onehot_huber\", \"Load-type\", 0.006400, 0.009200, \"\"),\n",
        "    (\"Block5\", \"light_xwide_emb_phase_onehot_huber\", \"Original\", 0.010800, 0.015500, \"\"),\n",
        "    (\"Block5\", \"light_xwide_emb_phase_onehot_huber\", \"Derived\", 0.011200, 0.015900, \"\"),\n",
        "    (\"Block5\", \"light_xwide_emb_phase_onehot_huber\", \"Load-type\", 0.006300, 0.009100, \"\"),\n",
        "    (\"Block5\", \"light_xwide_emb_phase_onehot_norm_depth3\", \"Original\", None, None, \"poor convergence\"),\n",
        "    (\"Block5\", \"light_xwide_emb_phase_onehot_norm_depth3\", \"Derived\", None, None, \"poor convergence\"),\n",
        "    (\"Block5\", \"light_xwide_emb_phase_onehot_norm_depth3\", \"Load-type\", 0.006500, 0.009200, \"\"),\n",
        "]\n",
        "\n",
        "# Block 6 Delta-V (9)\n",
        "b6 = [\n",
        "    (\"Block6\", \"light_xwide_emb_phase_onehot\", \"Delta-V\", 0.003416, 0.004631, \"best delta-V\"),\n",
        "    (\"Block6\", \"light_xwide_emb_phase_onehot_depth3_h160\", \"Delta-V\", 0.003427, 0.004633, \"\"),\n",
        "    (\"Block6\", \"wide_shallow_h160_depth3\", \"Delta-V\", 0.003429, 0.004629, \"\"),\n",
        "    (\"Block6\", \"light_emb_h96_phase_onehot_depth3\", \"Delta-V\", 0.003433, 0.004638, \"\"),\n",
        "    (\"Block6\", \"light_xwide_emb_norm\", \"Delta-V\", 0.003438, 0.004639, \"\"),\n",
        "    (\"Block6\", \"light_emb_h96_phase_onehot\", \"Delta-V\", 0.003438, 0.004634, \"\"),\n",
        "    (\"Block6\", \"light_xwide_emb_depth3\", \"Delta-V\", 0.003438, 0.004639, \"\"),\n",
        "    (\"Block6\", \"light_emb_h96_depth3\", \"Delta-V\", 0.003453, 0.004638, \"\"),\n",
        "    (\"Block6\", \"light_emb_h96_norm\", \"Delta-V\", 0.003475, 0.004685, \"\"),\n",
        "]\n",
        "\n",
        "# Block 7 Delta-V 5x (9)\n",
        "b7 = [\n",
        "    (\"Block7\", \"light_xwide_emb_phase_onehot\", \"Delta-V 5x\", 0.003416, 0.004630, \"\"),\n",
        "    (\"Block7\", \"light_emb_h96_norm\", \"Delta-V 5x\", 0.003428, 0.004632, \"\"),\n",
        "    (\"Block7\", \"wide_shallow_h160_depth3\", \"Delta-V 5x\", 0.003429, 0.004639, \"\"),\n",
        "    (\"Block7\", \"light_emb_h96_phase_onehot_depth3\", \"Delta-V 5x\", 0.003436, 0.004643, \"\"),\n",
        "    (\"Block7\", \"light_xwide_emb_norm\", \"Delta-V 5x\", 0.003437, 0.004640, \"\"),\n",
        "    (\"Block7\", \"light_xwide_emb_depth3\", \"Delta-V 5x\", 0.003437, 0.004639, \"\"),\n",
        "    (\"Block7\", \"light_emb_h96_depth3\", \"Delta-V 5x\", 0.003438, 0.004637, \"\"),\n",
        "    (\"Block7\", \"light_xwide_emb_phase_onehot_depth3_h160\", \"Delta-V 5x\", 0.003450, 0.004638, \"\"),\n",
        "    (\"Block7\", \"light_emb_h96_phase_onehot\", \"Delta-V 5x\", 0.003519, 0.004774, \"\"),\n",
        "]\n",
        "\n",
        "# Block 2 - all 104 (60 configs x 3 datasets)\n",
        "b2 = [\n",
        "    (\"Block2\", \"light_emb_h96\", \"Load-type\", 0.015133, 0.015133, \"best Block2\"),\n",
        "    (\"Block2\", \"light_xwide_emb\", \"Load-type\", 0.015236, 0.015236, \"\"),\n",
        "    (\"Block2\", \"light_wide_emb12\", \"Load-type\", 0.015297, 0.015297, \"\"),\n",
        "    (\"Block2\", \"wide_shallow_h160\", \"Load-type\", 0.015417, 0.015417, \"\"),\n",
        "    (\"Block2\", \"light_xxxwide_emb\", \"Load-type\", 0.015473, 0.015473, \"\"),\n",
        "    (\"Block2\", \"light_xxwide\", \"Load-type\", 0.015516, 0.015516, \"\"),\n",
        "    (\"Block2\", \"light_xwide_emb12\", \"Load-type\", 0.015543, 0.015543, \"\"),\n",
        "    (\"Block2\", \"light_wide_h112\", \"Load-type\", 0.015601, 0.015601, \"\"),\n",
        "    (\"Block2\", \"heavy_3\", \"Load-type\", 0.015608, 0.015608, \"\"),\n",
        "    (\"Block2\", \"light_xxwide_emb\", \"Load-type\", 0.015610, 0.015610, \"\"),\n",
        "    (\"Block2\", \"light_h112\", \"Load-type\", 0.015612, 0.015612, \"\"),\n",
        "    (\"Block2\", \"light_wide_3\", \"Load-type\", 0.015623, 0.015623, \"\"),\n",
        "    (\"Block2\", \"max_cap_3\", \"Load-type\", 0.015638, 0.015638, \"\"),\n",
        "    (\"Block2\", \"light_xxxwide\", \"Load-type\", 0.015641, 0.015641, \"\"),\n",
        "    (\"Block2\", \"light_h144\", \"Load-type\", 0.015695, 0.015695, \"\"),\n",
        "    (\"Block2\", \"light_xwide_h96\", \"Load-type\", 0.015707, 0.015707, \"\"),\n",
        "    (\"Block2\", \"light_xwide_3\", \"Load-type\", 0.015724, 0.015724, \"\"),\n",
        "    (\"Block2\", \"wide_shallow_h112\", \"Load-type\", 0.015735, 0.015735, \"\"),\n",
        "    (\"Block2\", \"emb_heavy_3\", \"Load-type\", 0.015842, 0.015842, \"\"),\n",
        "    (\"Block2\", \"light_emb_h80\", \"Load-type\", 0.015868, 0.015868, \"\"),\n",
        "    (\"Block2\", \"medium_wide_3\", \"Load-type\", 0.015956, 0.015956, \"\"),\n",
        "    (\"Block2\", \"light_wide_h80\", \"Load-type\", 0.016018, 0.016018, \"\"),\n",
        "    (\"Block2\", \"wide_shallow_h96\", \"Load-type\", 0.016039, 0.016039, \"\"),\n",
        "    (\"Block2\", \"deep_wide_3\", \"Load-type\", 0.016050, 0.016050, \"\"),\n",
        "    (\"Block2\", \"light_wide_h96\", \"Load-type\", 0.016079, 0.016079, \"\"),\n",
        "    (\"Block2\", \"deep_3\", \"Load-type\", 0.016268, 0.016268, \"\"),\n",
        "    (\"Block2\", \"light_h80\", \"Load-type\", 0.016278, 0.016278, \"\"),\n",
        "    (\"Block2\", \"light_emb12\", \"Load-type\", 0.016318, 0.016318, \"\"),\n",
        "    (\"Block2\", \"light_h176\", \"Load-type\", 0.016472, 0.016472, \"\"),\n",
        "    (\"Block2\", \"medium_emb12\", \"Load-type\", 0.016495, 0.016495, \"\"),\n",
        "    (\"Block2\", \"heavy_wide_3\", \"Load-type\", 0.016726, 0.016726, \"\"),\n",
        "    (\"Block2\", \"deep_emb12\", \"Load-type\", 0.016848, 0.016848, \"\"),\n",
        "    (\"Block2\", \"heavy_emb12\", \"Load-type\", 0.016942, 0.016942, \"\"),\n",
        "    (\"Block2\", \"medium_3\", \"Load-type\", 0.020678, 0.020678, \"\"),\n",
        "    (\"Block2\", \"heavy_emb12\", \"Original\", 0.023660, 0.023660, \"\"),\n",
        "    (\"Block2\", \"deep_emb12\", \"Original\", 0.023892, 0.023892, \"\"),\n",
        "    (\"Block2\", \"light_xwide_3\", \"Original\", 0.025757, 0.025757, \"\"),\n",
        "    (\"Block2\", \"medium_wide_3\", \"Original\", 0.025859, 0.025859, \"\"),\n",
        "    (\"Block2\", \"heavy_3\", \"Original\", 0.025878, 0.025878, \"\"),\n",
        "    (\"Block2\", \"light_wide_3\", \"Original\", 0.025880, 0.025880, \"\"),\n",
        "    (\"Block2\", \"heavy_wide_3\", \"Original\", 0.025893, 0.025893, \"\"),\n",
        "    (\"Block2\", \"deep_wide_3\", \"Original\", 0.026574, 0.026574, \"\"),\n",
        "    (\"Block2\", \"medium_emb12\", \"Original\", 0.026793, 0.026793, \"\"),\n",
        "    (\"Block2\", \"medium_emb12\", \"Derived\", 0.026833, 0.026833, \"\"),\n",
        "    (\"Block2\", \"deep_3\", \"Original\", 0.026896, 0.026896, \"\"),\n",
        "    (\"Block2\", \"emb_heavy_3\", \"Derived\", 0.026953, 0.026953, \"\"),\n",
        "    (\"Block2\", \"medium_3\", \"Derived\", 0.026972, 0.026972, \"\"),\n",
        "    (\"Block2\", \"max_cap_3\", \"Original\", 0.027236, 0.027236, \"\"),\n",
        "    (\"Block2\", \"emb_heavy_3\", \"Original\", 0.027292, 0.027292, \"\"),\n",
        "    (\"Block2\", \"heavy_wide_3\", \"Derived\", 0.027310, 0.027310, \"\"),\n",
        "    (\"Block2\", \"deep_3\", \"Derived\", 0.027319, 0.027319, \"\"),\n",
        "    (\"Block2\", \"light_wide_3\", \"Derived\", 0.027447, 0.027447, \"\"),\n",
        "    (\"Block2\", \"heavy_3\", \"Derived\", 0.027461, 0.027461, \"\"),\n",
        "    (\"Block2\", \"medium_wide_3\", \"Derived\", 0.027504, 0.027504, \"\"),\n",
        "    (\"Block2\", \"max_cap_3\", \"Derived\", 0.027976, 0.027976, \"\"),\n",
        "    (\"Block2\", \"deep_emb12\", \"Derived\", 0.028090, 0.028090, \"\"),\n",
        "    (\"Block2\", \"heavy_emb12\", \"Derived\", 0.028318, 0.028318, \"\"),\n",
        "    (\"Block2\", \"medium_3\", \"Original\", 0.028460, 0.028460, \"\"),\n",
        "    (\"Block2\", \"light_wide_emb12\", \"Original\", 0.028721, 0.028721, \"\"),\n",
        "    (\"Block2\", \"light_xwide_3\", \"Derived\", 0.028773, 0.028773, \"\"),\n",
        "    (\"Block2\", \"light_emb12\", \"Original\", 0.028795, 0.028795, \"\"),\n",
        "    (\"Block2\", \"light_xxwide\", \"Original\", 0.028844, 0.028844, \"\"),\n",
        "    (\"Block2\", \"light_h80\", \"Original\", 0.028912, 0.028912, \"\"),\n",
        "    (\"Block2\", \"wide_shallow_h160\", \"Original\", 0.028930, 0.028930, \"\"),\n",
        "    (\"Block2\", \"light_wide_h80\", \"Original\", 0.028982, 0.028982, \"\"),\n",
        "    (\"Block2\", \"light_h144\", \"Original\", 0.029013, 0.029013, \"\"),\n",
        "    (\"Block2\", \"light_emb_h96\", \"Original\", 0.029059, 0.029059, \"\"),\n",
        "    (\"Block2\", \"light_wide_h112\", \"Original\", 0.029250, 0.029250, \"\"),\n",
        "    (\"Block2\", \"wide_shallow_h112\", \"Original\", 0.029294, 0.029294, \"\"),\n",
        "    (\"Block2\", \"light_emb_h80\", \"Original\", 0.029385, 0.029385, \"\"),\n",
        "    (\"Block2\", \"light_wide_h96\", \"Original\", 0.029396, 0.029396, \"\"),\n",
        "    (\"Block2\", \"light_xxwide_emb\", \"Original\", 0.029457, 0.029457, \"\"),\n",
        "    (\"Block2\", \"light_xwide_emb\", \"Original\", 0.029474, 0.029474, \"\"),\n",
        "    (\"Block2\", \"light_xwide_h96\", \"Original\", 0.029499, 0.029499, \"\"),\n",
        "    (\"Block2\", \"deep_wide_3\", \"Derived\", 0.029622, 0.029622, \"\"),\n",
        "    (\"Block2\", \"light_xxxwide\", \"Original\", 0.029805, 0.029805, \"\"),\n",
        "    (\"Block2\", \"light_emb_h96\", \"Derived\", 0.030051, 0.030051, \"\"),\n",
        "    (\"Block2\", \"wide_shallow_h96\", \"Original\", 0.030169, 0.030169, \"\"),\n",
        "    (\"Block2\", \"wide_shallow_h112\", \"Derived\", 0.030228, 0.030228, \"\"),\n",
        "    (\"Block2\", \"light_h112\", \"Original\", 0.030233, 0.030233, \"\"),\n",
        "    (\"Block2\", \"light_h176\", \"Original\", 0.030284, 0.030284, \"\"),\n",
        "    (\"Block2\", \"light_h112\", \"Derived\", 0.030303, 0.030303, \"\"),\n",
        "    (\"Block2\", \"light_wide_h112\", \"Derived\", 0.030304, 0.030304, \"\"),\n",
        "    (\"Block2\", \"light_wide_emb12\", \"Derived\", 0.030437, 0.030437, \"\"),\n",
        "    (\"Block2\", \"light_wide_h96\", \"Derived\", 0.030463, 0.030463, \"\"),\n",
        "    (\"Block2\", \"light_h144\", \"Derived\", 0.030463, 0.030463, \"\"),\n",
        "    (\"Block2\", \"wide_shallow_h96\", \"Derived\", 0.030476, 0.030476, \"\"),\n",
        "    (\"Block2\", \"light_xxwide_emb\", \"Derived\", 0.030487, 0.030487, \"\"),\n",
        "    (\"Block2\", \"wide_shallow_emb12\", \"Derived\", 0.030492, 0.030492, \"\"),\n",
        "    (\"Block2\", \"light_xwide_h96\", \"Derived\", 0.030525, 0.030525, \"\"),\n",
        "    (\"Block2\", \"light_xxxwide_emb\", \"Derived\", 0.030576, 0.030576, \"\"),\n",
        "    (\"Block2\", \"light_xwide_emb12\", \"Derived\", 0.030605, 0.030605, \"\"),\n",
        "    (\"Block2\", \"light_xxxwide_emb\", \"Original\", 0.030626, 0.030626, \"\"),\n",
        "    (\"Block2\", \"light_h80\", \"Derived\", 0.030639, 0.030639, \"\"),\n",
        "    (\"Block2\", \"light_xwide_emb\", \"Derived\", 0.030672, 0.030672, \"\"),\n",
        "    (\"Block2\", \"light_xxxwide\", \"Derived\", 0.030732, 0.030732, \"\"),\n",
        "    (\"Block2\", \"light_emb_h80\", \"Derived\", 0.030892, 0.030892, \"\"),\n",
        "    (\"Block2\", \"light_h176\", \"Derived\", 0.030944, 0.030944, \"\"),\n",
        "    (\"Block2\", \"light_emb12\", \"Derived\", 0.030958, 0.030958, \"\"),\n",
        "    (\"Block2\", \"light_xxwide\", \"Derived\", 0.031020, 0.031020, \"\"),\n",
        "    (\"Block2\", \"light_wide_h80\", \"Derived\", 0.031032, 0.031032, \"\"),\n",
        "    (\"Block2\", \"light_xwide_emb12\", \"Original\", 0.031277, 0.031277, \"\"),\n",
        "    (\"Block2\", \"wide_shallow_h160\", \"Derived\", 0.031335, 0.031335, \"\"),\n",
        "    (\"Block2\", \"wide_shallow_emb12\", \"Original\", 0.031643, 0.031643, \"\"),\n",
        "]\n",
        "\n",
        "all_rows = gnn2 + b1 + b2 + b3 + b4 + b5 + b6 + b7\n",
        "df = pd.DataFrame(all_rows, columns=[\"Block\", \"Config\", \"Dataset\", \"MAE\", \"RMSE\", \"Notes\"])\n",
        "df = df[df[\"MAE\"].notna()].copy()\n",
        "df = df.sort_values(\"MAE\").reset_index(drop=True)\n",
        "print(\"ALL MODELS TRIED (GNN2 + GNN3) — sorted by MAE\")\n",
        "print(\"=\" * 90)\n",
        "pd.set_option(\"display.max_rows\", 200)\n",
        "pd.set_option(\"display.width\", 120)\n",
        "print(df.to_string())\n",
        "print(\"\\nBest full-V: Block5 light_emb_h96_phase_onehot_depth3_h112 + Load-type | MAE=0.006099\")\n",
        "print(\"Best delta-V: Block6/7 light_xwide_emb_phase_onehot | MAE=0.003416, RMSE≈0.00463\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77a4526f",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Summary: All explorations tried (GNN2 + GNN3)\n",
        "\n",
        "**Full results tables:** Block 1 (60 rows), Block 2 (104 rows), Block 3 (27 completed), Block 4 (30 rows), Block 5 (24 rows), Block 6 (9 rows), Block 7 (9 rows) — see each block's output above.\n",
        "\n",
        "## Best per block (short summary)\n",
        "\n",
        "| Block | Config | Dataset | MAE | RMSE | Description |\n",
        "|-------|--------|---------|-----|------|-------------|\n",
        "| GNN2 | PF identity vmag+ang | 1st (Original) | 0.0185 | 0.0243 | First dataset, full |V|+angle |\n",
        "| GNN2 | PF identity vmag-only | Load-type | 0.011337 | 0.016622 | Load-type, vmag only |\n",
        "| GNN2 | PF identity inj | Derived | — | — | Run after derived dataset block (gnn_samples_inj_full) |\n",
        "| Block 1 | light_xwide | Load-type | 0.015253 | 0.015253 | 20 nominees × 3 datasets (60 total) |\n",
        "| Block 2 | light_emb_h96 | Load-type | 0.015133 | 0.015133 | 60 nominees × 3 datasets (104 total) |\n",
        "| Block 3 | light_xwide_emb_depth3 | Load-type | 0.006161 | 0.009093 | 10 configs × 3 datasets (27 completed; phase_subgraph had errors) |\n",
        "| Block 4 | light_emb_h96_phase_onehot_depth3 | Load-type | 0.006114 | 0.008798 | 10 configs × 3 datasets (30 total) |\n",
        "| Block 5 | light_emb_h96_phase_onehot_depth3_h112 | Load-type | 0.006099 | 0.008769 | 8 configs × 3 datasets (24 total; phase_subgraph RuntimeError) |\n",
        "| Block 6 | light_xwide_emb_phase_onehot | Delta-V | 0.003416 | 0.004631 | 9 configs on fourth dataset |\n",
        "| Block 7 | light_xwide_emb_phase_onehot | Delta-V 5× | 0.003416 | 0.004630 | 9 configs on fifth dataset (5× PV) |\n",
        "\n",
        "## All configs tried (by block)\n",
        "\n",
        "**Block 1 (20):** light, light_wide, light_xwide, light_emb, light_wide_emb, light_deep, wide_shallow, medium, medium_wide, deep, deep_wide, heavy, heavy_wide, emb_heavy, max_cap, compact_deep, deep_plus, deep_xplus, xdeep, ultra_deep\n",
        "\n",
        "**Block 2 (60):** light_emb_h96, light_xwide_emb, light_wide_emb12, wide_shallow_h160, light_xxxwide_emb, light_xxwide, light_xwide_emb12, light_wide_h112, heavy_3, light_xxwide_emb, light_h112, light_wide_3, max_cap_3, light_xxxwide, light_h144, light_xwide_h96, light_xwide_3, wide_shallow_h112, emb_heavy_3, light_emb_h80, medium_wide_3, light_wide_h80, wide_shallow_h96, deep_wide_3, light_wide_h96, deep_3, light_h80, light_emb12, light_h176, medium_emb12, heavy_wide_3, deep_emb12, heavy_emb12, medium_3, wide_shallow_emb12, + Original/Derived/Load-type for each\n",
        "\n",
        "**Block 3 (10):** light_emb_h96_depth3, light_emb_h96_depth4, light_xwide_emb_depth3, light_emb_h96_norm, light_xwide_emb_norm, wide_shallow_h160_depth3, light_wide_emb12_norm, light_emb_h96_phase_onehot, light_xwide_emb_phase_onehot, light_emb_h96_phase_subgraph (errors)\n",
        "\n",
        "**Block 4 (10):** light_xwide_emb_depth4, light_xwide_emb_depth3_h160, light_xwide_emb_phase_onehot_depth3, light_emb_h96_phase_onehot_depth3, light_xwide_emb_norm_depth3, light_emb_h96_norm_depth3, wide_shallow_h160_depth4, light_xwide_emb_depth3_h192, light_emb_h96_phase_onehot_norm, light_xwide_emb_huber\n",
        "\n",
        "**Block 5 (8):** light_emb_h96_phase_onehot_norm_depth3, light_xwide_emb_phase_onehot_norm_depth3, light_xwide_emb_phase_onehot_depth3_h160, light_emb_h96_phase_onehot_depth3_h112, light_emb_h96_phase_subgraph (errors), light_emb_h96_phase_subgraph_depth3 (errors), light_emb_h96_phase_onehot_huber, light_xwide_emb_phase_onehot_huber\n",
        "\n",
        "**Block 6 & 7 (9 each):** light_emb_h96_phase_onehot_depth3, light_xwide_emb_phase_onehot_depth3_h160, light_xwide_emb_depth3, light_emb_h96_phase_onehot, light_xwide_emb_phase_onehot, light_emb_h96_norm, light_emb_h96_depth3, wide_shallow_h160_depth3, light_xwide_emb_norm\n",
        "\n",
        "**Datasets:** Original (gnn_samples_out), Derived (gnn_samples_inj_full), Load-type (gnn_samples_loadtype_full), Delta-V (gnn_samples_deltav_full), Delta-V 5× (gnn_samples_deltav_5x_full).\n",
        "\n",
        "**Best overall (full voltage V):** Block 5 — light_emb_h96_phase_onehot_depth3_h112 + Load-type | MAE=0.006099, RMSE=0.008769.\n",
        "\n",
        "**Best delta-V:** Block 6/7 — light_xwide_emb_phase_onehot | MAE=0.003416, RMSE≈0.00463 pu."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ec8ab51",
      "metadata": {},
      "source": [
        "---\n",
        "## Train 7 best models and save checkpoints\n",
        "\n",
        "Runs `run_gnn3_best7_train.py` — trains each of the 7 best models (one per block) on their datasets and saves checkpoints to `gnn3_best7_output/`. Requires: `gnn_samples_loadtype_full`, `gnn_samples_deltav_full`, `gnn_samples_deltav_5x_full`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "train7code",
      "metadata": {},
      "outputs": [],
      "source": [
        "%run run_gnn3_best7_train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "overlay7md",
      "metadata": {},
      "source": [
        "## 24h overlay, MAE/RMSE, per-step timing (all-in-one)\n",
        "\n",
        "Runs `run_gnn3_timing_comparison.py` — for each of the 7 models: overlay plots (shown in notebook), MAE/RMSE vs OpenDSS, per-step timing (CPU + GPU). Saves plots to `gnn3_best7_output/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "overlay7code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "GNN3 BEST 7: 24h voltage profile overlay (OpenDSS vs GNN)\n",
            "======================================================================\n",
            "\n",
            ">>> Block 1\n",
            "  1: OpenDSS total=0.026s | GNN total=4.173s | nonconv=0\n",
            "  [saved] gnn3_best7_output\\overlay_24h_block1.png\n",
            "\n",
            ">>> Block 2\n",
            "  2: OpenDSS total=0.024s | GNN total=2.789s | nonconv=0\n",
            "  [saved] gnn3_best7_output\\overlay_24h_block2.png\n",
            "\n",
            ">>> Block 3\n",
            "  3: OpenDSS total=0.025s | GNN total=7.071s | nonconv=0\n",
            "  [saved] gnn3_best7_output\\overlay_24h_block3.png\n",
            "\n",
            ">>> Block 4\n",
            "  4: OpenDSS total=0.026s | GNN total=3.453s | nonconv=0\n",
            "  [saved] gnn3_best7_output\\overlay_24h_block4.png\n",
            "\n",
            ">>> Block 5\n",
            "  5: OpenDSS total=0.026s | GNN total=4.526s | nonconv=0\n",
            "  [saved] gnn3_best7_output\\overlay_24h_block5.png\n",
            "\n",
            ">>> Block 6\n",
            "  6: OpenDSS total=0.049s | GNN total=4.131s | nonconv=0\n",
            "  [saved] gnn3_best7_output\\overlay_24h_block6.png\n",
            "\n",
            ">>> Block 7\n",
            "  7: OpenDSS total=0.048s | GNN total=5.669s | nonconv=0\n",
            "  [saved] gnn3_best7_output\\overlay_24h_block7.png\n",
            "\n",
            "======================================================================\n",
            "INFERENCE SPEEDS (24h = 288 steps per model)\n",
            "======================================================================\n",
            "  block1: OpenDSS total=0.026s | GNN total=4.173s | GNN mean/step=14.49ms\n",
            "  block2: OpenDSS total=0.024s | GNN total=2.789s | GNN mean/step=9.68ms\n",
            "  block3: OpenDSS total=0.025s | GNN total=7.071s | GNN mean/step=24.55ms\n",
            "  block4: OpenDSS total=0.026s | GNN total=3.453s | GNN mean/step=11.99ms\n",
            "  block5: OpenDSS total=0.026s | GNN total=4.526s | GNN mean/step=15.72ms\n",
            "  block6: OpenDSS total=0.049s | GNN total=4.131s | GNN mean/step=14.34ms\n",
            "  block7: OpenDSS total=0.048s | GNN total=5.669s | GNN mean/step=19.68ms\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "%run run_gnn3_timing_comparison.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d478398",
      "metadata": {},
      "source": [
        "non batched results:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54e6872e",
      "metadata": {},
      "source": [
        "\n",
        "========================================================================\n",
        "GNN3 BEST 7: Overlay plots, MAE/RMSE, per-step timing (CPU + GPU)\n",
        "  OpenDSS: profile only (set_time, apply_full, solve, get_voltage)\n",
        "  Delta-V: vmag_zero from separate 24h pass (PV=0); full solve only in main loop\n",
        "  (ensures identical OpenDSS voltage profiles across all blocks)\n",
        "========================================================================\n",
        "\n",
        ">>> Block 1 on CPU...\n",
        "  @ 840.1: MAE=0.005276 pu | RMSE=0.006559 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block1.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=13, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=8, edge_emb_dim=4\n",
        "    h_dim=128, num_layers=2\n",
        "    use_norm=False, use_phase_onehot=False\n",
        "    dataset=gnn_samples_loadtype_full, target_col=vmag_pu\n",
        "    train best_rmse=0.008948 pu\n",
        "    train best_mae=0.006312 pu\n",
        "    best_epoch=9\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 1 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     4.30 ms  (0.0043s)\n",
        "  5_apply_snapshot_full         :   236.29 ms  (0.2363s)\n",
        "  6_solve_full                  :    30.42 ms  (0.0304s)\n",
        "  7_get_voltage_full            :   125.17 ms  (0.1252s)\n",
        "  TOTAL                         :   396.19 ms  (0.3962s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    98.38 ms  (0.0984s)  (2.1%)\n",
        "  2_tensor_data_creation        :    25.61 ms  (0.0256s)  (0.6%)\n",
        "  3_model_forward               :  4517.80 ms  (4.5178s)  (97.3%)\n",
        "  TOTAL                         :  4641.78 ms  (4.6418s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 396.19 ms  |  GNN total: 4641.78 ms\n",
        "  GNN/OpenDSS ratio: 11.72x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 1 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 1 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     3.51 ms  (0.0035s)\n",
        "  5_apply_snapshot_full         :   195.60 ms  (0.1956s)\n",
        "  6_solve_full                  :    29.40 ms  (0.0294s)\n",
        "  7_get_voltage_full            :   120.72 ms  (0.1207s)\n",
        "  TOTAL                         :   349.23 ms  (0.3492s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    96.55 ms  (0.0965s)  (14.1%)\n",
        "  2_tensor_data_creation        :    41.97 ms  (0.0420s)  (6.1%)\n",
        "  3_model_forward               :   547.26 ms  (0.5473s)  (79.8%)\n",
        "  TOTAL                         :   685.78 ms  (0.6858s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 349.23 ms  |  GNN total: 685.78 ms\n",
        "  GNN/OpenDSS ratio: 1.96x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 2 on CPU...\n",
        "  @ 840.1: MAE=0.005190 pu | RMSE=0.006738 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block2.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=13, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=96, num_layers=2\n",
        "    use_norm=False, use_phase_onehot=False\n",
        "    dataset=gnn_samples_loadtype_full, target_col=vmag_pu\n",
        "    train best_rmse=0.008728 pu\n",
        "    train best_mae=0.006098 pu\n",
        "    best_epoch=12\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 2 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     4.20 ms  (0.0042s)\n",
        "  5_apply_snapshot_full         :   242.03 ms  (0.2420s)\n",
        "  6_solve_full                  :    31.40 ms  (0.0314s)\n",
        "  7_get_voltage_full            :   128.72 ms  (0.1287s)\n",
        "  TOTAL                         :   406.35 ms  (0.4064s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :   103.43 ms  (0.1034s)  (3.4%)\n",
        "  2_tensor_data_creation        :    25.86 ms  (0.0259s)  (0.9%)\n",
        "  3_model_forward               :  2869.39 ms  (2.8694s)  (95.7%)\n",
        "  TOTAL                         :  2998.68 ms  (2.9987s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 406.35 ms  |  GNN total: 2998.68 ms\n",
        "  GNN/OpenDSS ratio: 7.38x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 2 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 2 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     3.47 ms  (0.0035s)\n",
        "  5_apply_snapshot_full         :   202.22 ms  (0.2022s)\n",
        "  6_solve_full                  :    29.33 ms  (0.0293s)\n",
        "  7_get_voltage_full            :   124.78 ms  (0.1248s)\n",
        "  TOTAL                         :   359.80 ms  (0.3598s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    96.73 ms  (0.0967s)  (13.8%)\n",
        "  2_tensor_data_creation        :    41.67 ms  (0.0417s)  (6.0%)\n",
        "  3_model_forward               :   560.77 ms  (0.5608s)  (80.2%)\n",
        "  TOTAL                         :   699.17 ms  (0.6992s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 359.80 ms  |  GNN total: 699.17 ms\n",
        "  GNN/OpenDSS ratio: 1.94x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 3 on CPU...\n",
        "  @ 840.1: MAE=0.004694 pu | RMSE=0.006015 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block3.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=13, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=128, num_layers=3\n",
        "    use_norm=False, use_phase_onehot=False\n",
        "    dataset=gnn_samples_loadtype_full, target_col=vmag_pu\n",
        "    train best_rmse=0.008919 pu\n",
        "    train best_mae=0.006216 pu\n",
        "    best_epoch=11\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 3 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     4.76 ms  (0.0048s)\n",
        "  5_apply_snapshot_full         :   238.98 ms  (0.2390s)\n",
        "  6_solve_full                  :    33.52 ms  (0.0335s)\n",
        "  7_get_voltage_full            :   127.47 ms  (0.1275s)\n",
        "  TOTAL                         :   404.72 ms  (0.4047s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    98.87 ms  (0.0989s)  (1.4%)\n",
        "  2_tensor_data_creation        :    27.25 ms  (0.0273s)  (0.4%)\n",
        "  3_model_forward               :  6974.85 ms  (6.9749s)  (98.2%)\n",
        "  TOTAL                         :  7100.97 ms  (7.1010s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 404.72 ms  |  GNN total: 7100.97 ms\n",
        "  GNN/OpenDSS ratio: 17.55x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 3 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 3 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     3.45 ms  (0.0035s)\n",
        "  5_apply_snapshot_full         :   198.25 ms  (0.1982s)\n",
        "  6_solve_full                  :    28.98 ms  (0.0290s)\n",
        "  7_get_voltage_full            :   120.65 ms  (0.1207s)\n",
        "  TOTAL                         :   351.33 ms  (0.3513s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    96.04 ms  (0.0960s)  (11.2%)\n",
        "  2_tensor_data_creation        :    41.35 ms  (0.0414s)  (4.8%)\n",
        "  3_model_forward               :   721.57 ms  (0.7216s)  (84.0%)\n",
        "  TOTAL                         :   858.96 ms  (0.8590s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 351.33 ms  |  GNN total: 858.96 ms\n",
        "  GNN/OpenDSS ratio: 2.44x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 4 on CPU...\n",
        "  @ 840.1: MAE=0.004710 pu | RMSE=0.006225 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block4.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=16, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=96, num_layers=3\n",
        "    use_norm=False, use_phase_onehot=True\n",
        "    dataset=gnn_samples_loadtype_full, target_col=vmag_pu\n",
        "    train best_rmse=0.008946 pu\n",
        "    train best_mae=0.006363 pu\n",
        "    best_epoch=6\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 4 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     4.34 ms  (0.0043s)\n",
        "  5_apply_snapshot_full         :   236.90 ms  (0.2369s)\n",
        "  6_solve_full                  :    31.23 ms  (0.0312s)\n",
        "  7_get_voltage_full            :   126.27 ms  (0.1263s)\n",
        "  TOTAL                         :   398.74 ms  (0.3987s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :   103.61 ms  (0.1036s)  (2.9%)\n",
        "  2_tensor_data_creation        :    25.96 ms  (0.0260s)  (0.7%)\n",
        "  3_model_forward               :  3430.53 ms  (3.4305s)  (96.4%)\n",
        "  TOTAL                         :  3560.10 ms  (3.5601s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 398.74 ms  |  GNN total: 3560.10 ms\n",
        "  GNN/OpenDSS ratio: 8.93x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 4 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 4 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     3.45 ms  (0.0034s)\n",
        "  5_apply_snapshot_full         :   200.46 ms  (0.2005s)\n",
        "  6_solve_full                  :    28.83 ms  (0.0288s)\n",
        "  7_get_voltage_full            :   122.33 ms  (0.1223s)\n",
        "  TOTAL                         :   355.07 ms  (0.3551s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    98.35 ms  (0.0984s)  (11.3%)\n",
        "  2_tensor_data_creation        :    41.22 ms  (0.0412s)  (4.7%)\n",
        "  3_model_forward               :   732.36 ms  (0.7324s)  (84.0%)\n",
        "  TOTAL                         :   871.94 ms  (0.8719s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 355.07 ms  |  GNN total: 871.94 ms\n",
        "  GNN/OpenDSS ratio: 2.46x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 5 on CPU...\n",
        "  @ 840.1: MAE=0.003972 pu | RMSE=0.005366 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block5.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=16, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=112, num_layers=3\n",
        "    use_norm=False, use_phase_onehot=True\n",
        "    dataset=gnn_samples_loadtype_full, target_col=vmag_pu\n",
        "    train best_rmse=0.008885 pu\n",
        "    train best_mae=0.006284 pu\n",
        "    best_epoch=8\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 5 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     4.46 ms  (0.0045s)\n",
        "  5_apply_snapshot_full         :   238.21 ms  (0.2382s)\n",
        "  6_solve_full                  :    32.78 ms  (0.0328s)\n",
        "  7_get_voltage_full            :   127.40 ms  (0.1274s)\n",
        "  TOTAL                         :   402.85 ms  (0.4029s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :   104.60 ms  (0.1046s)  (2.0%)\n",
        "  2_tensor_data_creation        :    27.10 ms  (0.0271s)  (0.5%)\n",
        "  3_model_forward               :  5059.67 ms  (5.0597s)  (97.5%)\n",
        "  TOTAL                         :  5191.37 ms  (5.1914s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 402.85 ms  |  GNN total: 5191.37 ms\n",
        "  GNN/OpenDSS ratio: 12.89x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 5 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 5 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     3.54 ms  (0.0035s)\n",
        "  5_apply_snapshot_full         :   200.85 ms  (0.2009s)\n",
        "  6_solve_full                  :    29.12 ms  (0.0291s)\n",
        "  7_get_voltage_full            :   121.83 ms  (0.1218s)\n",
        "  TOTAL                         :   355.35 ms  (0.3553s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    98.69 ms  (0.0987s)  (11.4%)\n",
        "  2_tensor_data_creation        :    41.54 ms  (0.0415s)  (4.8%)\n",
        "  3_model_forward               :   726.27 ms  (0.7263s)  (83.8%)\n",
        "  TOTAL                         :   866.50 ms  (0.8665s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 355.35 ms  |  GNN total: 866.50 ms\n",
        "  GNN/OpenDSS ratio: 2.44x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 6 on CPU...\n",
        "  @ 840.1: MAE=0.028297 pu | RMSE=0.036542 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block6.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=17, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=128, num_layers=2\n",
        "    use_norm=False, use_phase_onehot=True\n",
        "    dataset=gnn_samples_deltav_full, target_col=vmag_delta_pu\n",
        "    train best_rmse=0.004621 pu\n",
        "    train best_mae=0.003362 pu\n",
        "    best_epoch=6\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 6 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     4.16 ms  (0.0042s)\n",
        "  5_apply_snapshot_full         :   229.93 ms  (0.2299s)\n",
        "  6_solve_full                  :    29.72 ms  (0.0297s)\n",
        "  7_get_voltage_full            :   123.13 ms  (0.1231s)\n",
        "  TOTAL                         :   386.94 ms  (0.3869s)\n",
        "\n",
        "GNN (includes OpenDSS zero-PV for vmag_zero + GNN steps):\n",
        "  0_dss_zero_pv (for GNN input) :   325.12 ms  (0.3251s)  (7.3%)\n",
        "  1_build_gnn_x                 :   100.31 ms  (0.1003s)  (2.3%)\n",
        "  2_tensor_data_creation        :    25.47 ms  (0.0255s)  (0.6%)\n",
        "  3_model_forward               :  3999.54 ms  (3.9995s)  (89.9%)\n",
        "  TOTAL                         :  4450.45 ms  (4.4504s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 386.94 ms  |  GNN total: 4450.45 ms\n",
        "  GNN/OpenDSS ratio: 11.50x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 6 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 6 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     3.41 ms  (0.0034s)\n",
        "  5_apply_snapshot_full         :   216.03 ms  (0.2160s)\n",
        "  6_solve_full                  :    28.46 ms  (0.0285s)\n",
        "  7_get_voltage_full            :   120.25 ms  (0.1203s)\n",
        "  TOTAL                         :   368.15 ms  (0.3682s)\n",
        "\n",
        "GNN (includes OpenDSS zero-PV for vmag_zero + GNN steps):\n",
        "  0_dss_zero_pv (for GNN input) :   324.14 ms  (0.3241s)  (32.2%)\n",
        "  1_build_gnn_x                 :    99.48 ms  (0.0995s)  (9.9%)\n",
        "  2_tensor_data_creation        :    41.18 ms  (0.0412s)  (4.1%)\n",
        "  3_model_forward               :   542.49 ms  (0.5425s)  (53.9%)\n",
        "  TOTAL                         :  1007.29 ms  (1.0073s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 368.15 ms  |  GNN total: 1007.29 ms\n",
        "  GNN/OpenDSS ratio: 2.74x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 7 on CPU...\n",
        "  @ 840.1: MAE=0.028291 pu | RMSE=0.036593 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block7.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=17, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=128, num_layers=2\n",
        "    use_norm=False, use_phase_onehot=True\n",
        "    dataset=gnn_samples_deltav_5x_full, target_col=vmag_delta_pu\n",
        "    train best_rmse=0.004628 pu\n",
        "    train best_mae=0.003371 pu\n",
        "    best_epoch=6\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 7 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     4.80 ms  (0.0048s)\n",
        "  5_apply_snapshot_full         :   242.22 ms  (0.2422s)\n",
        "  6_solve_full                  :    34.32 ms  (0.0343s)\n",
        "  7_get_voltage_full            :   131.84 ms  (0.1318s)\n",
        "  TOTAL                         :   413.18 ms  (0.4132s)\n",
        "\n",
        "GNN (includes OpenDSS zero-PV for vmag_zero + GNN steps):\n",
        "  0_dss_zero_pv (for GNN input) :   329.19 ms  (0.3292s)  (5.6%)\n",
        "  1_build_gnn_x                 :   107.45 ms  (0.1075s)  (1.8%)\n",
        "  2_tensor_data_creation        :    28.05 ms  (0.0280s)  (0.5%)\n",
        "  3_model_forward               :  5465.09 ms  (5.4651s)  (92.2%)\n",
        "  TOTAL                         :  5929.79 ms  (5.9298s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 413.18 ms  |  GNN total: 5929.79 ms\n",
        "  GNN/OpenDSS ratio: 14.35x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 7 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 7 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     3.46 ms  (0.0035s)\n",
        "  5_apply_snapshot_full         :   216.48 ms  (0.2165s)\n",
        "  6_solve_full                  :    28.81 ms  (0.0288s)\n",
        "  7_get_voltage_full            :   120.28 ms  (0.1203s)\n",
        "  TOTAL                         :   369.04 ms  (0.3690s)\n",
        "\n",
        "GNN (includes OpenDSS zero-PV for vmag_zero + GNN steps):\n",
        "  0_dss_zero_pv (for GNN input) :   324.34 ms  (0.3243s)  (31.9%)\n",
        "  1_build_gnn_x                 :   100.34 ms  (0.1003s)  (9.9%)\n",
        "  2_tensor_data_creation        :    41.83 ms  (0.0418s)  (4.1%)\n",
        "  3_model_forward               :   549.50 ms  (0.5495s)  (54.1%)\n",
        "  TOTAL                         :  1016.01 ms  (1.0160s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 369.04 ms  |  GNN total: 1016.01 ms\n",
        "  GNN/OpenDSS ratio: 2.75x\n",
        "========================================================================\n",
        "\n",
        "========================================================================\n",
        "SUMMARY: MAE/RMSE @ 840.1 | Speeds (CPU)\n",
        "========================================================================\n",
        "  block1: MAE=0.005276 | RMSE=0.006559 | OpenDSS=396ms | GNN=4642ms\n",
        "  block2: MAE=0.005190 | RMSE=0.006738 | OpenDSS=406ms | GNN=2999ms\n",
        "  block3: MAE=0.004694 | RMSE=0.006015 | OpenDSS=405ms | GNN=7101ms\n",
        "  block4: MAE=0.004710 | RMSE=0.006225 | OpenDSS=399ms | GNN=3560ms\n",
        "  block5: MAE=0.003972 | RMSE=0.005366 | OpenDSS=403ms | GNN=5191ms\n",
        "  block6: MAE=0.028297 | RMSE=0.036542 | OpenDSS=387ms | GNN=4450ms\n",
        "  block7: MAE=0.028291 | RMSE=0.036593 | OpenDSS=413ms | GNN=5930ms\n",
        "========================================================================\n",
        "<Figure size 640x480 with 0 Axes>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6679a0a3",
      "metadata": {},
      "source": [
        "bathced results:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bca00a47",
      "metadata": {},
      "source": [
        "\n",
        "========================================================================\n",
        "GNN3 BEST 7: Overlay plots, MAE/RMSE, per-step timing (CPU + GPU)\n",
        "  OpenDSS: profile only (set_time, apply_full, solve, get_voltage)\n",
        "  GNN: batched inference (288 timesteps in one forward pass)\n",
        "  Delta-V: vmag_zero from separate 24h pass (PV=0); full solve only in main loop\n",
        "========================================================================\n",
        "\n",
        ">>> Block 1 on CPU...\n",
        "  @ 840.1: MAE=0.005276 pu | RMSE=0.006559 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block1.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=13, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=8, edge_emb_dim=4\n",
        "    h_dim=128, num_layers=2\n",
        "    use_norm=False, use_phase_onehot=False\n",
        "    dataset=gnn_samples_loadtype_full, target_col=vmag_pu\n",
        "    train best_rmse=0.008948 pu\n",
        "    train best_mae=0.006312 pu\n",
        "    best_epoch=9\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 1 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.73 ms  (0.0017s)\n",
        "  5_apply_snapshot_full         :   176.55 ms  (0.1766s)\n",
        "  6_solve_full                  :    24.90 ms  (0.0249s)\n",
        "  7_get_voltage_full            :   111.94 ms  (0.1119s)\n",
        "  TOTAL                         :   315.13 ms  (0.3151s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    94.01 ms  (0.0940s)  (2.6%)\n",
        "  2_tensor_data_creation        :    47.70 ms  (0.0477s)  (1.3%)\n",
        "  3_model_forward               :  3522.13 ms  (3.5221s)  (96.1%)\n",
        "  TOTAL                         :  3663.83 ms  (3.6638s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 315.13 ms  |  GNN total: 3663.83 ms\n",
        "  GNN/OpenDSS ratio: 11.63x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 1 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 1 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.64 ms  (0.0016s)\n",
        "  5_apply_snapshot_full         :   174.97 ms  (0.1750s)\n",
        "  6_solve_full                  :    24.82 ms  (0.0248s)\n",
        "  7_get_voltage_full            :   109.55 ms  (0.1096s)\n",
        "  TOTAL                         :   310.98 ms  (0.3110s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    92.35 ms  (0.0924s)  (18.5%)\n",
        "  2_tensor_data_creation        :   144.64 ms  (0.1446s)  (29.0%)\n",
        "  3_model_forward               :   261.41 ms  (0.2614s)  (52.4%)\n",
        "  TOTAL                         :   498.40 ms  (0.4984s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 310.98 ms  |  GNN total: 498.40 ms\n",
        "  GNN/OpenDSS ratio: 1.60x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 2 on CPU...\n",
        "  @ 840.1: MAE=0.005190 pu | RMSE=0.006738 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block2.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=13, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=96, num_layers=2\n",
        "    use_norm=False, use_phase_onehot=False\n",
        "    dataset=gnn_samples_loadtype_full, target_col=vmag_pu\n",
        "    train best_rmse=0.008728 pu\n",
        "    train best_mae=0.006098 pu\n",
        "    best_epoch=12\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 2 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.70 ms  (0.0017s)\n",
        "  5_apply_snapshot_full         :   176.26 ms  (0.1763s)\n",
        "  6_solve_full                  :    25.34 ms  (0.0253s)\n",
        "  7_get_voltage_full            :   112.85 ms  (0.1129s)\n",
        "  TOTAL                         :   316.14 ms  (0.3161s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    93.60 ms  (0.0936s)  (4.0%)\n",
        "  2_tensor_data_creation        :   210.08 ms  (0.2101s)  (9.1%)\n",
        "  3_model_forward               :  2017.58 ms  (2.0176s)  (86.9%)\n",
        "  TOTAL                         :  2321.26 ms  (2.3213s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 316.14 ms  |  GNN total: 2321.26 ms\n",
        "  GNN/OpenDSS ratio: 7.34x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 2 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 2 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.81 ms  (0.0018s)\n",
        "  5_apply_snapshot_full         :   176.87 ms  (0.1769s)\n",
        "  6_solve_full                  :    26.20 ms  (0.0262s)\n",
        "  7_get_voltage_full            :   116.50 ms  (0.1165s)\n",
        "  TOTAL                         :   321.38 ms  (0.3214s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    94.08 ms  (0.0941s)  (63.6%)\n",
        "  2_tensor_data_creation        :    26.81 ms  (0.0268s)  (18.1%)\n",
        "  3_model_forward               :    26.93 ms  (0.0269s)  (18.2%)\n",
        "  TOTAL                         :   147.82 ms  (0.1478s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 321.38 ms  |  GNN total: 147.82 ms\n",
        "  GNN/OpenDSS ratio: 0.46x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 3 on CPU...\n",
        "  @ 840.1: MAE=0.004694 pu | RMSE=0.006015 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block3.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=13, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=128, num_layers=3\n",
        "    use_norm=False, use_phase_onehot=False\n",
        "    dataset=gnn_samples_loadtype_full, target_col=vmag_pu\n",
        "    train best_rmse=0.008919 pu\n",
        "    train best_mae=0.006216 pu\n",
        "    best_epoch=11\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 3 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.78 ms  (0.0018s)\n",
        "  5_apply_snapshot_full         :   178.18 ms  (0.1782s)\n",
        "  6_solve_full                  :    25.81 ms  (0.0258s)\n",
        "  7_get_voltage_full            :   115.12 ms  (0.1151s)\n",
        "  TOTAL                         :   320.89 ms  (0.3209s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    93.54 ms  (0.0935s)  (1.6%)\n",
        "  2_tensor_data_creation        :    14.24 ms  (0.0142s)  (0.2%)\n",
        "  3_model_forward               :  5739.95 ms  (5.7399s)  (98.2%)\n",
        "  TOTAL                         :  5847.73 ms  (5.8477s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 320.89 ms  |  GNN total: 5847.73 ms\n",
        "  GNN/OpenDSS ratio: 18.22x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 3 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 3 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.75 ms  (0.0017s)\n",
        "  5_apply_snapshot_full         :   176.99 ms  (0.1770s)\n",
        "  6_solve_full                  :    25.85 ms  (0.0259s)\n",
        "  7_get_voltage_full            :   113.22 ms  (0.1132s)\n",
        "  TOTAL                         :   317.82 ms  (0.3178s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    93.57 ms  (0.0936s)  (66.8%)\n",
        "  2_tensor_data_creation        :    26.48 ms  (0.0265s)  (18.9%)\n",
        "  3_model_forward               :    19.98 ms  (0.0200s)  (14.3%)\n",
        "  TOTAL                         :   140.02 ms  (0.1400s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 317.82 ms  |  GNN total: 140.02 ms\n",
        "  GNN/OpenDSS ratio: 0.44x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 4 on CPU...\n",
        "  @ 840.1: MAE=0.004710 pu | RMSE=0.006225 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block4.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=16, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=96, num_layers=3\n",
        "    use_norm=False, use_phase_onehot=True\n",
        "    dataset=gnn_samples_loadtype_full, target_col=vmag_pu\n",
        "    train best_rmse=0.008946 pu\n",
        "    train best_mae=0.006363 pu\n",
        "    best_epoch=6\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 4 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.82 ms  (0.0018s)\n",
        "  5_apply_snapshot_full         :   178.52 ms  (0.1785s)\n",
        "  6_solve_full                  :    26.23 ms  (0.0262s)\n",
        "  7_get_voltage_full            :   114.62 ms  (0.1146s)\n",
        "  TOTAL                         :   321.20 ms  (0.3212s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    97.29 ms  (0.0973s)  (3.8%)\n",
        "  2_tensor_data_creation        :    13.89 ms  (0.0139s)  (0.5%)\n",
        "  3_model_forward               :  2454.34 ms  (2.4543s)  (95.7%)\n",
        "  TOTAL                         :  2565.52 ms  (2.5655s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 321.20 ms  |  GNN total: 2565.52 ms\n",
        "  GNN/OpenDSS ratio: 7.99x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 4 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 4 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.88 ms  (0.0019s)\n",
        "  5_apply_snapshot_full         :   176.76 ms  (0.1768s)\n",
        "  6_solve_full                  :    26.17 ms  (0.0262s)\n",
        "  7_get_voltage_full            :   112.35 ms  (0.1124s)\n",
        "  TOTAL                         :   317.16 ms  (0.3172s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    96.52 ms  (0.0965s)  (67.4%)\n",
        "  2_tensor_data_creation        :    28.14 ms  (0.0281s)  (19.7%)\n",
        "  3_model_forward               :    18.45 ms  (0.0184s)  (12.9%)\n",
        "  TOTAL                         :   143.11 ms  (0.1431s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 317.16 ms  |  GNN total: 143.11 ms\n",
        "  GNN/OpenDSS ratio: 0.45x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 5 on CPU...\n",
        "  @ 840.1: MAE=0.003972 pu | RMSE=0.005366 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block5.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=16, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=112, num_layers=3\n",
        "    use_norm=False, use_phase_onehot=True\n",
        "    dataset=gnn_samples_loadtype_full, target_col=vmag_pu\n",
        "    train best_rmse=0.008885 pu\n",
        "    train best_mae=0.006284 pu\n",
        "    best_epoch=8\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 5 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.84 ms  (0.0018s)\n",
        "  5_apply_snapshot_full         :   177.43 ms  (0.1774s)\n",
        "  6_solve_full                  :    26.19 ms  (0.0262s)\n",
        "  7_get_voltage_full            :   114.75 ms  (0.1147s)\n",
        "  TOTAL                         :   320.21 ms  (0.3202s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    96.88 ms  (0.0969s)  (2.7%)\n",
        "  2_tensor_data_creation        :    13.90 ms  (0.0139s)  (0.4%)\n",
        "  3_model_forward               :  3484.96 ms  (3.4850s)  (96.9%)\n",
        "  TOTAL                         :  3595.74 ms  (3.5957s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 320.21 ms  |  GNN total: 3595.74 ms\n",
        "  GNN/OpenDSS ratio: 11.23x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 5 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 5 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.77 ms  (0.0018s)\n",
        "  5_apply_snapshot_full         :   176.90 ms  (0.1769s)\n",
        "  6_solve_full                  :    26.07 ms  (0.0261s)\n",
        "  7_get_voltage_full            :   113.76 ms  (0.1138s)\n",
        "  TOTAL                         :   318.51 ms  (0.3185s)\n",
        "\n",
        "GNN (per-step times):\n",
        "  1_build_gnn_x                 :    96.15 ms  (0.0961s)  (67.3%)\n",
        "  2_tensor_data_creation        :    27.84 ms  (0.0278s)  (19.5%)\n",
        "  3_model_forward               :    18.89 ms  (0.0189s)  (13.2%)\n",
        "  TOTAL                         :   142.88 ms  (0.1429s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 318.51 ms  |  GNN total: 142.88 ms\n",
        "  GNN/OpenDSS ratio: 0.45x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 6 on CPU...\n",
        "  @ 840.1: MAE=0.028297 pu | RMSE=0.036542 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block6.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=17, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=128, num_layers=2\n",
        "    use_norm=False, use_phase_onehot=True\n",
        "    dataset=gnn_samples_deltav_full, target_col=vmag_delta_pu\n",
        "    train best_rmse=0.004621 pu\n",
        "    train best_mae=0.003362 pu\n",
        "    best_epoch=6\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 6 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.85 ms  (0.0018s)\n",
        "  5_apply_snapshot_full         :   195.07 ms  (0.1951s)\n",
        "  6_solve_full                  :    29.63 ms  (0.0296s)\n",
        "  7_get_voltage_full            :   115.09 ms  (0.1151s)\n",
        "  TOTAL                         :   341.63 ms  (0.3416s)\n",
        "\n",
        "GNN (includes OpenDSS zero-PV for vmag_zero + GNN steps):\n",
        "  0_dss_zero_pv (for GNN input) :   317.53 ms  (0.3175s)  (9.1%)\n",
        "  1_build_gnn_x                 :    98.74 ms  (0.0987s)  (2.8%)\n",
        "  2_tensor_data_creation        :    14.12 ms  (0.0141s)  (0.4%)\n",
        "  3_model_forward               :  3055.29 ms  (3.0553s)  (87.7%)\n",
        "  TOTAL                         :  3485.68 ms  (3.4857s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 341.63 ms  |  GNN total: 3485.68 ms\n",
        "  GNN/OpenDSS ratio: 10.20x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 6 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 6 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.84 ms  (0.0018s)\n",
        "  5_apply_snapshot_full         :   193.32 ms  (0.1933s)\n",
        "  6_solve_full                  :    29.96 ms  (0.0300s)\n",
        "  7_get_voltage_full            :   112.60 ms  (0.1126s)\n",
        "  TOTAL                         :   337.72 ms  (0.3377s)\n",
        "\n",
        "GNN (includes OpenDSS zero-PV for vmag_zero + GNN steps):\n",
        "  0_dss_zero_pv (for GNN input) :   317.59 ms  (0.3176s)  (69.0%)\n",
        "  1_build_gnn_x                 :    98.30 ms  (0.0983s)  (21.4%)\n",
        "  2_tensor_data_creation        :    26.77 ms  (0.0268s)  (5.8%)\n",
        "  3_model_forward               :    17.67 ms  (0.0177s)  (3.8%)\n",
        "  TOTAL                         :   460.33 ms  (0.4603s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 337.72 ms  |  GNN total: 460.33 ms\n",
        "  GNN/OpenDSS ratio: 1.36x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 7 on CPU...\n",
        "  @ 840.1: MAE=0.028291 pu | RMSE=0.036593 pu\n",
        "\n",
        "  [saved] gnn3_best7_output/overlay_24h_block7.png\n",
        "\n",
        "  GNN model details:\n",
        "    N=95 nodes, E=184 edges\n",
        "    node_in_dim=17, edge_in_dim=2, out_dim=1\n",
        "    node_emb_dim=16, edge_emb_dim=8\n",
        "    h_dim=128, num_layers=2\n",
        "    use_norm=False, use_phase_onehot=True\n",
        "    dataset=gnn_samples_deltav_5x_full, target_col=vmag_delta_pu\n",
        "    train best_rmse=0.004628 pu\n",
        "    train best_mae=0.003371 pu\n",
        "    best_epoch=6\n",
        "\n",
        "\n",
        "========================================================================\n",
        "BLOCK 7 | CPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.87 ms  (0.0019s)\n",
        "  5_apply_snapshot_full         :   194.61 ms  (0.1946s)\n",
        "  6_solve_full                  :    29.98 ms  (0.0300s)\n",
        "  7_get_voltage_full            :   113.28 ms  (0.1133s)\n",
        "  TOTAL                         :   339.75 ms  (0.3398s)\n",
        "\n",
        "GNN (includes OpenDSS zero-PV for vmag_zero + GNN steps):\n",
        "  0_dss_zero_pv (for GNN input) :   318.98 ms  (0.3190s)  (6.9%)\n",
        "  1_build_gnn_x                 :    98.06 ms  (0.0981s)  (2.1%)\n",
        "  2_tensor_data_creation        :    14.36 ms  (0.0144s)  (0.3%)\n",
        "  3_model_forward               :  4194.86 ms  (4.1949s)  (90.7%)\n",
        "  TOTAL                         :  4626.26 ms  (4.6263s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 339.75 ms  |  GNN total: 4626.26 ms\n",
        "  GNN/OpenDSS ratio: 13.62x\n",
        "========================================================================\n",
        "\n",
        ">>> Block 7 on GPU...\n",
        "\n",
        "========================================================================\n",
        "BLOCK 7 | GPU | 288 steps\n",
        "========================================================================\n",
        "\n",
        "OpenDSS (profile only: set_time, apply_full, solve, get_voltage):\n",
        "  1_set_time_index              :     1.94 ms  (0.0019s)\n",
        "  5_apply_snapshot_full         :   194.60 ms  (0.1946s)\n",
        "  6_solve_full                  :    30.06 ms  (0.0301s)\n",
        "  7_get_voltage_full            :   113.78 ms  (0.1138s)\n",
        "  TOTAL                         :   340.39 ms  (0.3404s)\n",
        "\n",
        "GNN (includes OpenDSS zero-PV for vmag_zero + GNN steps):\n",
        "  0_dss_zero_pv (for GNN input) :   323.20 ms  (0.3232s)  (69.1%)\n",
        "  1_build_gnn_x                 :    98.49 ms  (0.0985s)  (21.1%)\n",
        "  2_tensor_data_creation        :    28.20 ms  (0.0282s)  (6.0%)\n",
        "  3_model_forward               :    17.67 ms  (0.0177s)  (3.8%)\n",
        "  TOTAL                         :   467.56 ms  (0.4676s)\n",
        "\n",
        "Summary (comparable: OpenDSS profile vs GNN pipeline):\n",
        "  OpenDSS total: 340.39 ms  |  GNN total: 467.56 ms\n",
        "  GNN/OpenDSS ratio: 1.37x\n",
        "========================================================================\n",
        "\n",
        "========================================================================\n",
        "SUMMARY: MAE/RMSE @ 840.1 | Speeds (CPU)\n",
        "========================================================================\n",
        "  block1: MAE=0.005276 | RMSE=0.006559 | OpenDSS=315ms | GNN=3664ms\n",
        "  block2: MAE=0.005190 | RMSE=0.006738 | OpenDSS=316ms | GNN=2321ms\n",
        "  block3: MAE=0.004694 | RMSE=0.006015 | OpenDSS=321ms | GNN=5848ms\n",
        "  block4: MAE=0.004710 | RMSE=0.006225 | OpenDSS=321ms | GNN=2566ms\n",
        "  block5: MAE=0.003972 | RMSE=0.005366 | OpenDSS=320ms | GNN=3596ms\n",
        "  block6: MAE=0.028297 | RMSE=0.036542 | OpenDSS=342ms | GNN=3486ms\n",
        "  block7: MAE=0.028291 | RMSE=0.036593 | OpenDSS=340ms | GNN=4626ms\n",
        "========================================================================\n",
        "<Figure size 640x480 with 0 Axes>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16c4ad15",
      "metadata": {},
      "source": [
        "## Voltage profile by operation point\n",
        "\n",
        "Compare voltage at node 840.1 for different P_BASE, Q_BASE, PV_BASE values. Uses the same load/PV time series for all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae63967",
      "metadata": {},
      "outputs": [],
      "source": [
        "from plot_voltage_profile_by_operation_point import main\n",
        "\n",
        "# Operation points: (label, P_BASE, Q_BASE, PV_BASE)\n",
        "OPERATION_POINTS = [\n",
        "    (\"Current\", 1415.2, 835.2, 1000.0),\n",
        "    (\"Lower PV (800 kW)\", 1415.2, 835.2, 800.0),\n",
        "    (\"Higher load (1600/950)\", 1600.0, 950.0, 1000.0),\n",
        "    (\"Lower net load (1200/700)\", 1200.0, 700.0, 1000.0),\n",
        "]\n",
        "main(node=\"840.1\", operation_points=OPERATION_POINTS, save_path=\"plots/voltage_by_operation_point.png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "SSIM Environment",
      "language": "python",
      "name": "ssim_env"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
